{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113091eb-ae2e-44ae-92e9-93dd8d8f19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87484007-653e-4ae9-b363-52bd1f045fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e46f74f-6914-4c7b-927f-bc42f6a60011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Boring</th>\n",
       "      <th>Horrible</th>\n",
       "      <th>Calm</th>\n",
       "      <th>Funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Boring  Horrible  Calm  Funny\n",
       "0          1       8         1     3      2\n",
       "1          1       2         1     8      8\n",
       "2          1       2         8     1      1\n",
       "3          1       1         1     3      9\n",
       "4          2       8         1     4      2\n",
       "..       ...     ...       ...   ...    ...\n",
       "107       27       1         1     7      5\n",
       "108       28       7         1     6      1\n",
       "109       28       1         1     8      8\n",
       "110       28       1         7     6      1\n",
       "111       28       1         1     7      7\n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_folder = 'gameemo_database_epochs'\n",
    "epochs_psd_folder = 'gameemo_database_epochs_psd'\n",
    "labels_path = 'GameLabels\\GAMEEMO_SCORES.xlsx'\n",
    "labels_sheet = 'All'\n",
    "labels_file = pd.read_excel(labels_path, labels_sheet)\n",
    "labels_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ab4f72-dbb4-4008-979f-dbec8f3f6c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  3,  2],\n",
       "       [ 2,  1,  8,  8],\n",
       "       [ 2,  8,  1,  1],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 8,  1,  4,  2],\n",
       "       [ 2,  1,  7,  6],\n",
       "       [ 2,  8,  3,  2],\n",
       "       [ 2,  2,  7,  9],\n",
       "       [ 7,  2,  6,  1],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 8,  1,  3,  1],\n",
       "       [ 3,  1,  9,  6],\n",
       "       [ 1,  9,  2,  1],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 7,  1,  2,  1],\n",
       "       [ 2,  1,  5,  7],\n",
       "       [ 1,  8,  1,  2],\n",
       "       [ 2,  1,  3,  8],\n",
       "       [ 7,  1,  3,  1],\n",
       "       [ 1,  1,  7,  3],\n",
       "       [ 1,  8,  1,  1],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 8,  1,  3,  3],\n",
       "       [ 3,  1,  8,  6],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  1, 10],\n",
       "       [10,  1,  1,  1],\n",
       "       [ 3,  1,  8,  8],\n",
       "       [ 1,  5,  7,  1],\n",
       "       [ 1,  1,  6,  6],\n",
       "       [10,  1,  4,  4],\n",
       "       [ 1,  1,  8,  6],\n",
       "       [ 1,  9,  2,  3],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 8,  1,  5,  4],\n",
       "       [ 1,  1,  7,  2],\n",
       "       [ 1,  8,  2,  1],\n",
       "       [ 1,  1,  5, 10],\n",
       "       [ 7,  1,  7,  4],\n",
       "       [ 1,  1,  8,  6],\n",
       "       [ 7,  8,  2,  3],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 9,  1,  7,  4],\n",
       "       [ 1,  1,  5,  8],\n",
       "       [ 1,  6,  2,  3],\n",
       "       [ 1,  2,  5,  6],\n",
       "       [ 4,  1,  7,  7],\n",
       "       [ 6,  1,  7,  3],\n",
       "       [ 1,  8,  4,  2],\n",
       "       [ 1,  2,  7,  9],\n",
       "       [ 8,  1,  8,  2],\n",
       "       [ 3,  1,  6,  7],\n",
       "       [ 1,  8,  2,  4],\n",
       "       [ 1,  2,  4, 10],\n",
       "       [ 7,  1,  7,  3],\n",
       "       [ 3,  1,  9,  7],\n",
       "       [ 1,  8,  2,  2],\n",
       "       [ 3,  1,  1,  8],\n",
       "       [ 8,  1,  8,  2],\n",
       "       [ 2,  1,  8,  6],\n",
       "       [ 1,  9,  4,  1],\n",
       "       [ 1,  2,  2,  7],\n",
       "       [ 7,  1,  8,  3],\n",
       "       [ 3,  1,  7,  7],\n",
       "       [ 1,  7,  4,  3],\n",
       "       [ 1,  1,  2,  6],\n",
       "       [ 2,  1,  8,  7],\n",
       "       [ 3,  1,  6,  5],\n",
       "       [ 2,  6,  3,  3],\n",
       "       [ 1,  1,  2,  7],\n",
       "       [ 3,  6,  2,  7],\n",
       "       [ 7,  1,  6,  3],\n",
       "       [ 3,  6,  3,  4],\n",
       "       [ 1,  1,  4,  9],\n",
       "       [ 8,  1,  7,  2],\n",
       "       [ 2,  1,  7,  7],\n",
       "       [ 1, 10,  2,  1],\n",
       "       [ 1,  1,  5,  8],\n",
       "       [10,  1, 10,  1],\n",
       "       [ 2,  1,  6,  7],\n",
       "       [ 2, 10,  1,  1],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 9,  1,  7,  2],\n",
       "       [ 2,  1,  8,  8],\n",
       "       [ 1,  8,  3,  3],\n",
       "       [ 1,  1,  1,  6],\n",
       "       [ 9,  1,  8,  2],\n",
       "       [ 3,  1,  9,  6],\n",
       "       [ 1,  6,  5,  8],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 7,  1,  8,  3],\n",
       "       [ 5,  1,  7,  6],\n",
       "       [ 3,  7,  5,  5],\n",
       "       [ 1,  1,  6,  8],\n",
       "       [ 9,  1,  8,  3],\n",
       "       [ 2,  1,  7,  6],\n",
       "       [ 1,  6,  3,  4],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 8,  1,  6,  6],\n",
       "       [ 2,  1,  7,  2],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  5,  7],\n",
       "       [ 6,  1,  8,  2],\n",
       "       [ 1,  1, 10,  8],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  7,  5],\n",
       "       [ 7,  1,  6,  1],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 1,  7,  6,  1],\n",
       "       [ 1,  1,  7,  7]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array = np.array(labels_file[['Boring', 'Horrible', 'Calm', 'Funny']])\n",
    "labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9f5dce-4859-4ebf-9387-378ed5cb7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [02:09<00:00,  4.62s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(epochs_folder)):\n",
    "    for game in os.listdir(os.path.join(epochs_folder, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(epochs_folder, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(epochs_folder, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T\n",
    "            epochs_data.append(np.array(read_epoch))\n",
    "            labels_data.append(labels_array[k-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2417c246-a08d-4a59-a298-ced2092ead18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:19<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(epochs_psd_folder)):\n",
    "    for game in os.listdir(os.path.join(epochs_psd_folder, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(epochs_psd_folder, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(epochs_psd_folder, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T\n",
    "            epochs_data.append(np.array(read_epoch))\n",
    "            labels_data.append(labels_array[k-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f53713-f204-4754-b7ed-96552ba3ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 641) (4,)\n"
     ]
    }
   ],
   "source": [
    "print((epochs_data[0].shape), (labels_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d439a3dd-d753-4a30-b34c-e322d46c02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 14, 641) (6608, 4)\n"
     ]
    }
   ],
   "source": [
    "main_data = np.array(epochs_data)\n",
    "main_labels = np.array(labels_data)\n",
    "print(main_data.shape, main_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98664953-7364-4d91-be51-e2685256010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3964, 14, 641) (3964, 4)\n",
      "Validation set shape: (1322, 14, 641) (1322, 4)\n",
      "Testing set shape: (1322, 14, 641) (1322, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into training+validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(main_data, main_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6110800-bc66-4777-b51a-64427d847f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2caf0f20-2e45-4be6-8e5f-14f8d12fd348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75c3805-8a1c-4015-9f0f-df2a46b4f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet(nb_classes = 4, Chans = 14, Samples = 641, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    # input1   = Input(shape = (Chans, Samples, 1))\n",
    "    # block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "    #                                input_shape = (Chans, Samples, 1),\n",
    "    #                                use_bias = False)(input1)\n",
    "    # block1       = BatchNormalization()(block1)\n",
    "    # block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "    #                                depth_multiplier = D,\n",
    "    #                                depthwise_constraint = max_norm(1.))(block1)\n",
    "    # block1       = BatchNormalization()(block1)\n",
    "    # block1       = Activation('elu')(block1)\n",
    "    # block1       = AveragePooling2D((1, 4))(block1)\n",
    "    # block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    # block2       = SeparableConv2D(F2, (1, 16),\n",
    "    #                                use_bias = False, padding = 'same')(block1)\n",
    "    # block2       = BatchNormalization()(block2)\n",
    "    # block2       = Activation('elu')(block2)\n",
    "    # block2       = AveragePooling2D((1, 8))(block2)\n",
    "    # block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    # flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    # dense        = Dense(nb_classes, name = 'dense', \n",
    "    #                      kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    # # softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    # output      = Activation('linear', name = 'linear')(dense)\n",
    "    # return Model(inputs=input1, outputs=output)\n",
    "\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    # block1       = Conv2D(25, (Chans, 1),\n",
    "    #                              kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = Conv2D(25, (Chans, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block4)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    output      = Activation('linear')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991eff3f-2eed-4b76-a7ee-d2769c429604",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model = EEGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e45189f2-ccf9-443a-b17b-6527587921d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 641, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 637, 25)       150       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 637, 25)      100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 14, 637, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 318, 25)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 318, 25)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 314, 50)       6300      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 314, 50)      200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 314, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 157, 50)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 157, 50)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 153, 100)      25100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 153, 100)     400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14, 153, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 76, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 76, 100)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 72, 200)       100200    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 72, 25)         70025     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 72, 25)        100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1, 72, 25)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 36, 25)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 36, 25)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 900)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 3604      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206,179\n",
      "Trainable params: 205,779\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eegnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b72f519-1158-4274-ba9f-77aab74c7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2763bcc-b3d4-435f-91da-811bac9b2fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "248/248 [==============================] - 20s 23ms/step - loss: 8.9757 - accuracy: 0.2858 - val_loss: 8.1596 - val_accuracy: 0.3011\n",
      "Epoch 2/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 8.2166 - accuracy: 0.3216 - val_loss: 7.9838 - val_accuracy: 0.3540\n",
      "Epoch 3/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 7.6392 - accuracy: 0.3696 - val_loss: 7.5956 - val_accuracy: 0.4153\n",
      "Epoch 4/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 7.3276 - accuracy: 0.4077 - val_loss: 7.0477 - val_accuracy: 0.4183\n",
      "Epoch 5/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 7.0795 - accuracy: 0.4215 - val_loss: 7.1375 - val_accuracy: 0.4319\n",
      "Epoch 6/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.8800 - accuracy: 0.4344 - val_loss: 6.8701 - val_accuracy: 0.4766\n",
      "Epoch 7/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.7345 - accuracy: 0.4493 - val_loss: 6.9800 - val_accuracy: 0.3676\n",
      "Epoch 8/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.6677 - accuracy: 0.4478 - val_loss: 7.1165 - val_accuracy: 0.4470\n",
      "Epoch 9/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.5869 - accuracy: 0.4639 - val_loss: 6.6421 - val_accuracy: 0.4531\n",
      "Epoch 10/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.5029 - accuracy: 0.4664 - val_loss: 7.1124 - val_accuracy: 0.3646\n",
      "Epoch 11/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.3815 - accuracy: 0.4685 - val_loss: 7.0265 - val_accuracy: 0.3933\n",
      "Epoch 12/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.4200 - accuracy: 0.4705 - val_loss: 6.6655 - val_accuracy: 0.3971\n",
      "Epoch 13/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.2411 - accuracy: 0.4816 - val_loss: 7.7579 - val_accuracy: 0.4259\n",
      "Epoch 14/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.2425 - accuracy: 0.4796 - val_loss: 6.4640 - val_accuracy: 0.4675\n",
      "Epoch 15/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.2143 - accuracy: 0.4836 - val_loss: 6.4060 - val_accuracy: 0.4675\n",
      "Epoch 16/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.1070 - accuracy: 0.4985 - val_loss: 6.5115 - val_accuracy: 0.4145\n",
      "Epoch 17/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.1177 - accuracy: 0.4997 - val_loss: 6.7385 - val_accuracy: 0.4092\n",
      "Epoch 18/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.1243 - accuracy: 0.5015 - val_loss: 6.2182 - val_accuracy: 0.4970\n",
      "Epoch 19/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.0460 - accuracy: 0.5043 - val_loss: 6.1649 - val_accuracy: 0.5121\n",
      "Epoch 20/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.9792 - accuracy: 0.5076 - val_loss: 6.3880 - val_accuracy: 0.5076\n",
      "Epoch 21/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 6.1216 - accuracy: 0.4945 - val_loss: 6.1573 - val_accuracy: 0.4887\n",
      "Epoch 22/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.9940 - accuracy: 0.5098 - val_loss: 6.1571 - val_accuracy: 0.4644\n",
      "Epoch 23/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.8733 - accuracy: 0.5091 - val_loss: 6.4890 - val_accuracy: 0.5295\n",
      "Epoch 24/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.7876 - accuracy: 0.5222 - val_loss: 6.1655 - val_accuracy: 0.4856\n",
      "Epoch 25/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.8331 - accuracy: 0.5285 - val_loss: 6.0161 - val_accuracy: 0.5068\n",
      "Epoch 26/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.7762 - accuracy: 0.5179 - val_loss: 6.0256 - val_accuracy: 0.4977\n",
      "Epoch 27/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.8426 - accuracy: 0.5343 - val_loss: 6.3867 - val_accuracy: 0.4667\n",
      "Epoch 28/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.7346 - accuracy: 0.5288 - val_loss: 6.0291 - val_accuracy: 0.5265\n",
      "Epoch 29/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.7913 - accuracy: 0.5212 - val_loss: 5.9186 - val_accuracy: 0.5068\n",
      "Epoch 30/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.7355 - accuracy: 0.5333 - val_loss: 5.8960 - val_accuracy: 0.5144\n",
      "Epoch 31/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.6742 - accuracy: 0.5323 - val_loss: 6.0976 - val_accuracy: 0.4667\n",
      "Epoch 32/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.6855 - accuracy: 0.5353 - val_loss: 6.1044 - val_accuracy: 0.5673\n",
      "Epoch 33/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.6326 - accuracy: 0.5376 - val_loss: 6.1107 - val_accuracy: 0.5318\n",
      "Epoch 34/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.6367 - accuracy: 0.5242 - val_loss: 5.8646 - val_accuracy: 0.5182\n",
      "Epoch 35/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.5050 - accuracy: 0.5416 - val_loss: 5.9521 - val_accuracy: 0.5393\n",
      "Epoch 36/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.5599 - accuracy: 0.5315 - val_loss: 5.9163 - val_accuracy: 0.5393\n",
      "Epoch 37/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.5410 - accuracy: 0.5411 - val_loss: 5.8688 - val_accuracy: 0.4962\n",
      "Epoch 38/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4412 - accuracy: 0.5598 - val_loss: 5.8589 - val_accuracy: 0.5061\n",
      "Epoch 39/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4954 - accuracy: 0.5411 - val_loss: 5.8518 - val_accuracy: 0.5197\n",
      "Epoch 40/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4864 - accuracy: 0.5497 - val_loss: 5.9570 - val_accuracy: 0.5719\n",
      "Epoch 41/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4175 - accuracy: 0.5646 - val_loss: 5.8737 - val_accuracy: 0.5401\n",
      "Epoch 42/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.5302 - accuracy: 0.5507 - val_loss: 5.7970 - val_accuracy: 0.5189\n",
      "Epoch 43/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4120 - accuracy: 0.5499 - val_loss: 5.8910 - val_accuracy: 0.5772\n",
      "Epoch 44/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4846 - accuracy: 0.5467 - val_loss: 5.7926 - val_accuracy: 0.5348\n",
      "Epoch 45/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4692 - accuracy: 0.5487 - val_loss: 5.8320 - val_accuracy: 0.5522\n",
      "Epoch 46/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.4001 - accuracy: 0.5568 - val_loss: 5.7394 - val_accuracy: 0.5340\n",
      "Epoch 47/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.3963 - accuracy: 0.5583 - val_loss: 5.9221 - val_accuracy: 0.5204\n",
      "Epoch 48/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.3957 - accuracy: 0.5618 - val_loss: 6.0058 - val_accuracy: 0.5257\n",
      "Epoch 49/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.3833 - accuracy: 0.5608 - val_loss: 5.8064 - val_accuracy: 0.5537\n",
      "Epoch 50/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.3532 - accuracy: 0.5489 - val_loss: 5.8063 - val_accuracy: 0.5620\n",
      "Epoch 51/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2936 - accuracy: 0.5671 - val_loss: 5.8726 - val_accuracy: 0.4992\n",
      "Epoch 52/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.3446 - accuracy: 0.5515 - val_loss: 5.8097 - val_accuracy: 0.5719\n",
      "Epoch 53/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2762 - accuracy: 0.5704 - val_loss: 5.8835 - val_accuracy: 0.4871\n",
      "Epoch 54/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2349 - accuracy: 0.5676 - val_loss: 5.8934 - val_accuracy: 0.5688\n",
      "Epoch 55/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2879 - accuracy: 0.5568 - val_loss: 5.6960 - val_accuracy: 0.5446\n",
      "Epoch 56/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2294 - accuracy: 0.5628 - val_loss: 5.6468 - val_accuracy: 0.5658\n",
      "Epoch 57/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2378 - accuracy: 0.5621 - val_loss: 5.7307 - val_accuracy: 0.5537\n",
      "Epoch 58/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2795 - accuracy: 0.5608 - val_loss: 5.8284 - val_accuracy: 0.5492\n",
      "Epoch 59/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2227 - accuracy: 0.5792 - val_loss: 5.5210 - val_accuracy: 0.5575\n",
      "Epoch 60/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2285 - accuracy: 0.5694 - val_loss: 5.7918 - val_accuracy: 0.5144\n",
      "Epoch 61/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.1302 - accuracy: 0.5825 - val_loss: 5.6174 - val_accuracy: 0.5378\n",
      "Epoch 62/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.1449 - accuracy: 0.5643 - val_loss: 5.5383 - val_accuracy: 0.5635\n",
      "Epoch 63/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.1251 - accuracy: 0.5772 - val_loss: 5.7028 - val_accuracy: 0.5378\n",
      "Epoch 64/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.1904 - accuracy: 0.5674 - val_loss: 5.7759 - val_accuracy: 0.5741\n",
      "Epoch 65/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.1067 - accuracy: 0.5719 - val_loss: 5.7591 - val_accuracy: 0.5257\n",
      "Epoch 66/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2067 - accuracy: 0.5719 - val_loss: 5.7173 - val_accuracy: 0.5703\n",
      "Epoch 67/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.2009 - accuracy: 0.5742 - val_loss: 5.7553 - val_accuracy: 0.5106\n",
      "Epoch 68/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0892 - accuracy: 0.5860 - val_loss: 5.5640 - val_accuracy: 0.5492\n",
      "Epoch 69/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0942 - accuracy: 0.5792 - val_loss: 5.4128 - val_accuracy: 0.5416\n",
      "Epoch 70/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0986 - accuracy: 0.5739 - val_loss: 5.6912 - val_accuracy: 0.5711\n",
      "Epoch 71/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.1288 - accuracy: 0.5669 - val_loss: 5.5945 - val_accuracy: 0.5877\n",
      "Epoch 72/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0271 - accuracy: 0.5825 - val_loss: 5.3860 - val_accuracy: 0.5681\n",
      "Epoch 73/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0357 - accuracy: 0.5764 - val_loss: 5.4579 - val_accuracy: 0.5719\n",
      "Epoch 74/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0585 - accuracy: 0.5787 - val_loss: 5.8322 - val_accuracy: 0.5946\n",
      "Epoch 75/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0246 - accuracy: 0.5832 - val_loss: 5.5220 - val_accuracy: 0.5726\n",
      "Epoch 76/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0929 - accuracy: 0.5777 - val_loss: 5.4081 - val_accuracy: 0.5446\n",
      "Epoch 77/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0512 - accuracy: 0.5883 - val_loss: 5.6441 - val_accuracy: 0.5726\n",
      "Epoch 78/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0780 - accuracy: 0.5782 - val_loss: 5.7175 - val_accuracy: 0.5756\n",
      "Epoch 79/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0751 - accuracy: 0.5780 - val_loss: 5.4908 - val_accuracy: 0.5734\n",
      "Epoch 80/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0418 - accuracy: 0.5840 - val_loss: 5.6906 - val_accuracy: 0.5015\n",
      "Epoch 81/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0158 - accuracy: 0.5843 - val_loss: 5.3581 - val_accuracy: 0.5635\n",
      "Epoch 82/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0115 - accuracy: 0.5694 - val_loss: 5.3719 - val_accuracy: 0.5703\n",
      "Epoch 83/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 5.0085 - accuracy: 0.5815 - val_loss: 5.6164 - val_accuracy: 0.5393\n",
      "Epoch 84/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0335 - accuracy: 0.5764 - val_loss: 5.6605 - val_accuracy: 0.5923\n",
      "Epoch 85/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9580 - accuracy: 0.5812 - val_loss: 5.6141 - val_accuracy: 0.5552\n",
      "Epoch 86/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 5.0427 - accuracy: 0.5926 - val_loss: 5.6594 - val_accuracy: 0.5340\n",
      "Epoch 87/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9298 - accuracy: 0.5916 - val_loss: 5.3477 - val_accuracy: 0.6074\n",
      "Epoch 88/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8445 - accuracy: 0.5976 - val_loss: 5.6475 - val_accuracy: 0.5673\n",
      "Epoch 89/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8957 - accuracy: 0.5943 - val_loss: 5.5170 - val_accuracy: 0.5333\n",
      "Epoch 90/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8907 - accuracy: 0.5880 - val_loss: 5.6050 - val_accuracy: 0.5537\n",
      "Epoch 91/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9237 - accuracy: 0.5931 - val_loss: 5.4944 - val_accuracy: 0.5658\n",
      "Epoch 92/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9544 - accuracy: 0.5855 - val_loss: 5.3425 - val_accuracy: 0.5522\n",
      "Epoch 93/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8956 - accuracy: 0.5964 - val_loss: 5.3572 - val_accuracy: 0.5968\n",
      "Epoch 94/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8192 - accuracy: 0.5999 - val_loss: 5.5860 - val_accuracy: 0.5507\n",
      "Epoch 95/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9065 - accuracy: 0.5913 - val_loss: 5.5419 - val_accuracy: 0.5893\n",
      "Epoch 96/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8697 - accuracy: 0.5815 - val_loss: 5.6540 - val_accuracy: 0.5620\n",
      "Epoch 97/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8927 - accuracy: 0.5911 - val_loss: 5.5112 - val_accuracy: 0.5756\n",
      "Epoch 98/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9576 - accuracy: 0.5853 - val_loss: 5.3437 - val_accuracy: 0.5658\n",
      "Epoch 99/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8119 - accuracy: 0.5906 - val_loss: 5.3862 - val_accuracy: 0.5393\n",
      "Epoch 100/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8527 - accuracy: 0.5873 - val_loss: 5.4566 - val_accuracy: 0.5424\n",
      "Epoch 101/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8590 - accuracy: 0.5949 - val_loss: 5.5389 - val_accuracy: 0.5658\n",
      "Epoch 102/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8495 - accuracy: 0.5928 - val_loss: 5.4274 - val_accuracy: 0.5862\n",
      "Epoch 103/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7620 - accuracy: 0.6037 - val_loss: 5.4008 - val_accuracy: 0.5499\n",
      "Epoch 104/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8607 - accuracy: 0.5949 - val_loss: 5.3638 - val_accuracy: 0.5477\n",
      "Epoch 105/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9253 - accuracy: 0.5812 - val_loss: 5.6493 - val_accuracy: 0.5272\n",
      "Epoch 106/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9086 - accuracy: 0.5979 - val_loss: 5.5071 - val_accuracy: 0.5681\n",
      "Epoch 107/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7727 - accuracy: 0.6009 - val_loss: 5.4261 - val_accuracy: 0.5772\n",
      "Epoch 108/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.9001 - accuracy: 0.5906 - val_loss: 5.4380 - val_accuracy: 0.5477\n",
      "Epoch 109/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7289 - accuracy: 0.6049 - val_loss: 5.3572 - val_accuracy: 0.5703\n",
      "Epoch 110/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7890 - accuracy: 0.5961 - val_loss: 5.4111 - val_accuracy: 0.5628\n",
      "Epoch 111/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8286 - accuracy: 0.5901 - val_loss: 5.5748 - val_accuracy: 0.5469\n",
      "Epoch 112/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7808 - accuracy: 0.5956 - val_loss: 5.3598 - val_accuracy: 0.5348\n",
      "Epoch 113/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8401 - accuracy: 0.5850 - val_loss: 5.4377 - val_accuracy: 0.5628\n",
      "Epoch 114/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8336 - accuracy: 0.5880 - val_loss: 5.3020 - val_accuracy: 0.5681\n",
      "Epoch 115/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7410 - accuracy: 0.5906 - val_loss: 5.2455 - val_accuracy: 0.5477\n",
      "Epoch 116/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.8027 - accuracy: 0.5926 - val_loss: 5.4191 - val_accuracy: 0.5772\n",
      "Epoch 117/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7477 - accuracy: 0.5941 - val_loss: 5.5245 - val_accuracy: 0.5915\n",
      "Epoch 118/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7121 - accuracy: 0.5961 - val_loss: 5.1282 - val_accuracy: 0.5817\n",
      "Epoch 119/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7585 - accuracy: 0.6075 - val_loss: 5.1395 - val_accuracy: 0.5666\n",
      "Epoch 120/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7874 - accuracy: 0.5986 - val_loss: 5.2753 - val_accuracy: 0.5719\n",
      "Epoch 121/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6965 - accuracy: 0.5989 - val_loss: 5.6241 - val_accuracy: 0.5991\n",
      "Epoch 122/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7744 - accuracy: 0.5979 - val_loss: 5.3659 - val_accuracy: 0.5930\n",
      "Epoch 123/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7129 - accuracy: 0.6110 - val_loss: 5.2763 - val_accuracy: 0.5499\n",
      "Epoch 124/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6614 - accuracy: 0.6060 - val_loss: 5.3706 - val_accuracy: 0.5605\n",
      "Epoch 125/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7535 - accuracy: 0.6062 - val_loss: 5.4626 - val_accuracy: 0.5499\n",
      "Epoch 126/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7378 - accuracy: 0.5928 - val_loss: 5.2707 - val_accuracy: 0.5499\n",
      "Epoch 127/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7838 - accuracy: 0.6017 - val_loss: 5.4517 - val_accuracy: 0.5673\n",
      "Epoch 128/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7526 - accuracy: 0.6032 - val_loss: 5.4513 - val_accuracy: 0.5658\n",
      "Epoch 129/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7015 - accuracy: 0.6095 - val_loss: 5.4804 - val_accuracy: 0.5749\n",
      "Epoch 130/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6518 - accuracy: 0.6060 - val_loss: 5.4916 - val_accuracy: 0.6067\n",
      "Epoch 131/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7344 - accuracy: 0.5961 - val_loss: 5.2904 - val_accuracy: 0.5439\n",
      "Epoch 132/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7043 - accuracy: 0.6062 - val_loss: 5.4041 - val_accuracy: 0.5976\n",
      "Epoch 133/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7058 - accuracy: 0.6087 - val_loss: 5.6680 - val_accuracy: 0.5923\n",
      "Epoch 134/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6619 - accuracy: 0.6090 - val_loss: 5.4256 - val_accuracy: 0.5908\n",
      "Epoch 135/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6929 - accuracy: 0.6047 - val_loss: 5.4132 - val_accuracy: 0.5416\n",
      "Epoch 136/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6058 - accuracy: 0.6095 - val_loss: 5.3125 - val_accuracy: 0.5847\n",
      "Epoch 137/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6576 - accuracy: 0.5989 - val_loss: 5.3208 - val_accuracy: 0.5998\n",
      "Epoch 138/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6449 - accuracy: 0.6110 - val_loss: 5.3555 - val_accuracy: 0.5893\n",
      "Epoch 139/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5889 - accuracy: 0.6181 - val_loss: 5.6650 - val_accuracy: 0.5961\n",
      "Epoch 140/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7061 - accuracy: 0.6054 - val_loss: 5.3021 - val_accuracy: 0.5703\n",
      "Epoch 141/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6359 - accuracy: 0.6123 - val_loss: 5.3336 - val_accuracy: 0.5643\n",
      "Epoch 142/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6329 - accuracy: 0.6065 - val_loss: 5.4882 - val_accuracy: 0.5567\n",
      "Epoch 143/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6855 - accuracy: 0.6029 - val_loss: 5.5220 - val_accuracy: 0.5582\n",
      "Epoch 144/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6746 - accuracy: 0.6037 - val_loss: 5.4389 - val_accuracy: 0.6082\n",
      "Epoch 145/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6467 - accuracy: 0.6014 - val_loss: 5.2407 - val_accuracy: 0.6104\n",
      "Epoch 146/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6213 - accuracy: 0.6017 - val_loss: 5.2957 - val_accuracy: 0.5711\n",
      "Epoch 147/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.6960 - accuracy: 0.6034 - val_loss: 5.4157 - val_accuracy: 0.5961\n",
      "Epoch 148/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5540 - accuracy: 0.6266 - val_loss: 5.2478 - val_accuracy: 0.5938\n",
      "Epoch 149/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6060 - accuracy: 0.6178 - val_loss: 5.4055 - val_accuracy: 0.5688\n",
      "Epoch 150/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5755 - accuracy: 0.5969 - val_loss: 5.1501 - val_accuracy: 0.6195\n",
      "Epoch 151/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.7189 - accuracy: 0.6090 - val_loss: 5.3205 - val_accuracy: 0.6036\n",
      "Epoch 152/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6502 - accuracy: 0.6022 - val_loss: 5.2381 - val_accuracy: 0.5688\n",
      "Epoch 153/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6282 - accuracy: 0.6032 - val_loss: 5.3087 - val_accuracy: 0.6082\n",
      "Epoch 154/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.6268 - accuracy: 0.6143 - val_loss: 5.2555 - val_accuracy: 0.5961\n",
      "Epoch 155/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5480 - accuracy: 0.6198 - val_loss: 5.3145 - val_accuracy: 0.5590\n",
      "Epoch 156/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5872 - accuracy: 0.6105 - val_loss: 5.2772 - val_accuracy: 0.5779\n",
      "Epoch 157/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5956 - accuracy: 0.6082 - val_loss: 5.4772 - val_accuracy: 0.5885\n",
      "Epoch 158/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5424 - accuracy: 0.6115 - val_loss: 5.1234 - val_accuracy: 0.6029\n",
      "Epoch 159/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5150 - accuracy: 0.6266 - val_loss: 5.3152 - val_accuracy: 0.5620\n",
      "Epoch 160/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5260 - accuracy: 0.6163 - val_loss: 5.3598 - val_accuracy: 0.5749\n",
      "Epoch 161/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5669 - accuracy: 0.6092 - val_loss: 5.4959 - val_accuracy: 0.5530\n",
      "Epoch 162/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5116 - accuracy: 0.6135 - val_loss: 5.3976 - val_accuracy: 0.5794\n",
      "Epoch 163/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5667 - accuracy: 0.6143 - val_loss: 5.3094 - val_accuracy: 0.5582\n",
      "Epoch 164/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5653 - accuracy: 0.6110 - val_loss: 5.2415 - val_accuracy: 0.6104\n",
      "Epoch 165/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5700 - accuracy: 0.6229 - val_loss: 5.3351 - val_accuracy: 0.5643\n",
      "Epoch 166/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5938 - accuracy: 0.6128 - val_loss: 5.3585 - val_accuracy: 0.5772\n",
      "Epoch 167/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5203 - accuracy: 0.6113 - val_loss: 5.3093 - val_accuracy: 0.5832\n",
      "Epoch 168/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5547 - accuracy: 0.6218 - val_loss: 5.5862 - val_accuracy: 0.5900\n",
      "Epoch 169/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4475 - accuracy: 0.6181 - val_loss: 5.1320 - val_accuracy: 0.5779\n",
      "Epoch 170/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5068 - accuracy: 0.6105 - val_loss: 5.3075 - val_accuracy: 0.6074\n",
      "Epoch 171/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4562 - accuracy: 0.6234 - val_loss: 5.3155 - val_accuracy: 0.6006\n",
      "Epoch 172/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4814 - accuracy: 0.6153 - val_loss: 5.3077 - val_accuracy: 0.6006\n",
      "Epoch 173/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5769 - accuracy: 0.6065 - val_loss: 5.5165 - val_accuracy: 0.5734\n",
      "Epoch 174/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5033 - accuracy: 0.6138 - val_loss: 5.1321 - val_accuracy: 0.5968\n",
      "Epoch 175/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4580 - accuracy: 0.6329 - val_loss: 5.2117 - val_accuracy: 0.5696\n",
      "Epoch 176/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5632 - accuracy: 0.6107 - val_loss: 5.2169 - val_accuracy: 0.5658\n",
      "Epoch 177/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.6141 - accuracy: 0.6107 - val_loss: 5.4572 - val_accuracy: 0.6006\n",
      "Epoch 178/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5203 - accuracy: 0.6218 - val_loss: 5.2462 - val_accuracy: 0.5825\n",
      "Epoch 179/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4555 - accuracy: 0.6171 - val_loss: 5.1869 - val_accuracy: 0.5809\n",
      "Epoch 180/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5866 - accuracy: 0.6198 - val_loss: 5.3079 - val_accuracy: 0.5772\n",
      "Epoch 181/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.5252 - accuracy: 0.6201 - val_loss: 5.1595 - val_accuracy: 0.5915\n",
      "Epoch 182/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4996 - accuracy: 0.6128 - val_loss: 5.2862 - val_accuracy: 0.5787\n",
      "Epoch 183/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5073 - accuracy: 0.6171 - val_loss: 5.2179 - val_accuracy: 0.5484\n",
      "Epoch 184/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4621 - accuracy: 0.6148 - val_loss: 5.1552 - val_accuracy: 0.5764\n",
      "Epoch 185/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4557 - accuracy: 0.6118 - val_loss: 5.3012 - val_accuracy: 0.5840\n",
      "Epoch 186/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5969 - accuracy: 0.6120 - val_loss: 5.3649 - val_accuracy: 0.5560\n",
      "Epoch 187/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5356 - accuracy: 0.6090 - val_loss: 5.4295 - val_accuracy: 0.5953\n",
      "Epoch 188/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4199 - accuracy: 0.6314 - val_loss: 5.1866 - val_accuracy: 0.5855\n",
      "Epoch 189/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4311 - accuracy: 0.6276 - val_loss: 5.1877 - val_accuracy: 0.5303\n",
      "Epoch 190/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4298 - accuracy: 0.6226 - val_loss: 5.1961 - val_accuracy: 0.5590\n",
      "Epoch 191/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4350 - accuracy: 0.6208 - val_loss: 5.4530 - val_accuracy: 0.5938\n",
      "Epoch 192/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4960 - accuracy: 0.6221 - val_loss: 5.1541 - val_accuracy: 0.5855\n",
      "Epoch 193/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4376 - accuracy: 0.6234 - val_loss: 5.2272 - val_accuracy: 0.5673\n",
      "Epoch 194/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4814 - accuracy: 0.6173 - val_loss: 5.4210 - val_accuracy: 0.6157\n",
      "Epoch 195/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4196 - accuracy: 0.6276 - val_loss: 5.2303 - val_accuracy: 0.5711\n",
      "Epoch 196/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4585 - accuracy: 0.6163 - val_loss: 5.3692 - val_accuracy: 0.5386\n",
      "Epoch 197/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4477 - accuracy: 0.6138 - val_loss: 5.1971 - val_accuracy: 0.5961\n",
      "Epoch 198/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3922 - accuracy: 0.6241 - val_loss: 5.3135 - val_accuracy: 0.5802\n",
      "Epoch 199/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.5051 - accuracy: 0.6206 - val_loss: 5.2359 - val_accuracy: 0.5991\n",
      "Epoch 200/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4212 - accuracy: 0.6287 - val_loss: 5.0150 - val_accuracy: 0.6021\n",
      "Epoch 201/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4008 - accuracy: 0.6249 - val_loss: 5.1899 - val_accuracy: 0.5726\n",
      "Epoch 202/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4201 - accuracy: 0.6181 - val_loss: 5.1372 - val_accuracy: 0.5855\n",
      "Epoch 203/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4837 - accuracy: 0.6297 - val_loss: 5.2512 - val_accuracy: 0.5537\n",
      "Epoch 204/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4313 - accuracy: 0.6221 - val_loss: 5.1426 - val_accuracy: 0.5968\n",
      "Epoch 205/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3972 - accuracy: 0.6155 - val_loss: 5.1456 - val_accuracy: 0.5832\n",
      "Epoch 206/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4487 - accuracy: 0.6261 - val_loss: 5.1099 - val_accuracy: 0.5930\n",
      "Epoch 207/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4004 - accuracy: 0.6256 - val_loss: 5.1901 - val_accuracy: 0.5893\n",
      "Epoch 208/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4890 - accuracy: 0.6118 - val_loss: 5.1644 - val_accuracy: 0.5991\n",
      "Epoch 209/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3930 - accuracy: 0.6186 - val_loss: 5.2433 - val_accuracy: 0.5605\n",
      "Epoch 210/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.4103 - accuracy: 0.6266 - val_loss: 5.0544 - val_accuracy: 0.5787\n",
      "Epoch 211/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3623 - accuracy: 0.6246 - val_loss: 5.2213 - val_accuracy: 0.5711\n",
      "Epoch 212/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3609 - accuracy: 0.6309 - val_loss: 5.1493 - val_accuracy: 0.5893\n",
      "Epoch 213/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4518 - accuracy: 0.6269 - val_loss: 5.2443 - val_accuracy: 0.6188\n",
      "Epoch 214/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4741 - accuracy: 0.6090 - val_loss: 5.0767 - val_accuracy: 0.5862\n",
      "Epoch 215/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3767 - accuracy: 0.6292 - val_loss: 5.1831 - val_accuracy: 0.5991\n",
      "Epoch 216/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3864 - accuracy: 0.6261 - val_loss: 5.1776 - val_accuracy: 0.5666\n",
      "Epoch 217/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4175 - accuracy: 0.6188 - val_loss: 5.1635 - val_accuracy: 0.5772\n",
      "Epoch 218/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3627 - accuracy: 0.6279 - val_loss: 5.2634 - val_accuracy: 0.6104\n",
      "Epoch 219/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3387 - accuracy: 0.6322 - val_loss: 5.1128 - val_accuracy: 0.6089\n",
      "Epoch 220/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3746 - accuracy: 0.6208 - val_loss: 5.1079 - val_accuracy: 0.5696\n",
      "Epoch 221/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3312 - accuracy: 0.6213 - val_loss: 5.1919 - val_accuracy: 0.5779\n",
      "Epoch 222/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4031 - accuracy: 0.6241 - val_loss: 5.3439 - val_accuracy: 0.5802\n",
      "Epoch 223/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4178 - accuracy: 0.6186 - val_loss: 5.0461 - val_accuracy: 0.5817\n",
      "Epoch 224/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3843 - accuracy: 0.6246 - val_loss: 4.9469 - val_accuracy: 0.6203\n",
      "Epoch 225/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3768 - accuracy: 0.6332 - val_loss: 5.0920 - val_accuracy: 0.5998\n",
      "Epoch 226/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3623 - accuracy: 0.6302 - val_loss: 5.2444 - val_accuracy: 0.5817\n",
      "Epoch 227/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2993 - accuracy: 0.6259 - val_loss: 5.3717 - val_accuracy: 0.5991\n",
      "Epoch 228/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4395 - accuracy: 0.6176 - val_loss: 5.3586 - val_accuracy: 0.5643\n",
      "Epoch 229/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3472 - accuracy: 0.6319 - val_loss: 5.3293 - val_accuracy: 0.5756\n",
      "Epoch 230/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3354 - accuracy: 0.6274 - val_loss: 5.0212 - val_accuracy: 0.5847\n",
      "Epoch 231/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3661 - accuracy: 0.6292 - val_loss: 5.1933 - val_accuracy: 0.5749\n",
      "Epoch 232/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3857 - accuracy: 0.6322 - val_loss: 5.0780 - val_accuracy: 0.5847\n",
      "Epoch 233/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2957 - accuracy: 0.6271 - val_loss: 5.1315 - val_accuracy: 0.6301\n",
      "Epoch 234/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3846 - accuracy: 0.6297 - val_loss: 5.2075 - val_accuracy: 0.5847\n",
      "Epoch 235/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4232 - accuracy: 0.6284 - val_loss: 5.1254 - val_accuracy: 0.6036\n",
      "Epoch 236/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3511 - accuracy: 0.6176 - val_loss: 5.0932 - val_accuracy: 0.5673\n",
      "Epoch 237/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3503 - accuracy: 0.6251 - val_loss: 5.1524 - val_accuracy: 0.5908\n",
      "Epoch 238/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3135 - accuracy: 0.6292 - val_loss: 5.1932 - val_accuracy: 0.5658\n",
      "Epoch 239/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3371 - accuracy: 0.6317 - val_loss: 5.0465 - val_accuracy: 0.5741\n",
      "Epoch 240/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2874 - accuracy: 0.6229 - val_loss: 5.1131 - val_accuracy: 0.6127\n",
      "Epoch 241/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.4582 - accuracy: 0.6231 - val_loss: 5.0936 - val_accuracy: 0.5779\n",
      "Epoch 242/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3051 - accuracy: 0.6302 - val_loss: 5.1755 - val_accuracy: 0.5908\n",
      "Epoch 243/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3255 - accuracy: 0.6319 - val_loss: 5.0357 - val_accuracy: 0.5946\n",
      "Epoch 244/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3191 - accuracy: 0.6329 - val_loss: 5.2178 - val_accuracy: 0.5749\n",
      "Epoch 245/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3504 - accuracy: 0.6231 - val_loss: 5.2777 - val_accuracy: 0.5923\n",
      "Epoch 246/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3691 - accuracy: 0.6287 - val_loss: 5.0581 - val_accuracy: 0.5703\n",
      "Epoch 247/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3176 - accuracy: 0.6254 - val_loss: 5.0774 - val_accuracy: 0.6263\n",
      "Epoch 248/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3698 - accuracy: 0.6201 - val_loss: 5.0862 - val_accuracy: 0.5968\n",
      "Epoch 249/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3165 - accuracy: 0.6304 - val_loss: 5.0734 - val_accuracy: 0.6074\n",
      "Epoch 250/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2838 - accuracy: 0.6324 - val_loss: 5.4930 - val_accuracy: 0.5703\n",
      "Epoch 251/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3650 - accuracy: 0.6292 - val_loss: 5.0209 - val_accuracy: 0.5877\n",
      "Epoch 252/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2857 - accuracy: 0.6420 - val_loss: 5.1261 - val_accuracy: 0.5885\n",
      "Epoch 253/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3090 - accuracy: 0.6375 - val_loss: 5.0677 - val_accuracy: 0.5915\n",
      "Epoch 254/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2439 - accuracy: 0.6345 - val_loss: 5.2208 - val_accuracy: 0.5681\n",
      "Epoch 255/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2945 - accuracy: 0.6400 - val_loss: 5.0161 - val_accuracy: 0.5885\n",
      "Epoch 256/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2798 - accuracy: 0.6390 - val_loss: 4.9769 - val_accuracy: 0.6021\n",
      "Epoch 257/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2886 - accuracy: 0.6314 - val_loss: 5.1628 - val_accuracy: 0.5847\n",
      "Epoch 258/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3121 - accuracy: 0.6193 - val_loss: 5.0576 - val_accuracy: 0.5817\n",
      "Epoch 259/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2543 - accuracy: 0.6350 - val_loss: 5.1437 - val_accuracy: 0.5749\n",
      "Epoch 260/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2377 - accuracy: 0.6335 - val_loss: 5.0775 - val_accuracy: 0.6021\n",
      "Epoch 261/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2465 - accuracy: 0.6435 - val_loss: 4.9991 - val_accuracy: 0.5696\n",
      "Epoch 262/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2474 - accuracy: 0.6324 - val_loss: 5.2857 - val_accuracy: 0.5953\n",
      "Epoch 263/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2397 - accuracy: 0.6322 - val_loss: 5.0204 - val_accuracy: 0.5930\n",
      "Epoch 264/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3333 - accuracy: 0.6350 - val_loss: 5.0143 - val_accuracy: 0.5923\n",
      "Epoch 265/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2818 - accuracy: 0.6218 - val_loss: 5.0365 - val_accuracy: 0.5953\n",
      "Epoch 266/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2152 - accuracy: 0.6327 - val_loss: 5.4796 - val_accuracy: 0.5492\n",
      "Epoch 267/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2571 - accuracy: 0.6425 - val_loss: 5.1082 - val_accuracy: 0.5666\n",
      "Epoch 268/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2878 - accuracy: 0.6393 - val_loss: 5.0842 - val_accuracy: 0.5719\n",
      "Epoch 269/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3458 - accuracy: 0.6259 - val_loss: 4.9595 - val_accuracy: 0.5847\n",
      "Epoch 270/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3074 - accuracy: 0.6322 - val_loss: 5.2297 - val_accuracy: 0.5741\n",
      "Epoch 271/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2121 - accuracy: 0.6370 - val_loss: 4.9860 - val_accuracy: 0.6104\n",
      "Epoch 272/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2767 - accuracy: 0.6370 - val_loss: 5.0677 - val_accuracy: 0.6014\n",
      "Epoch 273/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3341 - accuracy: 0.6274 - val_loss: 5.0473 - val_accuracy: 0.6127\n",
      "Epoch 274/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3043 - accuracy: 0.6350 - val_loss: 5.0526 - val_accuracy: 0.6120\n",
      "Epoch 275/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2671 - accuracy: 0.6297 - val_loss: 5.0192 - val_accuracy: 0.6021\n",
      "Epoch 276/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2100 - accuracy: 0.6335 - val_loss: 4.9745 - val_accuracy: 0.5983\n",
      "Epoch 277/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2537 - accuracy: 0.6314 - val_loss: 5.0485 - val_accuracy: 0.5809\n",
      "Epoch 278/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1874 - accuracy: 0.6385 - val_loss: 5.0432 - val_accuracy: 0.6150\n",
      "Epoch 279/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2079 - accuracy: 0.6423 - val_loss: 5.2826 - val_accuracy: 0.5847\n",
      "Epoch 280/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2544 - accuracy: 0.6438 - val_loss: 5.1558 - val_accuracy: 0.5877\n",
      "Epoch 281/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2481 - accuracy: 0.6340 - val_loss: 4.9891 - val_accuracy: 0.5658\n",
      "Epoch 282/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2361 - accuracy: 0.6393 - val_loss: 5.0673 - val_accuracy: 0.5893\n",
      "Epoch 283/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1708 - accuracy: 0.6471 - val_loss: 5.1392 - val_accuracy: 0.5673\n",
      "Epoch 284/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.3225 - accuracy: 0.6372 - val_loss: 5.1436 - val_accuracy: 0.5900\n",
      "Epoch 285/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3040 - accuracy: 0.6332 - val_loss: 5.1198 - val_accuracy: 0.5930\n",
      "Epoch 286/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1810 - accuracy: 0.6393 - val_loss: 4.9682 - val_accuracy: 0.6006\n",
      "Epoch 287/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2150 - accuracy: 0.6372 - val_loss: 5.0461 - val_accuracy: 0.5764\n",
      "Epoch 288/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1703 - accuracy: 0.6405 - val_loss: 5.2239 - val_accuracy: 0.5900\n",
      "Epoch 289/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3017 - accuracy: 0.6342 - val_loss: 5.0855 - val_accuracy: 0.6006\n",
      "Epoch 290/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2195 - accuracy: 0.6276 - val_loss: 5.0953 - val_accuracy: 0.6120\n",
      "Epoch 291/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.3191 - accuracy: 0.6292 - val_loss: 5.1240 - val_accuracy: 0.5507\n",
      "Epoch 292/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2073 - accuracy: 0.6302 - val_loss: 5.1540 - val_accuracy: 0.5741\n",
      "Epoch 293/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2208 - accuracy: 0.6309 - val_loss: 5.1052 - val_accuracy: 0.6074\n",
      "Epoch 294/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2806 - accuracy: 0.6345 - val_loss: 4.9747 - val_accuracy: 0.5681\n",
      "Epoch 295/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2345 - accuracy: 0.6244 - val_loss: 5.2469 - val_accuracy: 0.5930\n",
      "Epoch 296/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2477 - accuracy: 0.6400 - val_loss: 5.0367 - val_accuracy: 0.5855\n",
      "Epoch 297/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2454 - accuracy: 0.6357 - val_loss: 5.0033 - val_accuracy: 0.6082\n",
      "Epoch 298/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2341 - accuracy: 0.6289 - val_loss: 5.1068 - val_accuracy: 0.6195\n",
      "Epoch 299/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1498 - accuracy: 0.6453 - val_loss: 5.1203 - val_accuracy: 0.6248\n",
      "Epoch 300/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2069 - accuracy: 0.6382 - val_loss: 5.3569 - val_accuracy: 0.6051\n",
      "Epoch 301/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2136 - accuracy: 0.6269 - val_loss: 4.9604 - val_accuracy: 0.5809\n",
      "Epoch 302/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2816 - accuracy: 0.6246 - val_loss: 4.8552 - val_accuracy: 0.5998\n",
      "Epoch 303/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2283 - accuracy: 0.6327 - val_loss: 5.0815 - val_accuracy: 0.5961\n",
      "Epoch 304/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2120 - accuracy: 0.6395 - val_loss: 5.1575 - val_accuracy: 0.5961\n",
      "Epoch 305/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2980 - accuracy: 0.6420 - val_loss: 4.9692 - val_accuracy: 0.6195\n",
      "Epoch 306/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1245 - accuracy: 0.6448 - val_loss: 5.0306 - val_accuracy: 0.5946\n",
      "Epoch 307/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1420 - accuracy: 0.6451 - val_loss: 5.0634 - val_accuracy: 0.5719\n",
      "Epoch 308/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2210 - accuracy: 0.6425 - val_loss: 5.1787 - val_accuracy: 0.5817\n",
      "Epoch 309/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2582 - accuracy: 0.6261 - val_loss: 5.1305 - val_accuracy: 0.6036\n",
      "Epoch 310/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1445 - accuracy: 0.6458 - val_loss: 5.1082 - val_accuracy: 0.5877\n",
      "Epoch 311/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1531 - accuracy: 0.6324 - val_loss: 4.9142 - val_accuracy: 0.6172\n",
      "Epoch 312/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2513 - accuracy: 0.6324 - val_loss: 5.0180 - val_accuracy: 0.5953\n",
      "Epoch 313/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2375 - accuracy: 0.6352 - val_loss: 5.0613 - val_accuracy: 0.5681\n",
      "Epoch 314/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1221 - accuracy: 0.6317 - val_loss: 5.1689 - val_accuracy: 0.5666\n",
      "Epoch 315/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1809 - accuracy: 0.6271 - val_loss: 4.9189 - val_accuracy: 0.5983\n",
      "Epoch 316/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2074 - accuracy: 0.6367 - val_loss: 4.9362 - val_accuracy: 0.5802\n",
      "Epoch 317/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2336 - accuracy: 0.6297 - val_loss: 4.8777 - val_accuracy: 0.6165\n",
      "Epoch 318/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1588 - accuracy: 0.6471 - val_loss: 5.1274 - val_accuracy: 0.5756\n",
      "Epoch 319/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2443 - accuracy: 0.6375 - val_loss: 5.3077 - val_accuracy: 0.5764\n",
      "Epoch 320/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1968 - accuracy: 0.6405 - val_loss: 5.0318 - val_accuracy: 0.6036\n",
      "Epoch 321/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2711 - accuracy: 0.6410 - val_loss: 4.9600 - val_accuracy: 0.6188\n",
      "Epoch 322/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1612 - accuracy: 0.6357 - val_loss: 4.9146 - val_accuracy: 0.5719\n",
      "Epoch 323/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2209 - accuracy: 0.6451 - val_loss: 4.9776 - val_accuracy: 0.5764\n",
      "Epoch 324/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1512 - accuracy: 0.6382 - val_loss: 4.9044 - val_accuracy: 0.5923\n",
      "Epoch 325/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2287 - accuracy: 0.6284 - val_loss: 5.0871 - val_accuracy: 0.5772\n",
      "Epoch 326/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1704 - accuracy: 0.6453 - val_loss: 4.9982 - val_accuracy: 0.5885\n",
      "Epoch 327/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2310 - accuracy: 0.6377 - val_loss: 5.2818 - val_accuracy: 0.6014\n",
      "Epoch 328/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2080 - accuracy: 0.6327 - val_loss: 4.9101 - val_accuracy: 0.5938\n",
      "Epoch 329/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1323 - accuracy: 0.6413 - val_loss: 5.0219 - val_accuracy: 0.5938\n",
      "Epoch 330/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2248 - accuracy: 0.6360 - val_loss: 5.0330 - val_accuracy: 0.5734\n",
      "Epoch 331/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1060 - accuracy: 0.6405 - val_loss: 5.0954 - val_accuracy: 0.5741\n",
      "Epoch 332/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1525 - accuracy: 0.6423 - val_loss: 5.0844 - val_accuracy: 0.6036\n",
      "Epoch 333/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1611 - accuracy: 0.6372 - val_loss: 5.2335 - val_accuracy: 0.5635\n",
      "Epoch 334/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2281 - accuracy: 0.6385 - val_loss: 5.1161 - val_accuracy: 0.5938\n",
      "Epoch 335/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1587 - accuracy: 0.6329 - val_loss: 4.9460 - val_accuracy: 0.6074\n",
      "Epoch 336/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1727 - accuracy: 0.6423 - val_loss: 4.8117 - val_accuracy: 0.6188\n",
      "Epoch 337/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2548 - accuracy: 0.6433 - val_loss: 4.9978 - val_accuracy: 0.5870\n",
      "Epoch 338/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1894 - accuracy: 0.6395 - val_loss: 5.0316 - val_accuracy: 0.5499\n",
      "Epoch 339/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2499 - accuracy: 0.6319 - val_loss: 5.0846 - val_accuracy: 0.6029\n",
      "Epoch 340/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2103 - accuracy: 0.6332 - val_loss: 5.0352 - val_accuracy: 0.5998\n",
      "Epoch 341/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1719 - accuracy: 0.6352 - val_loss: 4.9455 - val_accuracy: 0.5998\n",
      "Epoch 342/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1441 - accuracy: 0.6481 - val_loss: 5.1029 - val_accuracy: 0.5817\n",
      "Epoch 343/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2090 - accuracy: 0.6352 - val_loss: 5.0245 - val_accuracy: 0.6210\n",
      "Epoch 344/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2110 - accuracy: 0.6367 - val_loss: 4.9951 - val_accuracy: 0.5840\n",
      "Epoch 345/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1553 - accuracy: 0.6387 - val_loss: 4.9042 - val_accuracy: 0.6044\n",
      "Epoch 346/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2123 - accuracy: 0.6375 - val_loss: 4.9056 - val_accuracy: 0.5809\n",
      "Epoch 347/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.0715 - accuracy: 0.6519 - val_loss: 4.9132 - val_accuracy: 0.6127\n",
      "Epoch 348/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1790 - accuracy: 0.6448 - val_loss: 4.8741 - val_accuracy: 0.5961\n",
      "Epoch 349/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2231 - accuracy: 0.6365 - val_loss: 4.8069 - val_accuracy: 0.6104\n",
      "Epoch 350/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2025 - accuracy: 0.6413 - val_loss: 4.9185 - val_accuracy: 0.5703\n",
      "Epoch 351/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1843 - accuracy: 0.6299 - val_loss: 4.9677 - val_accuracy: 0.6218\n",
      "Epoch 352/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2159 - accuracy: 0.6413 - val_loss: 5.0253 - val_accuracy: 0.5794\n",
      "Epoch 353/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2425 - accuracy: 0.6289 - val_loss: 4.9137 - val_accuracy: 0.5870\n",
      "Epoch 354/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1141 - accuracy: 0.6425 - val_loss: 4.8426 - val_accuracy: 0.5832\n",
      "Epoch 355/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1361 - accuracy: 0.6443 - val_loss: 4.9497 - val_accuracy: 0.5794\n",
      "Epoch 356/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1211 - accuracy: 0.6367 - val_loss: 4.8873 - val_accuracy: 0.6241\n",
      "Epoch 357/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2204 - accuracy: 0.6463 - val_loss: 4.7500 - val_accuracy: 0.6112\n",
      "Epoch 358/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1424 - accuracy: 0.6405 - val_loss: 5.2410 - val_accuracy: 0.6067\n",
      "Epoch 359/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1751 - accuracy: 0.6435 - val_loss: 4.9568 - val_accuracy: 0.5719\n",
      "Epoch 360/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2078 - accuracy: 0.6279 - val_loss: 5.0926 - val_accuracy: 0.5961\n",
      "Epoch 361/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1966 - accuracy: 0.6160 - val_loss: 5.1091 - val_accuracy: 0.6044\n",
      "Epoch 362/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2220 - accuracy: 0.6403 - val_loss: 5.2157 - val_accuracy: 0.6074\n",
      "Epoch 363/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1328 - accuracy: 0.6302 - val_loss: 4.9448 - val_accuracy: 0.5832\n",
      "Epoch 364/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2205 - accuracy: 0.6309 - val_loss: 5.1884 - val_accuracy: 0.5870\n",
      "Epoch 365/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0715 - accuracy: 0.6438 - val_loss: 4.9842 - val_accuracy: 0.5794\n",
      "Epoch 366/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2248 - accuracy: 0.6405 - val_loss: 4.9126 - val_accuracy: 0.6044\n",
      "Epoch 367/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.0593 - accuracy: 0.6476 - val_loss: 4.8829 - val_accuracy: 0.6188\n",
      "Epoch 368/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0778 - accuracy: 0.6428 - val_loss: 4.8604 - val_accuracy: 0.5779\n",
      "Epoch 369/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1592 - accuracy: 0.6425 - val_loss: 4.9793 - val_accuracy: 0.5847\n",
      "Epoch 370/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1193 - accuracy: 0.6410 - val_loss: 4.9248 - val_accuracy: 0.5991\n",
      "Epoch 371/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0926 - accuracy: 0.6425 - val_loss: 4.8098 - val_accuracy: 0.5877\n",
      "Epoch 372/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1385 - accuracy: 0.6415 - val_loss: 4.8686 - val_accuracy: 0.5923\n",
      "Epoch 373/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2001 - accuracy: 0.6440 - val_loss: 4.8850 - val_accuracy: 0.5877\n",
      "Epoch 374/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0433 - accuracy: 0.6433 - val_loss: 5.0047 - val_accuracy: 0.5961\n",
      "Epoch 375/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0905 - accuracy: 0.6370 - val_loss: 4.9405 - val_accuracy: 0.5764\n",
      "Epoch 376/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2093 - accuracy: 0.6274 - val_loss: 4.9598 - val_accuracy: 0.6120\n",
      "Epoch 377/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1235 - accuracy: 0.6413 - val_loss: 5.1785 - val_accuracy: 0.5696\n",
      "Epoch 378/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1741 - accuracy: 0.6322 - val_loss: 4.9129 - val_accuracy: 0.6135\n",
      "Epoch 379/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1586 - accuracy: 0.6473 - val_loss: 4.9945 - val_accuracy: 0.5825\n",
      "Epoch 380/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2233 - accuracy: 0.6350 - val_loss: 4.9958 - val_accuracy: 0.6021\n",
      "Epoch 381/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1042 - accuracy: 0.6428 - val_loss: 4.7902 - val_accuracy: 0.5893\n",
      "Epoch 382/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.2526 - accuracy: 0.6329 - val_loss: 4.9911 - val_accuracy: 0.5855\n",
      "Epoch 383/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1282 - accuracy: 0.6400 - val_loss: 4.8156 - val_accuracy: 0.6150\n",
      "Epoch 384/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.2304 - accuracy: 0.6340 - val_loss: 5.1174 - val_accuracy: 0.5401\n",
      "Epoch 385/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1533 - accuracy: 0.6375 - val_loss: 4.8673 - val_accuracy: 0.6021\n",
      "Epoch 386/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1861 - accuracy: 0.6319 - val_loss: 4.9352 - val_accuracy: 0.5930\n",
      "Epoch 387/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0862 - accuracy: 0.6451 - val_loss: 4.8634 - val_accuracy: 0.5961\n",
      "Epoch 388/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1229 - accuracy: 0.6395 - val_loss: 5.0445 - val_accuracy: 0.5893\n",
      "Epoch 389/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1501 - accuracy: 0.6420 - val_loss: 4.9574 - val_accuracy: 0.5847\n",
      "Epoch 390/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0767 - accuracy: 0.6582 - val_loss: 4.8070 - val_accuracy: 0.5968\n",
      "Epoch 391/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1287 - accuracy: 0.6410 - val_loss: 4.7762 - val_accuracy: 0.5908\n",
      "Epoch 392/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1304 - accuracy: 0.6375 - val_loss: 4.9148 - val_accuracy: 0.6029\n",
      "Epoch 393/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0463 - accuracy: 0.6415 - val_loss: 4.9585 - val_accuracy: 0.5772\n",
      "Epoch 394/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1894 - accuracy: 0.6307 - val_loss: 4.8464 - val_accuracy: 0.6271\n",
      "Epoch 395/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1573 - accuracy: 0.6551 - val_loss: 4.9894 - val_accuracy: 0.5877\n",
      "Epoch 396/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1544 - accuracy: 0.6428 - val_loss: 5.0215 - val_accuracy: 0.5817\n",
      "Epoch 397/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1103 - accuracy: 0.6446 - val_loss: 4.8036 - val_accuracy: 0.5915\n",
      "Epoch 398/400\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 4.1032 - accuracy: 0.6541 - val_loss: 4.9140 - val_accuracy: 0.5908\n",
      "Epoch 399/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.0799 - accuracy: 0.6415 - val_loss: 4.8739 - val_accuracy: 0.6097\n",
      "Epoch 400/400\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 4.1040 - accuracy: 0.6488 - val_loss: 4.8433 - val_accuracy: 0.6044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb4ab97ac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegnet_model.fit(X_train, y_train, epochs=400, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf31224e-020b-4ab0-af83-bac0f8f0a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = eegnet_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a4d3791-9b1d-48a6-a67c-b881a1fa1914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.513453 , 2.1303315, 3.3699455, 6.6792765],\n",
       "       [1.4406395, 1.3675815, 3.612165 , 8.771011 ],\n",
       "       [2.8439906, 0.7648113, 4.7138047, 6.329714 ],\n",
       "       ...,\n",
       "       [1.0801206, 7.467737 , 4.70571  , 2.194997 ],\n",
       "       [0.6254885, 4.672606 , 4.7438397, 4.7774506],\n",
       "       [1.7059238, 4.2302547, 4.8992476, 4.628483 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bc6cc3c-6eb5-44fe-90eb-f6217a7efb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  3,  9],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 1,  1,  8,  8],\n",
       "       ...,\n",
       "       [ 1,  9,  4,  1],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  5,  7,  1]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7b20c-f876-474e-a24b-76be17a0ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
