{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8b28ed-5843-4c45-a812-75c8d9203fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9046432b-e5a9-4354-80ea-e3bf7647fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3441d90b-4614-4f4b-870d-f087f6afa14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Boring</th>\n",
       "      <th>Horrible</th>\n",
       "      <th>Calm</th>\n",
       "      <th>Funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Boring  Horrible  Calm  Funny\n",
       "0        1       8         1     3      2\n",
       "1        1       2         1     8      8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_ica_folder = 'gameemo_database_epochs_ica'\n",
    "current_dir = epochs_ica_folder \n",
    "labels_path = 'GameLabels\\GAMEEMO_SCORES.xlsx'\n",
    "labels_sheet = 'All'\n",
    "labels_file = pd.read_excel(labels_path, labels_sheet)\n",
    "labels_file.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67274db-4bd7-49ed-a5ba-69cba4b26615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array = np.array(labels_file[['Boring', 'Horrible', 'Calm', 'Funny']])\n",
    "labels_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7584ea-7295-49fc-bafb-b6056ac1cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram as spg\n",
    "from scipy.signal import stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5d4dc3d-9a2c-46c7-b605-2df442e5ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sampling_rate = 128  # Adjust based on the actual sampling rate of your data\n",
    "nperseg = 32  # Number of samples per segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bed55a68-f17d-4260-b4dc-c8ab2acefbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stft(signal, sampling_rate, nperseg):\n",
    "    stft_matrices = []\n",
    "    for i in range(signal.shape[0]):  # Loop over each channel\n",
    "        f, t, Zxx = stft(signal[i, :], fs=sampling_rate, nperseg=nperseg)\n",
    "        stft_matrices.append(Zxx)\n",
    "    return f, t, np.stack(stft_matrices, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4709f73c-aefc-4975-b448-c18f8359990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = os.listdir(current_dir)[0]\n",
    "game = os.listdir(os.path.join(current_dir, subject))[0]\n",
    "epoch = os.listdir(os.path.join(current_dir, subject, game))[0]\n",
    "read_epoch = pd.read_csv(os.path.join(current_dir, subject, game, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53a9662b-e69f-4a13-8099-dcdb80aa0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 641)\n"
     ]
    }
   ],
   "source": [
    "read_epoch = read_epoch[channels].T.values\n",
    "print(read_epoch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f28b847e-8374-4f4e-a665-bb037b657ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, spectrogram = compute_stft(read_epoch, sampling_rate, nperseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c4411a5-a711-4038-be19-322d0e26d3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 42, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab1caba3-f6de-4683-b1c8-d31a59e2187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(np.abs(spectrogram[:, :, 1]), aspect='auto', cmap='viridis', origin='lower')\n",
    "plt.title(\"Spectrogram\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b13a6bb-f360-4821-bd1b-a19b4e13d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [01:12<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(current_dir)):\n",
    "    for game in os.listdir(os.path.join(current_dir, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(current_dir, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(current_dir, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T.values\n",
    "            f, t, spectrogram = compute_stft(read_epoch, sampling_rate, nperseg)\n",
    "            epochs_data.append(np.array(spectrogram))\n",
    "            labels_data.append(labels_array[k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4e1d7a0-9c38-471f-ab63-c9c6063aae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 42, 14) (4,)\n"
     ]
    }
   ],
   "source": [
    "print((epochs_data[0].shape), (labels_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b66f94bc-c7df-4bc0-a0ed-955087d01bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 17, 42, 14) (6608, 4)\n"
     ]
    }
   ],
   "source": [
    "main_data = np.array(epochs_data)\n",
    "main_labels = np.array(labels_data)\n",
    "print(main_data.shape, main_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7748a584-eb97-482e-b6e8-0fc4d7312b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 42\n"
     ]
    }
   ],
   "source": [
    "row_size = main_data.shape[1]\n",
    "col_size = main_data.shape[2]\n",
    "print(row_size, col_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40e07961-877f-4415-9172-c8f9f736e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3964, 17, 42, 14) (3964, 4)\n",
      "Validation set shape: (1322, 17, 42, 14) (1322, 4)\n",
      "Testing set shape: (1322, 17, 42, 14) (1322, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into training+validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(main_data, main_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e406a904-2ea7-44c1-b7c7-aef3894ede48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93a19aa5-639a-4c7a-941b-a021245da895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eb01bfd-de2a-498a-accc-4cda2bfbe1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def EEGNet(nb_classes = 4, Chans = 14, Samples = 129, \n",
    "#              dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "#              D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "def EEGNet(nb_classes = 4, Row_size = row_size, Col_size = col_size, Chans = 14, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input_main   = Input((row_size, col_size, Chans))\n",
    "    block1       = Conv2D(25, (5, 5), padding='same',\n",
    "                                 input_shape=(row_size, col_size, Chans),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    # block1       = Conv2D(25, (Chans, 1),\n",
    "    #                              kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (5, 5), padding='same',\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (5, 5), padding='same',\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (5, 5), padding='same',\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    # block4       = Conv2D(25, (Chans, 1),\n",
    "    #                              kernel_constraint = max_norm(2., axis=(0,1,2)))(block4)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    output      = Activation('linear')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c9c589f-2c16-4e41-8ba4-c4b1e37060bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model = EEGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc146516-c7bc-41d1-b50d-78b1fde01e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 17, 42, 14)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 17, 42, 25)        8775      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 17, 42, 25)       100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 17, 42, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 17, 42, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 17, 42, 25)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 42, 50)        31300     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 17, 42, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 17, 42, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 17, 42, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 42, 50)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 42, 100)       125100    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 17, 42, 100)      400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 17, 42, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 42, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 17, 42, 100)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 17, 42, 200)       500200    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 17, 42, 200)      800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 17, 42, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 17, 42, 200)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 17, 42, 200)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 142800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 571204    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,238,079\n",
      "Trainable params: 1,237,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eegnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36b327f8-ba48-4aec-8b98-f164e92adf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66a441c0-969e-486d-84f6-b3753f924242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "248/248 [==============================] - 9s 16ms/step - loss: 24.9779 - accuracy: 0.2921 - val_loss: 15.4615 - val_accuracy: 0.2504\n",
      "Epoch 2/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 12.9268 - accuracy: 0.2921 - val_loss: 12.6198 - val_accuracy: 0.2542\n",
      "Epoch 3/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 11.2072 - accuracy: 0.3136 - val_loss: 12.8290 - val_accuracy: 0.2436\n",
      "Epoch 4/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 9.3108 - accuracy: 0.3537 - val_loss: 10.1422 - val_accuracy: 0.2315\n",
      "Epoch 5/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 8.4012 - accuracy: 0.3671 - val_loss: 7.5045 - val_accuracy: 0.4070\n",
      "Epoch 6/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 7.6347 - accuracy: 0.4024 - val_loss: 9.0605 - val_accuracy: 0.3116\n",
      "Epoch 7/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 7.9302 - accuracy: 0.3925 - val_loss: 7.4299 - val_accuracy: 0.4319\n",
      "Epoch 8/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 7.8079 - accuracy: 0.3993 - val_loss: 9.5282 - val_accuracy: 0.2927\n",
      "Epoch 9/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 7.4753 - accuracy: 0.4049 - val_loss: 7.2483 - val_accuracy: 0.4387\n",
      "Epoch 10/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 7.1620 - accuracy: 0.4344 - val_loss: 7.1046 - val_accuracy: 0.4357\n",
      "Epoch 11/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.9939 - accuracy: 0.4402 - val_loss: 8.5605 - val_accuracy: 0.4160\n",
      "Epoch 12/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 7.0509 - accuracy: 0.4420 - val_loss: 6.9909 - val_accuracy: 0.4312\n",
      "Epoch 13/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.7489 - accuracy: 0.4594 - val_loss: 6.8031 - val_accuracy: 0.4418\n",
      "Epoch 14/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.6674 - accuracy: 0.4594 - val_loss: 6.2923 - val_accuracy: 0.4879\n",
      "Epoch 15/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.6856 - accuracy: 0.4508 - val_loss: 6.5705 - val_accuracy: 0.3956\n",
      "Epoch 16/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.6212 - accuracy: 0.4695 - val_loss: 6.4988 - val_accuracy: 0.4879\n",
      "Epoch 17/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.4439 - accuracy: 0.4649 - val_loss: 6.4027 - val_accuracy: 0.5083\n",
      "Epoch 18/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 6.3769 - accuracy: 0.4892 - val_loss: 5.8792 - val_accuracy: 0.5227\n",
      "Epoch 19/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.3950 - accuracy: 0.4773 - val_loss: 6.0793 - val_accuracy: 0.4909\n",
      "Epoch 20/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.2608 - accuracy: 0.4919 - val_loss: 5.8982 - val_accuracy: 0.4947\n",
      "Epoch 21/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.3725 - accuracy: 0.4808 - val_loss: 5.8656 - val_accuracy: 0.5356\n",
      "Epoch 22/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.3264 - accuracy: 0.4793 - val_loss: 6.0301 - val_accuracy: 0.5008\n",
      "Epoch 23/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 6.2120 - accuracy: 0.4934 - val_loss: 6.7401 - val_accuracy: 0.5136\n",
      "Epoch 24/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.3532 - accuracy: 0.4826 - val_loss: 6.1298 - val_accuracy: 0.4879\n",
      "Epoch 25/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.1669 - accuracy: 0.4881 - val_loss: 5.8862 - val_accuracy: 0.5363\n",
      "Epoch 26/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 6.1740 - accuracy: 0.4821 - val_loss: 5.9579 - val_accuracy: 0.5499\n",
      "Epoch 27/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 6.1995 - accuracy: 0.4861 - val_loss: 6.7483 - val_accuracy: 0.5015\n",
      "Epoch 28/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 6.0887 - accuracy: 0.5048 - val_loss: 6.1710 - val_accuracy: 0.4947\n",
      "Epoch 29/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.3918 - accuracy: 0.4902 - val_loss: 5.5234 - val_accuracy: 0.5401\n",
      "Epoch 30/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.1048 - accuracy: 0.4955 - val_loss: 5.5415 - val_accuracy: 0.5356\n",
      "Epoch 31/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.0207 - accuracy: 0.4922 - val_loss: 5.6880 - val_accuracy: 0.4985\n",
      "Epoch 32/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.1735 - accuracy: 0.4841 - val_loss: 5.7299 - val_accuracy: 0.5318\n",
      "Epoch 33/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 6.0149 - accuracy: 0.4955 - val_loss: 5.8464 - val_accuracy: 0.4796\n",
      "Epoch 34/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.9277 - accuracy: 0.5023 - val_loss: 5.5133 - val_accuracy: 0.5424\n",
      "Epoch 35/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.9383 - accuracy: 0.5003 - val_loss: 5.4094 - val_accuracy: 0.5144\n",
      "Epoch 36/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.9663 - accuracy: 0.4929 - val_loss: 5.4387 - val_accuracy: 0.5106\n",
      "Epoch 37/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.9065 - accuracy: 0.4904 - val_loss: 5.5879 - val_accuracy: 0.5401\n",
      "Epoch 38/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.8660 - accuracy: 0.5013 - val_loss: 5.5411 - val_accuracy: 0.5340\n",
      "Epoch 39/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.8853 - accuracy: 0.5025 - val_loss: 6.3565 - val_accuracy: 0.5295\n",
      "Epoch 40/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.8643 - accuracy: 0.5050 - val_loss: 5.3984 - val_accuracy: 0.4856\n",
      "Epoch 41/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.7984 - accuracy: 0.5066 - val_loss: 5.7709 - val_accuracy: 0.5439\n",
      "Epoch 42/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.9166 - accuracy: 0.4980 - val_loss: 5.3825 - val_accuracy: 0.5257\n",
      "Epoch 43/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.8545 - accuracy: 0.5045 - val_loss: 5.5747 - val_accuracy: 0.4493\n",
      "Epoch 44/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.8049 - accuracy: 0.5058 - val_loss: 5.2353 - val_accuracy: 0.5234\n",
      "Epoch 45/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.7913 - accuracy: 0.5068 - val_loss: 5.6999 - val_accuracy: 0.5250\n",
      "Epoch 46/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.7669 - accuracy: 0.4962 - val_loss: 5.7811 - val_accuracy: 0.5333\n",
      "Epoch 47/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.8509 - accuracy: 0.5076 - val_loss: 5.3969 - val_accuracy: 0.5106\n",
      "Epoch 48/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.7519 - accuracy: 0.5129 - val_loss: 5.4372 - val_accuracy: 0.5492\n",
      "Epoch 49/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.7405 - accuracy: 0.5139 - val_loss: 5.5938 - val_accuracy: 0.4750\n",
      "Epoch 50/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.6440 - accuracy: 0.5003 - val_loss: 6.0826 - val_accuracy: 0.4690\n",
      "Epoch 51/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.6840 - accuracy: 0.4992 - val_loss: 5.7772 - val_accuracy: 0.5174\n",
      "Epoch 52/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.7172 - accuracy: 0.5055 - val_loss: 5.4677 - val_accuracy: 0.5545\n",
      "Epoch 53/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.6621 - accuracy: 0.5106 - val_loss: 5.5324 - val_accuracy: 0.5106\n",
      "Epoch 54/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.6042 - accuracy: 0.5134 - val_loss: 5.6300 - val_accuracy: 0.5522\n",
      "Epoch 55/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.6444 - accuracy: 0.5096 - val_loss: 5.2187 - val_accuracy: 0.5711\n",
      "Epoch 56/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.5995 - accuracy: 0.5038 - val_loss: 5.5122 - val_accuracy: 0.5530\n",
      "Epoch 57/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.6319 - accuracy: 0.5091 - val_loss: 5.1832 - val_accuracy: 0.4992\n",
      "Epoch 58/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.5619 - accuracy: 0.5179 - val_loss: 5.3846 - val_accuracy: 0.5136\n",
      "Epoch 59/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.5436 - accuracy: 0.5164 - val_loss: 5.2490 - val_accuracy: 0.5514\n",
      "Epoch 60/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.4405 - accuracy: 0.5169 - val_loss: 5.2466 - val_accuracy: 0.5401\n",
      "Epoch 61/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.4636 - accuracy: 0.5126 - val_loss: 5.1521 - val_accuracy: 0.5204\n",
      "Epoch 62/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.3276 - accuracy: 0.5141 - val_loss: 5.0881 - val_accuracy: 0.5454\n",
      "Epoch 63/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.3377 - accuracy: 0.5161 - val_loss: 5.3809 - val_accuracy: 0.5310\n",
      "Epoch 64/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.3195 - accuracy: 0.5144 - val_loss: 4.8445 - val_accuracy: 0.5552\n",
      "Epoch 65/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.3476 - accuracy: 0.5219 - val_loss: 4.7509 - val_accuracy: 0.5295\n",
      "Epoch 66/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.1888 - accuracy: 0.5214 - val_loss: 5.0421 - val_accuracy: 0.5378\n",
      "Epoch 67/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.1232 - accuracy: 0.5308 - val_loss: 5.6492 - val_accuracy: 0.5068\n",
      "Epoch 68/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 5.0791 - accuracy: 0.5272 - val_loss: 5.2765 - val_accuracy: 0.4864\n",
      "Epoch 69/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 5.1329 - accuracy: 0.5366 - val_loss: 4.8305 - val_accuracy: 0.5393\n",
      "Epoch 70/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.9477 - accuracy: 0.5477 - val_loss: 4.5724 - val_accuracy: 0.5794\n",
      "Epoch 71/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 4.9476 - accuracy: 0.5588 - val_loss: 5.1357 - val_accuracy: 0.5454\n",
      "Epoch 72/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.8081 - accuracy: 0.5537 - val_loss: 4.2965 - val_accuracy: 0.5953\n",
      "Epoch 73/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.7033 - accuracy: 0.5727 - val_loss: 4.5863 - val_accuracy: 0.5719\n",
      "Epoch 74/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.6274 - accuracy: 0.5817 - val_loss: 4.5578 - val_accuracy: 0.5862\n",
      "Epoch 75/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.5918 - accuracy: 0.5855 - val_loss: 3.9188 - val_accuracy: 0.5658\n",
      "Epoch 76/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 4.3890 - accuracy: 0.5923 - val_loss: 4.1193 - val_accuracy: 0.5915\n",
      "Epoch 77/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.3206 - accuracy: 0.6070 - val_loss: 4.0569 - val_accuracy: 0.6248\n",
      "Epoch 78/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.3425 - accuracy: 0.5941 - val_loss: 3.8176 - val_accuracy: 0.6067\n",
      "Epoch 79/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.2803 - accuracy: 0.5994 - val_loss: 3.6461 - val_accuracy: 0.6225\n",
      "Epoch 80/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 4.0942 - accuracy: 0.6065 - val_loss: 3.9565 - val_accuracy: 0.6755\n",
      "Epoch 81/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 4.0097 - accuracy: 0.6279 - val_loss: 3.1503 - val_accuracy: 0.6589\n",
      "Epoch 82/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.9585 - accuracy: 0.6193 - val_loss: 3.4268 - val_accuracy: 0.6589\n",
      "Epoch 83/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.9025 - accuracy: 0.6264 - val_loss: 3.6514 - val_accuracy: 0.5446\n",
      "Epoch 84/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.8875 - accuracy: 0.6191 - val_loss: 5.5681 - val_accuracy: 0.6392\n",
      "Epoch 85/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.7547 - accuracy: 0.6259 - val_loss: 3.2808 - val_accuracy: 0.6082\n",
      "Epoch 86/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.8583 - accuracy: 0.6289 - val_loss: 4.3627 - val_accuracy: 0.6944\n",
      "Epoch 87/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.7625 - accuracy: 0.6428 - val_loss: 3.9444 - val_accuracy: 0.6210\n",
      "Epoch 88/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.6535 - accuracy: 0.6355 - val_loss: 3.0615 - val_accuracy: 0.6006\n",
      "Epoch 89/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.7372 - accuracy: 0.6317 - val_loss: 3.4829 - val_accuracy: 0.6899\n",
      "Epoch 90/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.6846 - accuracy: 0.6324 - val_loss: 3.7331 - val_accuracy: 0.5582\n",
      "Epoch 91/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.5538 - accuracy: 0.6476 - val_loss: 5.1016 - val_accuracy: 0.6059\n",
      "Epoch 92/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.4433 - accuracy: 0.6501 - val_loss: 5.3468 - val_accuracy: 0.5900\n",
      "Epoch 93/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.5465 - accuracy: 0.6458 - val_loss: 2.7751 - val_accuracy: 0.6793\n",
      "Epoch 94/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.4026 - accuracy: 0.6506 - val_loss: 3.7646 - val_accuracy: 0.6914\n",
      "Epoch 95/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.3471 - accuracy: 0.6584 - val_loss: 3.3877 - val_accuracy: 0.6785\n",
      "Epoch 96/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.4448 - accuracy: 0.6519 - val_loss: 5.7542 - val_accuracy: 0.6006\n",
      "Epoch 97/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.3146 - accuracy: 0.6564 - val_loss: 2.4026 - val_accuracy: 0.6520\n",
      "Epoch 98/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.5301 - accuracy: 0.6526 - val_loss: 2.8859 - val_accuracy: 0.7088\n",
      "Epoch 99/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.3123 - accuracy: 0.6544 - val_loss: 2.9442 - val_accuracy: 0.6944\n",
      "Epoch 100/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.2546 - accuracy: 0.6642 - val_loss: 4.3481 - val_accuracy: 0.5461\n",
      "Epoch 101/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.2447 - accuracy: 0.6620 - val_loss: 3.0155 - val_accuracy: 0.6891\n",
      "Epoch 102/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.1927 - accuracy: 0.6481 - val_loss: 3.1060 - val_accuracy: 0.5840\n",
      "Epoch 103/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.2911 - accuracy: 0.6572 - val_loss: 2.8009 - val_accuracy: 0.6589\n",
      "Epoch 104/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.0971 - accuracy: 0.6731 - val_loss: 2.3895 - val_accuracy: 0.7020\n",
      "Epoch 105/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 3.1434 - accuracy: 0.6673 - val_loss: 2.5813 - val_accuracy: 0.6982\n",
      "Epoch 106/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.2182 - accuracy: 0.6718 - val_loss: 2.8639 - val_accuracy: 0.6399\n",
      "Epoch 107/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.1505 - accuracy: 0.6673 - val_loss: 2.4581 - val_accuracy: 0.6467\n",
      "Epoch 108/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.0835 - accuracy: 0.6786 - val_loss: 2.4900 - val_accuracy: 0.7118\n",
      "Epoch 109/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.1143 - accuracy: 0.6688 - val_loss: 2.8088 - val_accuracy: 0.6324\n",
      "Epoch 110/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.0393 - accuracy: 0.6809 - val_loss: 3.1346 - val_accuracy: 0.7678\n",
      "Epoch 111/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9916 - accuracy: 0.6821 - val_loss: 2.1157 - val_accuracy: 0.7670\n",
      "Epoch 112/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.2126 - accuracy: 0.6758 - val_loss: 2.5178 - val_accuracy: 0.6399\n",
      "Epoch 113/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9798 - accuracy: 0.6872 - val_loss: 3.0431 - val_accuracy: 0.6989\n",
      "Epoch 114/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.0960 - accuracy: 0.6766 - val_loss: 2.6064 - val_accuracy: 0.6573\n",
      "Epoch 115/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.0073 - accuracy: 0.6842 - val_loss: 2.5117 - val_accuracy: 0.7080\n",
      "Epoch 116/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9744 - accuracy: 0.6824 - val_loss: 2.6570 - val_accuracy: 0.7300\n",
      "Epoch 117/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.0241 - accuracy: 0.6852 - val_loss: 2.9320 - val_accuracy: 0.7587\n",
      "Epoch 118/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 3.0995 - accuracy: 0.6781 - val_loss: 5.1886 - val_accuracy: 0.5144\n",
      "Epoch 119/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.8843 - accuracy: 0.6948 - val_loss: 3.3544 - val_accuracy: 0.5847\n",
      "Epoch 120/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9286 - accuracy: 0.6897 - val_loss: 3.3832 - val_accuracy: 0.5847\n",
      "Epoch 121/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9189 - accuracy: 0.6900 - val_loss: 2.5398 - val_accuracy: 0.6808\n",
      "Epoch 122/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.8230 - accuracy: 0.6930 - val_loss: 2.9237 - val_accuracy: 0.5961\n",
      "Epoch 123/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9693 - accuracy: 0.6849 - val_loss: 2.4068 - val_accuracy: 0.7632\n",
      "Epoch 124/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.0523 - accuracy: 0.6867 - val_loss: 2.2489 - val_accuracy: 0.6437\n",
      "Epoch 125/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9320 - accuracy: 0.6917 - val_loss: 3.1758 - val_accuracy: 0.7806\n",
      "Epoch 126/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.8915 - accuracy: 0.6900 - val_loss: 2.5873 - val_accuracy: 0.7648\n",
      "Epoch 127/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.9268 - accuracy: 0.6826 - val_loss: 2.2288 - val_accuracy: 0.6770\n",
      "Epoch 128/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 3.0037 - accuracy: 0.6922 - val_loss: 2.4708 - val_accuracy: 0.7663\n",
      "Epoch 129/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.8204 - accuracy: 0.6958 - val_loss: 2.5559 - val_accuracy: 0.7345\n",
      "Epoch 130/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.8198 - accuracy: 0.6985 - val_loss: 2.6186 - val_accuracy: 0.6475\n",
      "Epoch 131/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.8260 - accuracy: 0.6993 - val_loss: 2.0061 - val_accuracy: 0.7405\n",
      "Epoch 132/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.7736 - accuracy: 0.6937 - val_loss: 2.8504 - val_accuracy: 0.6989\n",
      "Epoch 133/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.7798 - accuracy: 0.7011 - val_loss: 2.7756 - val_accuracy: 0.6838\n",
      "Epoch 134/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.7820 - accuracy: 0.7018 - val_loss: 2.3305 - val_accuracy: 0.7579\n",
      "Epoch 135/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.7462 - accuracy: 0.7023 - val_loss: 2.5197 - val_accuracy: 0.6831\n",
      "Epoch 136/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.7425 - accuracy: 0.6978 - val_loss: 2.4689 - val_accuracy: 0.7027\n",
      "Epoch 137/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6951 - accuracy: 0.7101 - val_loss: 2.5689 - val_accuracy: 0.7685\n",
      "Epoch 138/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6896 - accuracy: 0.7096 - val_loss: 2.6430 - val_accuracy: 0.6346\n",
      "Epoch 139/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.7663 - accuracy: 0.7031 - val_loss: 2.2408 - val_accuracy: 0.7595\n",
      "Epoch 140/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.7673 - accuracy: 0.7048 - val_loss: 2.4629 - val_accuracy: 0.6982\n",
      "Epoch 141/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6504 - accuracy: 0.7106 - val_loss: 3.1982 - val_accuracy: 0.5923\n",
      "Epoch 142/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.7329 - accuracy: 0.7028 - val_loss: 2.5727 - val_accuracy: 0.7890\n",
      "Epoch 143/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6842 - accuracy: 0.7114 - val_loss: 2.5667 - val_accuracy: 0.7829\n",
      "Epoch 144/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6570 - accuracy: 0.7031 - val_loss: 3.6948 - val_accuracy: 0.6921\n",
      "Epoch 145/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6818 - accuracy: 0.7124 - val_loss: 2.0716 - val_accuracy: 0.6929\n",
      "Epoch 146/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.7053 - accuracy: 0.7096 - val_loss: 2.1247 - val_accuracy: 0.6770\n",
      "Epoch 147/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6700 - accuracy: 0.7124 - val_loss: 2.4179 - val_accuracy: 0.8079\n",
      "Epoch 148/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.7865 - accuracy: 0.7159 - val_loss: 2.3688 - val_accuracy: 0.7352\n",
      "Epoch 149/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6404 - accuracy: 0.7154 - val_loss: 2.5195 - val_accuracy: 0.8192\n",
      "Epoch 150/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6285 - accuracy: 0.7086 - val_loss: 2.4626 - val_accuracy: 0.5908\n",
      "Epoch 151/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.7407 - accuracy: 0.6993 - val_loss: 2.1170 - val_accuracy: 0.6475\n",
      "Epoch 152/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6230 - accuracy: 0.7281 - val_loss: 1.9672 - val_accuracy: 0.6725\n",
      "Epoch 153/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6046 - accuracy: 0.7281 - val_loss: 2.8452 - val_accuracy: 0.6551\n",
      "Epoch 154/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.5959 - accuracy: 0.7278 - val_loss: 2.7473 - val_accuracy: 0.6172\n",
      "Epoch 155/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6681 - accuracy: 0.7142 - val_loss: 2.4334 - val_accuracy: 0.6362\n",
      "Epoch 156/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6274 - accuracy: 0.7205 - val_loss: 1.8717 - val_accuracy: 0.7292\n",
      "Epoch 157/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.6389 - accuracy: 0.7245 - val_loss: 2.2621 - val_accuracy: 0.8464\n",
      "Epoch 158/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.6381 - accuracy: 0.7217 - val_loss: 2.2646 - val_accuracy: 0.7610\n",
      "Epoch 159/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.5519 - accuracy: 0.7240 - val_loss: 2.2667 - val_accuracy: 0.7602\n",
      "Epoch 160/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.5801 - accuracy: 0.7308 - val_loss: 2.5694 - val_accuracy: 0.7337\n",
      "Epoch 161/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4266 - accuracy: 0.7301 - val_loss: 2.1866 - val_accuracy: 0.6657\n",
      "Epoch 162/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4383 - accuracy: 0.7273 - val_loss: 1.7298 - val_accuracy: 0.7519\n",
      "Epoch 163/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.5232 - accuracy: 0.7250 - val_loss: 1.8269 - val_accuracy: 0.7935\n",
      "Epoch 164/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.5280 - accuracy: 0.7273 - val_loss: 3.0195 - val_accuracy: 0.5968\n",
      "Epoch 165/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.5245 - accuracy: 0.7293 - val_loss: 2.7412 - val_accuracy: 0.7368\n",
      "Epoch 166/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4642 - accuracy: 0.7293 - val_loss: 2.4304 - val_accuracy: 0.6944\n",
      "Epoch 167/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.5275 - accuracy: 0.7255 - val_loss: 2.0836 - val_accuracy: 0.7194\n",
      "Epoch 168/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4378 - accuracy: 0.7253 - val_loss: 1.9624 - val_accuracy: 0.8003\n",
      "Epoch 169/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.5036 - accuracy: 0.7248 - val_loss: 2.1250 - val_accuracy: 0.6293\n",
      "Epoch 170/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3792 - accuracy: 0.7356 - val_loss: 1.9468 - val_accuracy: 0.7564\n",
      "Epoch 171/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4283 - accuracy: 0.7298 - val_loss: 2.2043 - val_accuracy: 0.8396\n",
      "Epoch 172/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4447 - accuracy: 0.7298 - val_loss: 1.9660 - val_accuracy: 0.8222\n",
      "Epoch 173/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4447 - accuracy: 0.7281 - val_loss: 1.8425 - val_accuracy: 0.8396\n",
      "Epoch 174/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3716 - accuracy: 0.7409 - val_loss: 2.1738 - val_accuracy: 0.7057\n",
      "Epoch 175/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3625 - accuracy: 0.7341 - val_loss: 2.6603 - val_accuracy: 0.6369\n",
      "Epoch 176/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.5200 - accuracy: 0.7293 - val_loss: 2.3077 - val_accuracy: 0.7821\n",
      "Epoch 177/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4557 - accuracy: 0.7351 - val_loss: 1.9109 - val_accuracy: 0.7481\n",
      "Epoch 178/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4376 - accuracy: 0.7283 - val_loss: 2.3531 - val_accuracy: 0.6921\n",
      "Epoch 179/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3592 - accuracy: 0.7447 - val_loss: 3.0333 - val_accuracy: 0.6520\n",
      "Epoch 180/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4437 - accuracy: 0.7334 - val_loss: 3.7780 - val_accuracy: 0.5764\n",
      "Epoch 181/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.5243 - accuracy: 0.7235 - val_loss: 2.5794 - val_accuracy: 0.6422\n",
      "Epoch 182/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4031 - accuracy: 0.7384 - val_loss: 2.8860 - val_accuracy: 0.7216\n",
      "Epoch 183/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3778 - accuracy: 0.7404 - val_loss: 1.9656 - val_accuracy: 0.7284\n",
      "Epoch 184/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4392 - accuracy: 0.7321 - val_loss: 3.1192 - val_accuracy: 0.6165\n",
      "Epoch 185/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4458 - accuracy: 0.7318 - val_loss: 1.7643 - val_accuracy: 0.6679\n",
      "Epoch 186/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3344 - accuracy: 0.7467 - val_loss: 3.0849 - val_accuracy: 0.7579\n",
      "Epoch 187/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3239 - accuracy: 0.7381 - val_loss: 2.4332 - val_accuracy: 0.5840\n",
      "Epoch 188/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4296 - accuracy: 0.7351 - val_loss: 1.8965 - val_accuracy: 0.7685\n",
      "Epoch 189/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3481 - accuracy: 0.7404 - val_loss: 3.0341 - val_accuracy: 0.5862\n",
      "Epoch 190/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3345 - accuracy: 0.7392 - val_loss: 2.4303 - val_accuracy: 0.7791\n",
      "Epoch 191/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3913 - accuracy: 0.7442 - val_loss: 2.8401 - val_accuracy: 0.7799\n",
      "Epoch 192/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3567 - accuracy: 0.7419 - val_loss: 1.9034 - val_accuracy: 0.7458\n",
      "Epoch 193/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3138 - accuracy: 0.7366 - val_loss: 1.7963 - val_accuracy: 0.7958\n",
      "Epoch 194/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3101 - accuracy: 0.7482 - val_loss: 2.1476 - val_accuracy: 0.6452\n",
      "Epoch 195/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3868 - accuracy: 0.7369 - val_loss: 2.2532 - val_accuracy: 0.7557\n",
      "Epoch 196/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2614 - accuracy: 0.7407 - val_loss: 1.9690 - val_accuracy: 0.8502\n",
      "Epoch 197/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3276 - accuracy: 0.7394 - val_loss: 2.5314 - val_accuracy: 0.6452\n",
      "Epoch 198/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3096 - accuracy: 0.7392 - val_loss: 2.4237 - val_accuracy: 0.7708\n",
      "Epoch 199/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2884 - accuracy: 0.7533 - val_loss: 2.0027 - val_accuracy: 0.7375\n",
      "Epoch 200/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.3708 - accuracy: 0.7417 - val_loss: 1.5414 - val_accuracy: 0.7481\n",
      "Epoch 201/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3274 - accuracy: 0.7376 - val_loss: 2.0162 - val_accuracy: 0.8071\n",
      "Epoch 202/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3979 - accuracy: 0.7475 - val_loss: 4.9698 - val_accuracy: 0.5756\n",
      "Epoch 203/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3976 - accuracy: 0.7417 - val_loss: 1.9090 - val_accuracy: 0.7254\n",
      "Epoch 204/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2511 - accuracy: 0.7414 - val_loss: 4.0405 - val_accuracy: 0.6520\n",
      "Epoch 205/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2969 - accuracy: 0.7563 - val_loss: 1.5482 - val_accuracy: 0.7504\n",
      "Epoch 206/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3084 - accuracy: 0.7500 - val_loss: 5.0873 - val_accuracy: 0.6029\n",
      "Epoch 207/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3007 - accuracy: 0.7419 - val_loss: 1.9257 - val_accuracy: 0.7973\n",
      "Epoch 208/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3317 - accuracy: 0.7447 - val_loss: 2.8690 - val_accuracy: 0.7466\n",
      "Epoch 209/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3836 - accuracy: 0.7500 - val_loss: 2.0003 - val_accuracy: 0.7610\n",
      "Epoch 210/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2499 - accuracy: 0.7462 - val_loss: 1.6312 - val_accuracy: 0.7602\n",
      "Epoch 211/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4134 - accuracy: 0.7429 - val_loss: 1.8363 - val_accuracy: 0.7352\n",
      "Epoch 212/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2761 - accuracy: 0.7450 - val_loss: 1.6280 - val_accuracy: 0.7905\n",
      "Epoch 213/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3193 - accuracy: 0.7470 - val_loss: 2.3825 - val_accuracy: 0.6672\n",
      "Epoch 214/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3077 - accuracy: 0.7422 - val_loss: 3.7474 - val_accuracy: 0.5182\n",
      "Epoch 215/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1904 - accuracy: 0.7591 - val_loss: 1.8828 - val_accuracy: 0.7065\n",
      "Epoch 216/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3093 - accuracy: 0.7545 - val_loss: 2.8159 - val_accuracy: 0.6997\n",
      "Epoch 217/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2555 - accuracy: 0.7591 - val_loss: 1.4989 - val_accuracy: 0.8132\n",
      "Epoch 218/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.4419 - accuracy: 0.7379 - val_loss: 2.2497 - val_accuracy: 0.6452\n",
      "Epoch 219/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2884 - accuracy: 0.7500 - val_loss: 2.5749 - val_accuracy: 0.6490\n",
      "Epoch 220/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2392 - accuracy: 0.7571 - val_loss: 1.9115 - val_accuracy: 0.7905\n",
      "Epoch 221/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1712 - accuracy: 0.7573 - val_loss: 1.6278 - val_accuracy: 0.7466\n",
      "Epoch 222/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2779 - accuracy: 0.7442 - val_loss: 2.4673 - val_accuracy: 0.7693\n",
      "Epoch 223/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1775 - accuracy: 0.7543 - val_loss: 2.6653 - val_accuracy: 0.7035\n",
      "Epoch 224/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3481 - accuracy: 0.7462 - val_loss: 2.1012 - val_accuracy: 0.7057\n",
      "Epoch 225/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2653 - accuracy: 0.7553 - val_loss: 1.8197 - val_accuracy: 0.8124\n",
      "Epoch 226/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2875 - accuracy: 0.7626 - val_loss: 2.2075 - val_accuracy: 0.8033\n",
      "Epoch 227/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2812 - accuracy: 0.7608 - val_loss: 2.3824 - val_accuracy: 0.6074\n",
      "Epoch 228/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1930 - accuracy: 0.7598 - val_loss: 2.1125 - val_accuracy: 0.7617\n",
      "Epoch 229/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2946 - accuracy: 0.7513 - val_loss: 1.9784 - val_accuracy: 0.8139\n",
      "Epoch 230/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2278 - accuracy: 0.7714 - val_loss: 3.0829 - val_accuracy: 0.6906\n",
      "Epoch 231/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2342 - accuracy: 0.7689 - val_loss: 2.0557 - val_accuracy: 0.7428\n",
      "Epoch 232/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1880 - accuracy: 0.7666 - val_loss: 2.5698 - val_accuracy: 0.7300\n",
      "Epoch 233/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2525 - accuracy: 0.7614 - val_loss: 1.9812 - val_accuracy: 0.6445\n",
      "Epoch 234/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1490 - accuracy: 0.7629 - val_loss: 2.3690 - val_accuracy: 0.7413\n",
      "Epoch 235/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2023 - accuracy: 0.7634 - val_loss: 1.7999 - val_accuracy: 0.8124\n",
      "Epoch 236/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1839 - accuracy: 0.7586 - val_loss: 3.4410 - val_accuracy: 0.6286\n",
      "Epoch 237/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2300 - accuracy: 0.7568 - val_loss: 1.8115 - val_accuracy: 0.7542\n",
      "Epoch 238/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2063 - accuracy: 0.7636 - val_loss: 2.8010 - val_accuracy: 0.7806\n",
      "Epoch 239/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1493 - accuracy: 0.7661 - val_loss: 2.7324 - val_accuracy: 0.6725\n",
      "Epoch 240/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2917 - accuracy: 0.7482 - val_loss: 2.3395 - val_accuracy: 0.6150\n",
      "Epoch 241/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3222 - accuracy: 0.7518 - val_loss: 1.9390 - val_accuracy: 0.8533\n",
      "Epoch 242/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2095 - accuracy: 0.7588 - val_loss: 2.6802 - val_accuracy: 0.5719\n",
      "Epoch 243/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1690 - accuracy: 0.7626 - val_loss: 1.7389 - val_accuracy: 0.7254\n",
      "Epoch 244/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.3782 - accuracy: 0.7581 - val_loss: 2.9204 - val_accuracy: 0.5877\n",
      "Epoch 245/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2487 - accuracy: 0.7576 - val_loss: 1.9913 - val_accuracy: 0.7443\n",
      "Epoch 246/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1668 - accuracy: 0.7621 - val_loss: 4.3077 - val_accuracy: 0.6369\n",
      "Epoch 247/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1113 - accuracy: 0.7725 - val_loss: 2.5822 - val_accuracy: 0.7988\n",
      "Epoch 248/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1234 - accuracy: 0.7694 - val_loss: 1.7800 - val_accuracy: 0.8003\n",
      "Epoch 249/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2198 - accuracy: 0.7659 - val_loss: 1.8893 - val_accuracy: 0.7897\n",
      "Epoch 250/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2896 - accuracy: 0.7571 - val_loss: 1.9016 - val_accuracy: 0.7156\n",
      "Epoch 251/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0729 - accuracy: 0.7669 - val_loss: 1.4649 - val_accuracy: 0.7912\n",
      "Epoch 252/400\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 2.2017 - accuracy: 0.7634 - val_loss: 1.8682 - val_accuracy: 0.8056\n",
      "Epoch 253/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1645 - accuracy: 0.7750 - val_loss: 1.9894 - val_accuracy: 0.7118\n",
      "Epoch 254/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1438 - accuracy: 0.7656 - val_loss: 3.1264 - val_accuracy: 0.7133\n",
      "Epoch 255/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1236 - accuracy: 0.7619 - val_loss: 1.6233 - val_accuracy: 0.7829\n",
      "Epoch 256/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1884 - accuracy: 0.7730 - val_loss: 1.9827 - val_accuracy: 0.7239\n",
      "Epoch 257/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.2893 - accuracy: 0.7482 - val_loss: 1.7389 - val_accuracy: 0.8154\n",
      "Epoch 258/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1687 - accuracy: 0.7737 - val_loss: 2.1137 - val_accuracy: 0.8351\n",
      "Epoch 259/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2420 - accuracy: 0.7621 - val_loss: 2.1288 - val_accuracy: 0.6710\n",
      "Epoch 260/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0901 - accuracy: 0.7740 - val_loss: 1.8823 - val_accuracy: 0.8253\n",
      "Epoch 261/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2977 - accuracy: 0.7611 - val_loss: 2.1859 - val_accuracy: 0.6679\n",
      "Epoch 262/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2601 - accuracy: 0.7606 - val_loss: 1.5990 - val_accuracy: 0.7307\n",
      "Epoch 263/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1818 - accuracy: 0.7664 - val_loss: 2.1749 - val_accuracy: 0.7307\n",
      "Epoch 264/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2470 - accuracy: 0.7621 - val_loss: 1.4910 - val_accuracy: 0.8419\n",
      "Epoch 265/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0758 - accuracy: 0.7760 - val_loss: 2.2203 - val_accuracy: 0.8048\n",
      "Epoch 266/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1830 - accuracy: 0.7757 - val_loss: 1.6909 - val_accuracy: 0.7844\n",
      "Epoch 267/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2327 - accuracy: 0.7568 - val_loss: 2.1686 - val_accuracy: 0.7912\n",
      "Epoch 268/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1071 - accuracy: 0.7737 - val_loss: 1.9156 - val_accuracy: 0.7179\n",
      "Epoch 269/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1336 - accuracy: 0.7672 - val_loss: 2.1214 - val_accuracy: 0.6210\n",
      "Epoch 270/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1317 - accuracy: 0.7770 - val_loss: 4.3118 - val_accuracy: 0.5605\n",
      "Epoch 271/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0715 - accuracy: 0.7697 - val_loss: 1.9541 - val_accuracy: 0.7897\n",
      "Epoch 272/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1107 - accuracy: 0.7775 - val_loss: 1.6947 - val_accuracy: 0.7852\n",
      "Epoch 273/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0997 - accuracy: 0.7692 - val_loss: 2.4348 - val_accuracy: 0.6997\n",
      "Epoch 274/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1388 - accuracy: 0.7682 - val_loss: 1.7816 - val_accuracy: 0.7814\n",
      "Epoch 275/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1170 - accuracy: 0.7737 - val_loss: 2.7689 - val_accuracy: 0.6263\n",
      "Epoch 276/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2398 - accuracy: 0.7644 - val_loss: 1.8220 - val_accuracy: 0.6437\n",
      "Epoch 277/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0552 - accuracy: 0.7745 - val_loss: 2.6570 - val_accuracy: 0.5711\n",
      "Epoch 278/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1309 - accuracy: 0.7684 - val_loss: 2.1263 - val_accuracy: 0.7814\n",
      "Epoch 279/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1968 - accuracy: 0.7666 - val_loss: 1.9793 - val_accuracy: 0.8018\n",
      "Epoch 280/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0915 - accuracy: 0.7752 - val_loss: 2.0574 - val_accuracy: 0.7602\n",
      "Epoch 281/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0674 - accuracy: 0.7780 - val_loss: 3.0162 - val_accuracy: 0.5673\n",
      "Epoch 282/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0672 - accuracy: 0.7702 - val_loss: 1.6733 - val_accuracy: 0.8638\n",
      "Epoch 283/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1084 - accuracy: 0.7752 - val_loss: 1.6056 - val_accuracy: 0.7557\n",
      "Epoch 284/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1343 - accuracy: 0.7750 - val_loss: 2.5505 - val_accuracy: 0.6649\n",
      "Epoch 285/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0782 - accuracy: 0.7712 - val_loss: 2.3099 - val_accuracy: 0.7927\n",
      "Epoch 286/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1030 - accuracy: 0.7828 - val_loss: 1.9781 - val_accuracy: 0.8563\n",
      "Epoch 287/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0774 - accuracy: 0.7762 - val_loss: 1.4427 - val_accuracy: 0.9009\n",
      "Epoch 288/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1574 - accuracy: 0.7770 - val_loss: 2.1214 - val_accuracy: 0.6339\n",
      "Epoch 289/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0901 - accuracy: 0.7775 - val_loss: 1.9000 - val_accuracy: 0.8230\n",
      "Epoch 290/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1146 - accuracy: 0.7709 - val_loss: 1.9430 - val_accuracy: 0.7988\n",
      "Epoch 291/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1131 - accuracy: 0.7687 - val_loss: 2.0952 - val_accuracy: 0.5764\n",
      "Epoch 292/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1810 - accuracy: 0.7631 - val_loss: 1.5472 - val_accuracy: 0.8396\n",
      "Epoch 293/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0593 - accuracy: 0.7780 - val_loss: 1.5394 - val_accuracy: 0.7436\n",
      "Epoch 294/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0653 - accuracy: 0.7780 - val_loss: 1.6213 - val_accuracy: 0.8154\n",
      "Epoch 295/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1121 - accuracy: 0.7719 - val_loss: 1.9539 - val_accuracy: 0.7012\n",
      "Epoch 296/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1444 - accuracy: 0.7732 - val_loss: 3.3554 - val_accuracy: 0.6112\n",
      "Epoch 297/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.4009 - accuracy: 0.7568 - val_loss: 2.9265 - val_accuracy: 0.7693\n",
      "Epoch 298/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0479 - accuracy: 0.7682 - val_loss: 2.7252 - val_accuracy: 0.5998\n",
      "Epoch 299/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0855 - accuracy: 0.7725 - val_loss: 2.7662 - val_accuracy: 0.7474\n",
      "Epoch 300/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3516 - accuracy: 0.7689 - val_loss: 3.6056 - val_accuracy: 0.5983\n",
      "Epoch 301/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0516 - accuracy: 0.7714 - val_loss: 1.9789 - val_accuracy: 0.6649\n",
      "Epoch 302/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.2075 - accuracy: 0.7846 - val_loss: 3.8956 - val_accuracy: 0.6558\n",
      "Epoch 303/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1941 - accuracy: 0.7762 - val_loss: 6.5311 - val_accuracy: 0.5983\n",
      "Epoch 304/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1287 - accuracy: 0.7772 - val_loss: 2.0653 - val_accuracy: 0.7534\n",
      "Epoch 305/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0986 - accuracy: 0.7793 - val_loss: 1.9973 - val_accuracy: 0.7284\n",
      "Epoch 306/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1032 - accuracy: 0.7747 - val_loss: 2.1680 - val_accuracy: 0.8026\n",
      "Epoch 307/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0701 - accuracy: 0.7838 - val_loss: 1.8049 - val_accuracy: 0.7595\n",
      "Epoch 308/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1493 - accuracy: 0.7765 - val_loss: 2.8639 - val_accuracy: 0.6808\n",
      "Epoch 309/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0626 - accuracy: 0.7767 - val_loss: 1.4300 - val_accuracy: 0.8971\n",
      "Epoch 310/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1254 - accuracy: 0.7747 - val_loss: 2.1859 - val_accuracy: 0.7950\n",
      "Epoch 311/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0071 - accuracy: 0.7868 - val_loss: 2.3818 - val_accuracy: 0.6558\n",
      "Epoch 312/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0192 - accuracy: 0.7788 - val_loss: 2.6066 - val_accuracy: 0.7761\n",
      "Epoch 313/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1081 - accuracy: 0.7805 - val_loss: 1.9218 - val_accuracy: 0.7458\n",
      "Epoch 314/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1361 - accuracy: 0.7709 - val_loss: 1.4518 - val_accuracy: 0.7980\n",
      "Epoch 315/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1191 - accuracy: 0.7760 - val_loss: 2.4587 - val_accuracy: 0.7012\n",
      "Epoch 316/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0381 - accuracy: 0.7853 - val_loss: 2.2395 - val_accuracy: 0.6626\n",
      "Epoch 317/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2590 - accuracy: 0.7694 - val_loss: 3.5548 - val_accuracy: 0.6036\n",
      "Epoch 318/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0191 - accuracy: 0.7815 - val_loss: 1.8148 - val_accuracy: 0.8517\n",
      "Epoch 319/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0067 - accuracy: 0.7866 - val_loss: 1.9452 - val_accuracy: 0.7375\n",
      "Epoch 320/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.3096 - accuracy: 0.7674 - val_loss: 3.9544 - val_accuracy: 0.5772\n",
      "Epoch 321/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2158 - accuracy: 0.7651 - val_loss: 1.5971 - val_accuracy: 0.7322\n",
      "Epoch 322/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0616 - accuracy: 0.7828 - val_loss: 1.5002 - val_accuracy: 0.7005\n",
      "Epoch 323/400\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 2.1057 - accuracy: 0.7722 - val_loss: 1.5367 - val_accuracy: 0.8880\n",
      "Epoch 324/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0811 - accuracy: 0.7830 - val_loss: 1.5875 - val_accuracy: 0.8343\n",
      "Epoch 325/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0313 - accuracy: 0.7825 - val_loss: 2.6415 - val_accuracy: 0.5772\n",
      "Epoch 326/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1391 - accuracy: 0.7790 - val_loss: 1.3944 - val_accuracy: 0.8109\n",
      "Epoch 327/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0395 - accuracy: 0.7830 - val_loss: 2.1095 - val_accuracy: 0.7390\n",
      "Epoch 328/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1033 - accuracy: 0.7820 - val_loss: 2.0590 - val_accuracy: 0.8192\n",
      "Epoch 329/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0922 - accuracy: 0.7772 - val_loss: 1.8764 - val_accuracy: 0.7995\n",
      "Epoch 330/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0550 - accuracy: 0.7803 - val_loss: 2.4449 - val_accuracy: 0.7126\n",
      "Epoch 331/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9703 - accuracy: 0.7876 - val_loss: 1.6250 - val_accuracy: 0.7799\n",
      "Epoch 332/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0826 - accuracy: 0.7714 - val_loss: 1.7311 - val_accuracy: 0.8200\n",
      "Epoch 333/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0210 - accuracy: 0.7846 - val_loss: 1.6862 - val_accuracy: 0.7489\n",
      "Epoch 334/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1196 - accuracy: 0.7813 - val_loss: 2.0760 - val_accuracy: 0.7708\n",
      "Epoch 335/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0575 - accuracy: 0.7873 - val_loss: 2.2645 - val_accuracy: 0.7716\n",
      "Epoch 336/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0930 - accuracy: 0.7740 - val_loss: 3.0902 - val_accuracy: 0.7065\n",
      "Epoch 337/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.1418 - accuracy: 0.7712 - val_loss: 2.4477 - val_accuracy: 0.8079\n",
      "Epoch 338/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0515 - accuracy: 0.7755 - val_loss: 1.6591 - val_accuracy: 0.7852\n",
      "Epoch 339/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0662 - accuracy: 0.7793 - val_loss: 1.4524 - val_accuracy: 0.7587\n",
      "Epoch 340/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0828 - accuracy: 0.7795 - val_loss: 3.9920 - val_accuracy: 0.7481\n",
      "Epoch 341/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0614 - accuracy: 0.7737 - val_loss: 1.8731 - val_accuracy: 0.7345\n",
      "Epoch 342/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0197 - accuracy: 0.7861 - val_loss: 1.6885 - val_accuracy: 0.8230\n",
      "Epoch 343/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0505 - accuracy: 0.7838 - val_loss: 3.0084 - val_accuracy: 0.6785\n",
      "Epoch 344/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0969 - accuracy: 0.7752 - val_loss: 1.7913 - val_accuracy: 0.8026\n",
      "Epoch 345/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1768 - accuracy: 0.7899 - val_loss: 2.0389 - val_accuracy: 0.6097\n",
      "Epoch 346/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1438 - accuracy: 0.7770 - val_loss: 2.4179 - val_accuracy: 0.8722\n",
      "Epoch 347/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1345 - accuracy: 0.7841 - val_loss: 1.5909 - val_accuracy: 0.8487\n",
      "Epoch 348/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9803 - accuracy: 0.7833 - val_loss: 2.2581 - val_accuracy: 0.6581\n",
      "Epoch 349/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0543 - accuracy: 0.7805 - val_loss: 1.8540 - val_accuracy: 0.6808\n",
      "Epoch 350/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0455 - accuracy: 0.7818 - val_loss: 3.0321 - val_accuracy: 0.5961\n",
      "Epoch 351/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0384 - accuracy: 0.7871 - val_loss: 2.0478 - val_accuracy: 0.6823\n",
      "Epoch 352/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0351 - accuracy: 0.7770 - val_loss: 2.4582 - val_accuracy: 0.6346\n",
      "Epoch 353/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 1.9595 - accuracy: 0.7866 - val_loss: 2.0072 - val_accuracy: 0.7534\n",
      "Epoch 354/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2469 - accuracy: 0.7745 - val_loss: 2.3867 - val_accuracy: 0.7322\n",
      "Epoch 355/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0277 - accuracy: 0.7919 - val_loss: 2.1248 - val_accuracy: 0.8336\n",
      "Epoch 356/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0459 - accuracy: 0.7848 - val_loss: 4.0141 - val_accuracy: 0.5613\n",
      "Epoch 357/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1515 - accuracy: 0.7687 - val_loss: 2.6348 - val_accuracy: 0.6293\n",
      "Epoch 358/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1698 - accuracy: 0.7704 - val_loss: 1.4720 - val_accuracy: 0.8608\n",
      "Epoch 359/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.1404 - accuracy: 0.7767 - val_loss: 1.6099 - val_accuracy: 0.8381\n",
      "Epoch 360/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1124 - accuracy: 0.7742 - val_loss: 1.8618 - val_accuracy: 0.7474\n",
      "Epoch 361/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.2666 - accuracy: 0.7692 - val_loss: 1.5666 - val_accuracy: 0.7663\n",
      "Epoch 362/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0260 - accuracy: 0.7856 - val_loss: 1.3959 - val_accuracy: 0.8094\n",
      "Epoch 363/400\n",
      "248/248 [==============================] - 3s 13ms/step - loss: 2.0376 - accuracy: 0.7901 - val_loss: 2.1175 - val_accuracy: 0.8691\n",
      "Epoch 364/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9721 - accuracy: 0.7858 - val_loss: 1.4058 - val_accuracy: 0.8775\n",
      "Epoch 365/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0262 - accuracy: 0.7871 - val_loss: 1.5433 - val_accuracy: 0.8109\n",
      "Epoch 366/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0459 - accuracy: 0.7924 - val_loss: 1.6046 - val_accuracy: 0.7950\n",
      "Epoch 367/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.8784 - accuracy: 0.7931 - val_loss: 1.9872 - val_accuracy: 0.8306\n",
      "Epoch 368/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0124 - accuracy: 0.7916 - val_loss: 1.5798 - val_accuracy: 0.8177\n",
      "Epoch 369/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1232 - accuracy: 0.7793 - val_loss: 1.6349 - val_accuracy: 0.7973\n",
      "Epoch 370/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0400 - accuracy: 0.7836 - val_loss: 1.6338 - val_accuracy: 0.8041\n",
      "Epoch 371/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0575 - accuracy: 0.7838 - val_loss: 1.5219 - val_accuracy: 0.7670\n",
      "Epoch 372/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1893 - accuracy: 0.7770 - val_loss: 1.3991 - val_accuracy: 0.7791\n",
      "Epoch 373/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0952 - accuracy: 0.7740 - val_loss: 1.8982 - val_accuracy: 0.7352\n",
      "Epoch 374/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1597 - accuracy: 0.7803 - val_loss: 1.4269 - val_accuracy: 0.8971\n",
      "Epoch 375/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0677 - accuracy: 0.7883 - val_loss: 1.5737 - val_accuracy: 0.8396\n",
      "Epoch 376/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0252 - accuracy: 0.7856 - val_loss: 2.9467 - val_accuracy: 0.6611\n",
      "Epoch 377/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1070 - accuracy: 0.7795 - val_loss: 1.8571 - val_accuracy: 0.7519\n",
      "Epoch 378/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9703 - accuracy: 0.7914 - val_loss: 1.8361 - val_accuracy: 0.7867\n",
      "Epoch 379/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.1261 - accuracy: 0.7828 - val_loss: 2.2011 - val_accuracy: 0.7519\n",
      "Epoch 380/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0651 - accuracy: 0.7876 - val_loss: 1.5680 - val_accuracy: 0.8147\n",
      "Epoch 381/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0130 - accuracy: 0.7899 - val_loss: 1.2663 - val_accuracy: 0.7277\n",
      "Epoch 382/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1641 - accuracy: 0.7719 - val_loss: 1.6981 - val_accuracy: 0.7398\n",
      "Epoch 383/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9669 - accuracy: 0.8012 - val_loss: 1.7603 - val_accuracy: 0.7821\n",
      "Epoch 384/400\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 2.0133 - accuracy: 0.7901 - val_loss: 1.8766 - val_accuracy: 0.7526\n",
      "Epoch 385/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0818 - accuracy: 0.7772 - val_loss: 2.3627 - val_accuracy: 0.8669\n",
      "Epoch 386/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0728 - accuracy: 0.7785 - val_loss: 2.6801 - val_accuracy: 0.6362\n",
      "Epoch 387/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9324 - accuracy: 0.7843 - val_loss: 3.1970 - val_accuracy: 0.7027\n",
      "Epoch 388/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1763 - accuracy: 0.7765 - val_loss: 1.8733 - val_accuracy: 0.6959\n",
      "Epoch 389/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0416 - accuracy: 0.7785 - val_loss: 1.4644 - val_accuracy: 0.8684\n",
      "Epoch 390/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0959 - accuracy: 0.7858 - val_loss: 1.7409 - val_accuracy: 0.8601\n",
      "Epoch 391/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0167 - accuracy: 0.7818 - val_loss: 1.3908 - val_accuracy: 0.8873\n",
      "Epoch 392/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1629 - accuracy: 0.7747 - val_loss: 1.9814 - val_accuracy: 0.7958\n",
      "Epoch 393/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 2.0270 - accuracy: 0.7843 - val_loss: 3.7901 - val_accuracy: 0.5658\n",
      "Epoch 394/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0870 - accuracy: 0.7730 - val_loss: 1.9358 - val_accuracy: 0.7110\n",
      "Epoch 395/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9942 - accuracy: 0.7841 - val_loss: 1.7801 - val_accuracy: 0.7678\n",
      "Epoch 396/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.0343 - accuracy: 0.7770 - val_loss: 1.4471 - val_accuracy: 0.8238\n",
      "Epoch 397/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9900 - accuracy: 0.7969 - val_loss: 1.4444 - val_accuracy: 0.7368\n",
      "Epoch 398/400\n",
      "248/248 [==============================] - 4s 14ms/step - loss: 1.9862 - accuracy: 0.7967 - val_loss: 2.1918 - val_accuracy: 0.7020\n",
      "Epoch 399/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 1.9294 - accuracy: 0.7919 - val_loss: 1.6804 - val_accuracy: 0.7640\n",
      "Epoch 400/400\n",
      "248/248 [==============================] - 3s 14ms/step - loss: 2.1128 - accuracy: 0.7745 - val_loss: 1.4036 - val_accuracy: 0.7746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f895a7d6f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegnet_model.fit(X_train, y_train, epochs=400, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57fbc32a-5d49-4ee9-a58d-eb476d7e32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = eegnet_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "492a2a4d-a83a-481d-b1eb-ce63d5f3844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8654947,  0.7841759,  3.84122  ,  8.139906 ],\n",
       "       [ 1.7992768,  2.7712681,  2.3457184,  6.6799164],\n",
       "       [ 1.5766071,  1.2346979,  6.673357 ,  7.4622793],\n",
       "       ...,\n",
       "       [ 1.6672094,  7.6444197,  3.1600943,  2.7504466],\n",
       "       [ 0.8327694, 10.569219 ,  2.362435 ,  1.0083494],\n",
       "       [ 1.3457086,  7.071151 ,  5.1842628,  2.5765576]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9970e24-c274-475e-a914-d91d01d05881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  3,  9],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 1,  1,  8,  8],\n",
       "       ...,\n",
       "       [ 1,  9,  4,  1],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  5,  7,  1]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac0983-f5e5-4fde-a5b3-fe376ef5c88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
