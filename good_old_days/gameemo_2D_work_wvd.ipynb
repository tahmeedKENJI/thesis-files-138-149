{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8b28ed-5843-4c45-a812-75c8d9203fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9046432b-e5a9-4354-80ea-e3bf7647fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3441d90b-4614-4f4b-870d-f087f6afa14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Boring</th>\n",
       "      <th>Horrible</th>\n",
       "      <th>Calm</th>\n",
       "      <th>Funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Boring  Horrible  Calm  Funny\n",
       "0        1       8         1     3      2\n",
       "1        1       2         1     8      8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_ica_folder = 'gameemo_database_epochs_ica'\n",
    "current_dir = epochs_ica_folder \n",
    "labels_path = 'GameLabels\\GAMEEMO_SCORES.xlsx'\n",
    "labels_sheet = 'All'\n",
    "labels_file = pd.read_excel(labels_path, labels_sheet)\n",
    "labels_file.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67274db-4bd7-49ed-a5ba-69cba4b26615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array = np.array(labels_file[['Boring', 'Horrible', 'Calm', 'Funny']])\n",
    "labels_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7584ea-7295-49fc-bafb-b6056ac1cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram as spg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d4dc3d-9a2c-46c7-b605-2df442e5ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sampling_rate = 128  # Adjust based on the actual sampling rate of your data\n",
    "nperseg = 32  # Number of samples per segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed55a68-f17d-4260-b4dc-c8ab2acefbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the spectrogram for selected channels using WVD\n",
    "def compute_spectrogram_wvd(signal, sampling_rate):\n",
    "    spectrograms = []\n",
    "    for i in range(signal.shape[0]):  # Loop over each channel\n",
    "        f, t, Sxx = spg(signal[i, :], fs=sampling_rate, nperseg=nperseg, mode='complex')\n",
    "        spectrograms.append(Sxx)\n",
    "    return f, t, np.stack(spectrograms, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4709f73c-aefc-4975-b448-c18f8359990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = os.listdir(current_dir)[0]\n",
    "game = os.listdir(os.path.join(current_dir, subject))[0]\n",
    "epoch = os.listdir(os.path.join(current_dir, subject, game))[0]\n",
    "read_epoch = pd.read_csv(os.path.join(current_dir, subject, game, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a9662b-e69f-4a13-8099-dcdb80aa0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 641)\n"
     ]
    }
   ],
   "source": [
    "read_epoch = read_epoch[channels].T.values\n",
    "print(read_epoch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28b847e-8374-4f4e-a665-bb037b657ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, spectrogram = compute_spectrogram_wvd(read_epoch, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4411a5-a711-4038-be19-322d0e26d3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 22, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1caba3-f6de-4683-b1c8-d31a59e2187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(np.abs(spectrogram[:, :, 1]), aspect='auto', cmap='viridis', origin='lower')\n",
    "plt.title(\"Spectrogram\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b13a6bb-f360-4821-bd1b-a19b4e13d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:56<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(current_dir)):\n",
    "    for game in os.listdir(os.path.join(current_dir, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(current_dir, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(current_dir, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T.values\n",
    "            f, t, spectrogram = compute_spectrogram_wvd(read_epoch, sampling_rate)\n",
    "            epochs_data.append(np.array(spectrogram))\n",
    "            labels_data.append(labels_array[k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4e1d7a0-9c38-471f-ab63-c9c6063aae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 22, 14) (4,)\n"
     ]
    }
   ],
   "source": [
    "print((epochs_data[0].shape), (labels_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66f94bc-c7df-4bc0-a0ed-955087d01bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 17, 22, 14) (6608, 4)\n"
     ]
    }
   ],
   "source": [
    "main_data = np.array(epochs_data)\n",
    "main_labels = np.array(labels_data)\n",
    "print(main_data.shape, main_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7748a584-eb97-482e-b6e8-0fc4d7312b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 22\n"
     ]
    }
   ],
   "source": [
    "row_size = main_data.shape[1]\n",
    "col_size = main_data.shape[2]\n",
    "print(row_size, col_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e07961-877f-4415-9172-c8f9f736e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3964, 17, 22, 14) (3964, 4)\n",
      "Validation set shape: (1322, 17, 22, 14) (1322, 4)\n",
      "Testing set shape: (1322, 17, 22, 14) (1322, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into training+validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(main_data, main_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e406a904-2ea7-44c1-b7c7-aef3894ede48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a19aa5-639a-4c7a-941b-a021245da895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb01bfd-de2a-498a-accc-4cda2bfbe1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def EEGNet(nb_classes = 4, Chans = 14, Samples = 129, \n",
    "#              dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "#              D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "def EEGNet(nb_classes = 4, Row_size = row_size, Col_size = col_size, Chans = 14, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input_main   = Input((row_size, col_size, Chans))\n",
    "    block1       = Conv2D(25, (5, 5), padding='same',\n",
    "                                 input_shape=(row_size, col_size, Chans),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    # block1       = Conv2D(25, (Chans, 1),\n",
    "    #                              kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (5, 5), padding='same',\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (5, 5), padding='same',\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (5, 5), padding='same',\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    # block4       = Conv2D(25, (Chans, 1),\n",
    "    #                              kernel_constraint = max_norm(2., axis=(0,1,2)))(block4)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(2, 2), padding='same',strides=(1, 1))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    output      = Activation('linear')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c9c589f-2c16-4e41-8ba4-c4b1e37060bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model = EEGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc146516-c7bc-41d1-b50d-78b1fde01e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 17, 22, 14)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 17, 22, 25)        8775      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 17, 22, 25)       100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 17, 22, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 17, 22, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 17, 22, 25)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 22, 50)        31300     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 17, 22, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 17, 22, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 17, 22, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 22, 50)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 22, 100)       125100    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 17, 22, 100)      400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 17, 22, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 22, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 17, 22, 100)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 17, 22, 200)       500200    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 17, 22, 200)      800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 17, 22, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 17, 22, 200)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 17, 22, 200)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 74800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 299204    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 966,079\n",
      "Trainable params: 965,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eegnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36b327f8-ba48-4aec-8b98-f164e92adf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a441c0-969e-486d-84f6-b3753f924242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "248/248 [==============================] - 7s 13ms/step - loss: 13.9351 - accuracy: 0.2863 - val_loss: 15.2207 - val_accuracy: 0.2027\n",
      "Epoch 2/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 10.7920 - accuracy: 0.2886 - val_loss: 9.5890 - val_accuracy: 0.3487\n",
      "Epoch 3/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 8.4549 - accuracy: 0.3449 - val_loss: 8.0595 - val_accuracy: 0.3949\n",
      "Epoch 4/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 7.7241 - accuracy: 0.3867 - val_loss: 8.3247 - val_accuracy: 0.3517\n",
      "Epoch 5/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 7.4637 - accuracy: 0.3993 - val_loss: 7.4780 - val_accuracy: 0.3631\n",
      "Epoch 6/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 7.3645 - accuracy: 0.4135 - val_loss: 7.2804 - val_accuracy: 0.4236\n",
      "Epoch 7/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 7.1736 - accuracy: 0.4279 - val_loss: 6.9397 - val_accuracy: 0.4017\n",
      "Epoch 8/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.8849 - accuracy: 0.4352 - val_loss: 6.8490 - val_accuracy: 0.4009\n",
      "Epoch 9/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 7.0322 - accuracy: 0.4301 - val_loss: 6.6703 - val_accuracy: 0.4743\n",
      "Epoch 10/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.8063 - accuracy: 0.4445 - val_loss: 6.4207 - val_accuracy: 0.4773\n",
      "Epoch 11/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.7006 - accuracy: 0.4516 - val_loss: 7.0633 - val_accuracy: 0.4879\n",
      "Epoch 12/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.6137 - accuracy: 0.4586 - val_loss: 6.4027 - val_accuracy: 0.4697\n",
      "Epoch 13/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.6423 - accuracy: 0.4531 - val_loss: 6.3548 - val_accuracy: 0.4357\n",
      "Epoch 14/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.5811 - accuracy: 0.4609 - val_loss: 6.5572 - val_accuracy: 0.4561\n",
      "Epoch 15/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.4312 - accuracy: 0.4639 - val_loss: 5.9649 - val_accuracy: 0.4342\n",
      "Epoch 16/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.4695 - accuracy: 0.4622 - val_loss: 5.8598 - val_accuracy: 0.5303\n",
      "Epoch 17/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.2846 - accuracy: 0.4806 - val_loss: 7.1123 - val_accuracy: 0.4728\n",
      "Epoch 18/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.7610 - accuracy: 0.4569 - val_loss: 5.8408 - val_accuracy: 0.5038\n",
      "Epoch 19/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 6.1543 - accuracy: 0.4783 - val_loss: 5.7386 - val_accuracy: 0.5113\n",
      "Epoch 20/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.1379 - accuracy: 0.4750 - val_loss: 6.7358 - val_accuracy: 0.3782\n",
      "Epoch 21/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.2071 - accuracy: 0.4763 - val_loss: 5.7418 - val_accuracy: 0.4682\n",
      "Epoch 22/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.0763 - accuracy: 0.4927 - val_loss: 6.4811 - val_accuracy: 0.5015\n",
      "Epoch 23/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.1636 - accuracy: 0.4831 - val_loss: 7.9103 - val_accuracy: 0.4032\n",
      "Epoch 24/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.0731 - accuracy: 0.4886 - val_loss: 5.7719 - val_accuracy: 0.4622\n",
      "Epoch 25/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.0441 - accuracy: 0.4960 - val_loss: 6.5361 - val_accuracy: 0.5393\n",
      "Epoch 26/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 10.0930 - accuracy: 0.4844 - val_loss: 12.2596 - val_accuracy: 0.3540\n",
      "Epoch 27/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 7.0267 - accuracy: 0.4450 - val_loss: 6.4107 - val_accuracy: 0.4841\n",
      "Epoch 28/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.3427 - accuracy: 0.4748 - val_loss: 5.8204 - val_accuracy: 0.4433\n",
      "Epoch 29/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.4135 - accuracy: 0.4783 - val_loss: 6.4953 - val_accuracy: 0.4100\n",
      "Epoch 30/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.0780 - accuracy: 0.4904 - val_loss: 5.5244 - val_accuracy: 0.4894\n",
      "Epoch 31/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.0153 - accuracy: 0.4836 - val_loss: 5.9675 - val_accuracy: 0.4955\n",
      "Epoch 32/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.9424 - accuracy: 0.4917 - val_loss: 5.5684 - val_accuracy: 0.5416\n",
      "Epoch 33/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.9511 - accuracy: 0.4902 - val_loss: 5.6691 - val_accuracy: 0.5257\n",
      "Epoch 34/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.2631 - accuracy: 0.4904 - val_loss: 6.7870 - val_accuracy: 0.4781\n",
      "Epoch 35/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 6.1268 - accuracy: 0.4897 - val_loss: 6.0029 - val_accuracy: 0.4402\n",
      "Epoch 36/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8960 - accuracy: 0.5000 - val_loss: 5.7272 - val_accuracy: 0.4758\n",
      "Epoch 37/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8730 - accuracy: 0.4892 - val_loss: 5.4712 - val_accuracy: 0.5083\n",
      "Epoch 38/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.9053 - accuracy: 0.5043 - val_loss: 5.6586 - val_accuracy: 0.5068\n",
      "Epoch 39/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.9414 - accuracy: 0.4937 - val_loss: 5.8445 - val_accuracy: 0.4985\n",
      "Epoch 40/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.8433 - accuracy: 0.5040 - val_loss: 5.4831 - val_accuracy: 0.4902\n",
      "Epoch 41/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8747 - accuracy: 0.5058 - val_loss: 5.8868 - val_accuracy: 0.4160\n",
      "Epoch 42/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8760 - accuracy: 0.4955 - val_loss: 6.1184 - val_accuracy: 0.5514\n",
      "Epoch 43/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8088 - accuracy: 0.4982 - val_loss: 5.5921 - val_accuracy: 0.4932\n",
      "Epoch 44/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8300 - accuracy: 0.5076 - val_loss: 7.0440 - val_accuracy: 0.5144\n",
      "Epoch 45/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.8796 - accuracy: 0.5020 - val_loss: 5.7727 - val_accuracy: 0.4690\n",
      "Epoch 46/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7799 - accuracy: 0.5055 - val_loss: 5.5967 - val_accuracy: 0.5386\n",
      "Epoch 47/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7555 - accuracy: 0.4995 - val_loss: 5.6388 - val_accuracy: 0.5446\n",
      "Epoch 48/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.8552 - accuracy: 0.4985 - val_loss: 5.7242 - val_accuracy: 0.5469\n",
      "Epoch 49/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.8394 - accuracy: 0.5043 - val_loss: 5.4436 - val_accuracy: 0.5537\n",
      "Epoch 50/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.7840 - accuracy: 0.5025 - val_loss: 5.6758 - val_accuracy: 0.4826\n",
      "Epoch 51/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7741 - accuracy: 0.5139 - val_loss: 5.9329 - val_accuracy: 0.5401\n",
      "Epoch 52/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.7676 - accuracy: 0.5053 - val_loss: 5.9219 - val_accuracy: 0.4803\n",
      "Epoch 53/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.8006 - accuracy: 0.5025 - val_loss: 5.5677 - val_accuracy: 0.5371\n",
      "Epoch 54/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 5.7995 - accuracy: 0.5131 - val_loss: 6.4924 - val_accuracy: 0.5348\n",
      "Epoch 55/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7617 - accuracy: 0.5111 - val_loss: 5.4189 - val_accuracy: 0.5401\n",
      "Epoch 56/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6898 - accuracy: 0.5063 - val_loss: 7.9561 - val_accuracy: 0.4644\n",
      "Epoch 57/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.8003 - accuracy: 0.4995 - val_loss: 5.3997 - val_accuracy: 0.5166\n",
      "Epoch 58/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7014 - accuracy: 0.5038 - val_loss: 5.4845 - val_accuracy: 0.5076\n",
      "Epoch 59/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.6983 - accuracy: 0.5131 - val_loss: 5.3691 - val_accuracy: 0.5333\n",
      "Epoch 60/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.6908 - accuracy: 0.5129 - val_loss: 6.0380 - val_accuracy: 0.4788\n",
      "Epoch 61/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7186 - accuracy: 0.5020 - val_loss: 5.1600 - val_accuracy: 0.5363\n",
      "Epoch 62/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6707 - accuracy: 0.5081 - val_loss: 5.7920 - val_accuracy: 0.5401\n",
      "Epoch 63/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 5.6901 - accuracy: 0.5043 - val_loss: 5.3964 - val_accuracy: 0.5484\n",
      "Epoch 64/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.6159 - accuracy: 0.5134 - val_loss: 5.6156 - val_accuracy: 0.5424\n",
      "Epoch 65/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.6697 - accuracy: 0.5164 - val_loss: 5.3512 - val_accuracy: 0.5340\n",
      "Epoch 66/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6984 - accuracy: 0.5192 - val_loss: 5.4975 - val_accuracy: 0.5530\n",
      "Epoch 67/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5926 - accuracy: 0.5116 - val_loss: 5.3043 - val_accuracy: 0.5356\n",
      "Epoch 68/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6983 - accuracy: 0.4992 - val_loss: 5.1981 - val_accuracy: 0.5499\n",
      "Epoch 69/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.5976 - accuracy: 0.5035 - val_loss: 5.3934 - val_accuracy: 0.5393\n",
      "Epoch 70/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 5.6661 - accuracy: 0.5111 - val_loss: 5.7448 - val_accuracy: 0.4909\n",
      "Epoch 71/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5594 - accuracy: 0.5179 - val_loss: 5.4188 - val_accuracy: 0.4455\n",
      "Epoch 72/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6613 - accuracy: 0.5083 - val_loss: 5.4931 - val_accuracy: 0.5454\n",
      "Epoch 73/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6135 - accuracy: 0.5114 - val_loss: 5.2547 - val_accuracy: 0.5469\n",
      "Epoch 74/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6262 - accuracy: 0.5156 - val_loss: 5.2273 - val_accuracy: 0.4947\n",
      "Epoch 75/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5760 - accuracy: 0.5192 - val_loss: 5.3010 - val_accuracy: 0.5340\n",
      "Epoch 76/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6198 - accuracy: 0.5141 - val_loss: 5.3394 - val_accuracy: 0.4803\n",
      "Epoch 77/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6134 - accuracy: 0.5149 - val_loss: 5.1666 - val_accuracy: 0.4970\n",
      "Epoch 78/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.6579 - accuracy: 0.5172 - val_loss: 7.2006 - val_accuracy: 0.4561\n",
      "Epoch 79/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6042 - accuracy: 0.5174 - val_loss: 5.3432 - val_accuracy: 0.4879\n",
      "Epoch 80/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5147 - accuracy: 0.5154 - val_loss: 5.3463 - val_accuracy: 0.5272\n",
      "Epoch 81/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5641 - accuracy: 0.5096 - val_loss: 5.4557 - val_accuracy: 0.4909\n",
      "Epoch 82/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5785 - accuracy: 0.5035 - val_loss: 5.3276 - val_accuracy: 0.5219\n",
      "Epoch 83/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.5230 - accuracy: 0.5119 - val_loss: 5.4798 - val_accuracy: 0.4939\n",
      "Epoch 84/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5417 - accuracy: 0.5156 - val_loss: 5.2802 - val_accuracy: 0.5461\n",
      "Epoch 85/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5574 - accuracy: 0.5179 - val_loss: 5.2840 - val_accuracy: 0.4705\n",
      "Epoch 86/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6169 - accuracy: 0.5106 - val_loss: 5.3348 - val_accuracy: 0.5030\n",
      "Epoch 87/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6032 - accuracy: 0.5146 - val_loss: 5.3814 - val_accuracy: 0.4705\n",
      "Epoch 88/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.6041 - accuracy: 0.5038 - val_loss: 6.0840 - val_accuracy: 0.4766\n",
      "Epoch 89/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5405 - accuracy: 0.5114 - val_loss: 5.4403 - val_accuracy: 0.5265\n",
      "Epoch 90/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5343 - accuracy: 0.5106 - val_loss: 5.1887 - val_accuracy: 0.5030\n",
      "Epoch 91/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4707 - accuracy: 0.5144 - val_loss: 5.1484 - val_accuracy: 0.5393\n",
      "Epoch 92/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5406 - accuracy: 0.5103 - val_loss: 5.5821 - val_accuracy: 0.5545\n",
      "Epoch 93/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5810 - accuracy: 0.5154 - val_loss: 5.0663 - val_accuracy: 0.5386\n",
      "Epoch 94/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4784 - accuracy: 0.5202 - val_loss: 5.2979 - val_accuracy: 0.5197\n",
      "Epoch 95/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5376 - accuracy: 0.5139 - val_loss: 5.1267 - val_accuracy: 0.5567\n",
      "Epoch 96/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5007 - accuracy: 0.5119 - val_loss: 5.3096 - val_accuracy: 0.5378\n",
      "Epoch 97/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5028 - accuracy: 0.5149 - val_loss: 5.1942 - val_accuracy: 0.5431\n",
      "Epoch 98/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5273 - accuracy: 0.5096 - val_loss: 5.2303 - val_accuracy: 0.5204\n",
      "Epoch 99/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4934 - accuracy: 0.5136 - val_loss: 5.6334 - val_accuracy: 0.5121\n",
      "Epoch 100/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4890 - accuracy: 0.5182 - val_loss: 5.3681 - val_accuracy: 0.5431\n",
      "Epoch 101/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.5555 - accuracy: 0.5139 - val_loss: 5.1331 - val_accuracy: 0.5212\n",
      "Epoch 102/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4447 - accuracy: 0.5091 - val_loss: 5.1790 - val_accuracy: 0.5333\n",
      "Epoch 103/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4169 - accuracy: 0.5156 - val_loss: 5.2126 - val_accuracy: 0.5091\n",
      "Epoch 104/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4418 - accuracy: 0.5189 - val_loss: 5.1435 - val_accuracy: 0.5189\n",
      "Epoch 105/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4882 - accuracy: 0.5144 - val_loss: 5.2120 - val_accuracy: 0.5166\n",
      "Epoch 106/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.5237 - accuracy: 0.5179 - val_loss: 5.1720 - val_accuracy: 0.5174\n",
      "Epoch 107/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4464 - accuracy: 0.5164 - val_loss: 5.1269 - val_accuracy: 0.4788\n",
      "Epoch 108/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4617 - accuracy: 0.5061 - val_loss: 5.1718 - val_accuracy: 0.5545\n",
      "Epoch 109/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4770 - accuracy: 0.5204 - val_loss: 5.3202 - val_accuracy: 0.5461\n",
      "Epoch 110/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5186 - accuracy: 0.5166 - val_loss: 5.3210 - val_accuracy: 0.5008\n",
      "Epoch 111/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4446 - accuracy: 0.5103 - val_loss: 5.1814 - val_accuracy: 0.5620\n",
      "Epoch 112/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4232 - accuracy: 0.5179 - val_loss: 5.4247 - val_accuracy: 0.5280\n",
      "Epoch 113/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4590 - accuracy: 0.5182 - val_loss: 5.2219 - val_accuracy: 0.5605\n",
      "Epoch 114/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.5241 - accuracy: 0.5119 - val_loss: 5.3527 - val_accuracy: 0.5393\n",
      "Epoch 115/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4688 - accuracy: 0.5134 - val_loss: 5.3817 - val_accuracy: 0.5068\n",
      "Epoch 116/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4466 - accuracy: 0.5219 - val_loss: 5.1963 - val_accuracy: 0.4720\n",
      "Epoch 117/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4633 - accuracy: 0.5139 - val_loss: 5.1106 - val_accuracy: 0.5590\n",
      "Epoch 118/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3892 - accuracy: 0.5207 - val_loss: 5.0784 - val_accuracy: 0.5507\n",
      "Epoch 119/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4280 - accuracy: 0.5225 - val_loss: 5.2308 - val_accuracy: 0.5605\n",
      "Epoch 120/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4299 - accuracy: 0.5179 - val_loss: 5.2028 - val_accuracy: 0.5590\n",
      "Epoch 121/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4015 - accuracy: 0.5288 - val_loss: 5.3505 - val_accuracy: 0.5499\n",
      "Epoch 122/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4397 - accuracy: 0.5114 - val_loss: 5.1883 - val_accuracy: 0.5582\n",
      "Epoch 123/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4194 - accuracy: 0.5154 - val_loss: 5.1976 - val_accuracy: 0.4962\n",
      "Epoch 124/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4255 - accuracy: 0.5197 - val_loss: 5.5605 - val_accuracy: 0.5401\n",
      "Epoch 125/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4332 - accuracy: 0.5219 - val_loss: 5.2187 - val_accuracy: 0.5477\n",
      "Epoch 126/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4418 - accuracy: 0.5212 - val_loss: 5.1417 - val_accuracy: 0.5424\n",
      "Epoch 127/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4444 - accuracy: 0.5098 - val_loss: 5.1832 - val_accuracy: 0.5499\n",
      "Epoch 128/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3842 - accuracy: 0.5131 - val_loss: 5.0866 - val_accuracy: 0.5303\n",
      "Epoch 129/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4168 - accuracy: 0.5119 - val_loss: 5.4511 - val_accuracy: 0.5212\n",
      "Epoch 130/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4362 - accuracy: 0.5209 - val_loss: 5.3550 - val_accuracy: 0.5575\n",
      "Epoch 131/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3915 - accuracy: 0.5146 - val_loss: 5.2249 - val_accuracy: 0.5628\n",
      "Epoch 132/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3850 - accuracy: 0.5179 - val_loss: 5.0888 - val_accuracy: 0.5234\n",
      "Epoch 133/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4112 - accuracy: 0.5164 - val_loss: 5.0621 - val_accuracy: 0.5507\n",
      "Epoch 134/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4287 - accuracy: 0.5172 - val_loss: 5.2683 - val_accuracy: 0.4705\n",
      "Epoch 135/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4272 - accuracy: 0.5121 - val_loss: 5.2053 - val_accuracy: 0.5613\n",
      "Epoch 136/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3790 - accuracy: 0.5197 - val_loss: 5.2377 - val_accuracy: 0.5219\n",
      "Epoch 137/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4040 - accuracy: 0.5172 - val_loss: 5.2340 - val_accuracy: 0.5371\n",
      "Epoch 138/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.4225 - accuracy: 0.5169 - val_loss: 5.1226 - val_accuracy: 0.5348\n",
      "Epoch 139/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4154 - accuracy: 0.5219 - val_loss: 5.2015 - val_accuracy: 0.5545\n",
      "Epoch 140/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4905 - accuracy: 0.5161 - val_loss: 5.1335 - val_accuracy: 0.5552\n",
      "Epoch 141/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4012 - accuracy: 0.5101 - val_loss: 5.1299 - val_accuracy: 0.5598\n",
      "Epoch 142/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3535 - accuracy: 0.5209 - val_loss: 5.3154 - val_accuracy: 0.4743\n",
      "Epoch 143/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3758 - accuracy: 0.5156 - val_loss: 5.2820 - val_accuracy: 0.5166\n",
      "Epoch 144/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3271 - accuracy: 0.5182 - val_loss: 5.6235 - val_accuracy: 0.5439\n",
      "Epoch 145/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.4133 - accuracy: 0.5217 - val_loss: 5.2590 - val_accuracy: 0.5567\n",
      "Epoch 146/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3874 - accuracy: 0.5166 - val_loss: 5.1062 - val_accuracy: 0.5643\n",
      "Epoch 147/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3880 - accuracy: 0.5235 - val_loss: 5.0657 - val_accuracy: 0.5598\n",
      "Epoch 148/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3605 - accuracy: 0.5225 - val_loss: 5.3653 - val_accuracy: 0.4962\n",
      "Epoch 149/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3610 - accuracy: 0.5182 - val_loss: 5.0132 - val_accuracy: 0.5061\n",
      "Epoch 150/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3507 - accuracy: 0.5245 - val_loss: 5.0901 - val_accuracy: 0.5545\n",
      "Epoch 151/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3677 - accuracy: 0.5174 - val_loss: 5.0509 - val_accuracy: 0.5613\n",
      "Epoch 152/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3527 - accuracy: 0.5230 - val_loss: 5.2019 - val_accuracy: 0.5068\n",
      "Epoch 153/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.3686 - accuracy: 0.5179 - val_loss: 5.3691 - val_accuracy: 0.5144\n",
      "Epoch 154/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3471 - accuracy: 0.5214 - val_loss: 5.1166 - val_accuracy: 0.5136\n",
      "Epoch 155/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3355 - accuracy: 0.5164 - val_loss: 5.0821 - val_accuracy: 0.4955\n",
      "Epoch 156/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.3247 - accuracy: 0.5217 - val_loss: 5.4160 - val_accuracy: 0.5083\n",
      "Epoch 157/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 5.4087 - accuracy: 0.5177 - val_loss: 5.0869 - val_accuracy: 0.5242\n",
      "Epoch 158/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3815 - accuracy: 0.5172 - val_loss: 5.1117 - val_accuracy: 0.5582\n",
      "Epoch 159/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3310 - accuracy: 0.5283 - val_loss: 5.0531 - val_accuracy: 0.5469\n",
      "Epoch 160/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3238 - accuracy: 0.5207 - val_loss: 5.2170 - val_accuracy: 0.5197\n",
      "Epoch 161/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3259 - accuracy: 0.5222 - val_loss: 5.0623 - val_accuracy: 0.5537\n",
      "Epoch 162/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3304 - accuracy: 0.5204 - val_loss: 5.1862 - val_accuracy: 0.4894\n",
      "Epoch 163/400\n",
      "248/248 [==============================] - 2s 10ms/step - loss: 5.3324 - accuracy: 0.5227 - val_loss: 5.1811 - val_accuracy: 0.5325\n",
      "Epoch 164/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3195 - accuracy: 0.5237 - val_loss: 5.0339 - val_accuracy: 0.5446\n",
      "Epoch 165/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3489 - accuracy: 0.5159 - val_loss: 5.1866 - val_accuracy: 0.5371\n",
      "Epoch 166/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3629 - accuracy: 0.5177 - val_loss: 5.0650 - val_accuracy: 0.5287\n",
      "Epoch 167/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3635 - accuracy: 0.5204 - val_loss: 5.1673 - val_accuracy: 0.5461\n",
      "Epoch 168/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3221 - accuracy: 0.5144 - val_loss: 5.0808 - val_accuracy: 0.5446\n",
      "Epoch 169/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3142 - accuracy: 0.5121 - val_loss: 5.0779 - val_accuracy: 0.5552\n",
      "Epoch 170/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3077 - accuracy: 0.5222 - val_loss: 5.1818 - val_accuracy: 0.5635\n",
      "Epoch 171/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3300 - accuracy: 0.5199 - val_loss: 4.9801 - val_accuracy: 0.5620\n",
      "Epoch 172/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3423 - accuracy: 0.5275 - val_loss: 5.1342 - val_accuracy: 0.5280\n",
      "Epoch 173/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3159 - accuracy: 0.5257 - val_loss: 5.1726 - val_accuracy: 0.5507\n",
      "Epoch 174/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3096 - accuracy: 0.5172 - val_loss: 5.2014 - val_accuracy: 0.4992\n",
      "Epoch 175/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3195 - accuracy: 0.5204 - val_loss: 5.2442 - val_accuracy: 0.5469\n",
      "Epoch 176/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3180 - accuracy: 0.5222 - val_loss: 5.0500 - val_accuracy: 0.5318\n",
      "Epoch 177/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3774 - accuracy: 0.5235 - val_loss: 5.5385 - val_accuracy: 0.5038\n",
      "Epoch 178/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3173 - accuracy: 0.5174 - val_loss: 5.3087 - val_accuracy: 0.5522\n",
      "Epoch 179/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2970 - accuracy: 0.5194 - val_loss: 5.3767 - val_accuracy: 0.4932\n",
      "Epoch 180/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3231 - accuracy: 0.5217 - val_loss: 5.1909 - val_accuracy: 0.5227\n",
      "Epoch 181/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2936 - accuracy: 0.5315 - val_loss: 5.0831 - val_accuracy: 0.5567\n",
      "Epoch 182/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3005 - accuracy: 0.5209 - val_loss: 5.0164 - val_accuracy: 0.5613\n",
      "Epoch 183/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3330 - accuracy: 0.5151 - val_loss: 5.1541 - val_accuracy: 0.5408\n",
      "Epoch 184/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3045 - accuracy: 0.5144 - val_loss: 5.0708 - val_accuracy: 0.5582\n",
      "Epoch 185/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2979 - accuracy: 0.5199 - val_loss: 5.3509 - val_accuracy: 0.5469\n",
      "Epoch 186/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3329 - accuracy: 0.5217 - val_loss: 5.0332 - val_accuracy: 0.5461\n",
      "Epoch 187/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2887 - accuracy: 0.5290 - val_loss: 5.0429 - val_accuracy: 0.5552\n",
      "Epoch 188/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2746 - accuracy: 0.5277 - val_loss: 5.0666 - val_accuracy: 0.5643\n",
      "Epoch 189/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2656 - accuracy: 0.5209 - val_loss: 5.2098 - val_accuracy: 0.5643\n",
      "Epoch 190/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2848 - accuracy: 0.5225 - val_loss: 5.0717 - val_accuracy: 0.5424\n",
      "Epoch 191/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3091 - accuracy: 0.5194 - val_loss: 5.2146 - val_accuracy: 0.4985\n",
      "Epoch 192/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2934 - accuracy: 0.5225 - val_loss: 5.0399 - val_accuracy: 0.5234\n",
      "Epoch 193/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2798 - accuracy: 0.5280 - val_loss: 5.1518 - val_accuracy: 0.5280\n",
      "Epoch 194/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2948 - accuracy: 0.5280 - val_loss: 5.0384 - val_accuracy: 0.5348\n",
      "Epoch 195/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2871 - accuracy: 0.5189 - val_loss: 5.1539 - val_accuracy: 0.5053\n",
      "Epoch 196/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2614 - accuracy: 0.5262 - val_loss: 5.0182 - val_accuracy: 0.5212\n",
      "Epoch 197/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2987 - accuracy: 0.5199 - val_loss: 5.2882 - val_accuracy: 0.5136\n",
      "Epoch 198/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3132 - accuracy: 0.5217 - val_loss: 5.1969 - val_accuracy: 0.4955\n",
      "Epoch 199/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3073 - accuracy: 0.5154 - val_loss: 5.0519 - val_accuracy: 0.5666\n",
      "Epoch 200/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2813 - accuracy: 0.5293 - val_loss: 5.1239 - val_accuracy: 0.5477\n",
      "Epoch 201/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2702 - accuracy: 0.5174 - val_loss: 5.0747 - val_accuracy: 0.5620\n",
      "Epoch 202/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2900 - accuracy: 0.5166 - val_loss: 5.1978 - val_accuracy: 0.5424\n",
      "Epoch 203/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2862 - accuracy: 0.5275 - val_loss: 5.2816 - val_accuracy: 0.5439\n",
      "Epoch 204/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2815 - accuracy: 0.5197 - val_loss: 5.0404 - val_accuracy: 0.5507\n",
      "Epoch 205/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2757 - accuracy: 0.5240 - val_loss: 5.2157 - val_accuracy: 0.5477\n",
      "Epoch 206/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2929 - accuracy: 0.5255 - val_loss: 5.1126 - val_accuracy: 0.5136\n",
      "Epoch 207/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2811 - accuracy: 0.5275 - val_loss: 5.1088 - val_accuracy: 0.5340\n",
      "Epoch 208/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2652 - accuracy: 0.5300 - val_loss: 5.0882 - val_accuracy: 0.5234\n",
      "Epoch 209/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2392 - accuracy: 0.5270 - val_loss: 5.0720 - val_accuracy: 0.5537\n",
      "Epoch 210/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2717 - accuracy: 0.5232 - val_loss: 5.3816 - val_accuracy: 0.5303\n",
      "Epoch 211/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3041 - accuracy: 0.5154 - val_loss: 5.1403 - val_accuracy: 0.5348\n",
      "Epoch 212/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2568 - accuracy: 0.5262 - val_loss: 5.2392 - val_accuracy: 0.5098\n",
      "Epoch 213/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2457 - accuracy: 0.5283 - val_loss: 5.1024 - val_accuracy: 0.5416\n",
      "Epoch 214/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3317 - accuracy: 0.5250 - val_loss: 5.2177 - val_accuracy: 0.5348\n",
      "Epoch 215/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2741 - accuracy: 0.5232 - val_loss: 5.1032 - val_accuracy: 0.5303\n",
      "Epoch 216/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2401 - accuracy: 0.5214 - val_loss: 4.9777 - val_accuracy: 0.5469\n",
      "Epoch 217/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2379 - accuracy: 0.5305 - val_loss: 5.0949 - val_accuracy: 0.5582\n",
      "Epoch 218/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2743 - accuracy: 0.5272 - val_loss: 5.1567 - val_accuracy: 0.5439\n",
      "Epoch 219/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2715 - accuracy: 0.5237 - val_loss: 5.4201 - val_accuracy: 0.5166\n",
      "Epoch 220/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3200 - accuracy: 0.5184 - val_loss: 5.1123 - val_accuracy: 0.5408\n",
      "Epoch 221/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2769 - accuracy: 0.5257 - val_loss: 5.0230 - val_accuracy: 0.5560\n",
      "Epoch 222/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2739 - accuracy: 0.5300 - val_loss: 5.1119 - val_accuracy: 0.5530\n",
      "Epoch 223/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2506 - accuracy: 0.5207 - val_loss: 5.0129 - val_accuracy: 0.5454\n",
      "Epoch 224/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2370 - accuracy: 0.5283 - val_loss: 5.0946 - val_accuracy: 0.5348\n",
      "Epoch 225/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2548 - accuracy: 0.5308 - val_loss: 5.0435 - val_accuracy: 0.5234\n",
      "Epoch 226/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2791 - accuracy: 0.5298 - val_loss: 5.1788 - val_accuracy: 0.5386\n",
      "Epoch 227/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.3103 - accuracy: 0.5214 - val_loss: 5.1478 - val_accuracy: 0.5348\n",
      "Epoch 228/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2492 - accuracy: 0.5235 - val_loss: 5.1034 - val_accuracy: 0.5628\n",
      "Epoch 229/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2151 - accuracy: 0.5267 - val_loss: 5.0377 - val_accuracy: 0.5439\n",
      "Epoch 230/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2374 - accuracy: 0.5298 - val_loss: 5.0850 - val_accuracy: 0.5212\n",
      "Epoch 231/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2596 - accuracy: 0.5217 - val_loss: 5.0712 - val_accuracy: 0.5492\n",
      "Epoch 232/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2617 - accuracy: 0.5280 - val_loss: 6.7065 - val_accuracy: 0.5113\n",
      "Epoch 233/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2776 - accuracy: 0.5232 - val_loss: 5.0576 - val_accuracy: 0.5499\n",
      "Epoch 234/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2932 - accuracy: 0.5272 - val_loss: 5.0712 - val_accuracy: 0.5605\n",
      "Epoch 235/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2621 - accuracy: 0.5245 - val_loss: 5.1729 - val_accuracy: 0.5371\n",
      "Epoch 236/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2620 - accuracy: 0.5275 - val_loss: 5.0228 - val_accuracy: 0.5552\n",
      "Epoch 237/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2319 - accuracy: 0.5237 - val_loss: 5.0399 - val_accuracy: 0.5477\n",
      "Epoch 238/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2286 - accuracy: 0.5255 - val_loss: 4.9826 - val_accuracy: 0.5643\n",
      "Epoch 239/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3058 - accuracy: 0.5217 - val_loss: 5.0661 - val_accuracy: 0.5106\n",
      "Epoch 240/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3083 - accuracy: 0.5275 - val_loss: 5.1822 - val_accuracy: 0.5310\n",
      "Epoch 241/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2730 - accuracy: 0.5214 - val_loss: 5.1700 - val_accuracy: 0.5182\n",
      "Epoch 242/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2705 - accuracy: 0.5262 - val_loss: 5.2963 - val_accuracy: 0.5393\n",
      "Epoch 243/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2606 - accuracy: 0.5217 - val_loss: 5.0136 - val_accuracy: 0.5605\n",
      "Epoch 244/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2523 - accuracy: 0.5197 - val_loss: 5.0530 - val_accuracy: 0.5530\n",
      "Epoch 245/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2510 - accuracy: 0.5242 - val_loss: 5.0578 - val_accuracy: 0.5416\n",
      "Epoch 246/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2643 - accuracy: 0.5235 - val_loss: 5.1499 - val_accuracy: 0.5643\n",
      "Epoch 247/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2603 - accuracy: 0.5255 - val_loss: 5.0303 - val_accuracy: 0.5083\n",
      "Epoch 248/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2582 - accuracy: 0.5288 - val_loss: 4.9989 - val_accuracy: 0.5129\n",
      "Epoch 249/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2494 - accuracy: 0.5325 - val_loss: 5.0499 - val_accuracy: 0.5303\n",
      "Epoch 250/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2722 - accuracy: 0.5240 - val_loss: 5.1017 - val_accuracy: 0.5620\n",
      "Epoch 251/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2949 - accuracy: 0.5225 - val_loss: 5.9717 - val_accuracy: 0.5393\n",
      "Epoch 252/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2555 - accuracy: 0.5290 - val_loss: 5.0231 - val_accuracy: 0.5522\n",
      "Epoch 253/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2331 - accuracy: 0.5250 - val_loss: 5.0470 - val_accuracy: 0.5477\n",
      "Epoch 254/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2608 - accuracy: 0.5247 - val_loss: 5.1624 - val_accuracy: 0.5598\n",
      "Epoch 255/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2456 - accuracy: 0.5250 - val_loss: 5.0940 - val_accuracy: 0.5378\n",
      "Epoch 256/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2409 - accuracy: 0.5222 - val_loss: 4.9793 - val_accuracy: 0.5310\n",
      "Epoch 257/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2527 - accuracy: 0.5177 - val_loss: 5.1398 - val_accuracy: 0.5431\n",
      "Epoch 258/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2354 - accuracy: 0.5275 - val_loss: 5.1304 - val_accuracy: 0.5424\n",
      "Epoch 259/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2543 - accuracy: 0.5283 - val_loss: 5.2328 - val_accuracy: 0.5492\n",
      "Epoch 260/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2522 - accuracy: 0.5270 - val_loss: 5.0749 - val_accuracy: 0.5567\n",
      "Epoch 261/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2559 - accuracy: 0.5262 - val_loss: 5.0263 - val_accuracy: 0.5658\n",
      "Epoch 262/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2530 - accuracy: 0.5260 - val_loss: 5.1291 - val_accuracy: 0.5416\n",
      "Epoch 263/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2749 - accuracy: 0.5300 - val_loss: 5.2020 - val_accuracy: 0.5242\n",
      "Epoch 264/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2921 - accuracy: 0.5207 - val_loss: 5.0127 - val_accuracy: 0.5424\n",
      "Epoch 265/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2557 - accuracy: 0.5237 - val_loss: 5.1256 - val_accuracy: 0.5545\n",
      "Epoch 266/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2447 - accuracy: 0.5260 - val_loss: 5.1276 - val_accuracy: 0.5378\n",
      "Epoch 267/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2324 - accuracy: 0.5310 - val_loss: 5.0895 - val_accuracy: 0.4849\n",
      "Epoch 268/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2409 - accuracy: 0.5325 - val_loss: 5.0665 - val_accuracy: 0.5189\n",
      "Epoch 269/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2242 - accuracy: 0.5255 - val_loss: 4.9968 - val_accuracy: 0.5356\n",
      "Epoch 270/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2602 - accuracy: 0.5245 - val_loss: 5.0390 - val_accuracy: 0.5310\n",
      "Epoch 271/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2636 - accuracy: 0.5295 - val_loss: 5.1402 - val_accuracy: 0.5605\n",
      "Epoch 272/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2674 - accuracy: 0.5305 - val_loss: 5.2198 - val_accuracy: 0.5530\n",
      "Epoch 273/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2517 - accuracy: 0.5235 - val_loss: 5.0576 - val_accuracy: 0.5272\n",
      "Epoch 274/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2223 - accuracy: 0.5255 - val_loss: 5.1426 - val_accuracy: 0.5582\n",
      "Epoch 275/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2438 - accuracy: 0.5209 - val_loss: 5.0887 - val_accuracy: 0.5454\n",
      "Epoch 276/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2707 - accuracy: 0.5303 - val_loss: 5.0614 - val_accuracy: 0.5257\n",
      "Epoch 277/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2331 - accuracy: 0.5371 - val_loss: 5.0104 - val_accuracy: 0.5484\n",
      "Epoch 278/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2419 - accuracy: 0.5262 - val_loss: 5.0245 - val_accuracy: 0.5159\n",
      "Epoch 279/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2676 - accuracy: 0.5242 - val_loss: 5.0780 - val_accuracy: 0.5136\n",
      "Epoch 280/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2594 - accuracy: 0.5227 - val_loss: 5.1132 - val_accuracy: 0.5356\n",
      "Epoch 281/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2336 - accuracy: 0.5272 - val_loss: 5.0827 - val_accuracy: 0.5469\n",
      "Epoch 282/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2645 - accuracy: 0.5275 - val_loss: 5.0437 - val_accuracy: 0.5499\n",
      "Epoch 283/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2542 - accuracy: 0.5310 - val_loss: 5.1815 - val_accuracy: 0.5530\n",
      "Epoch 284/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2881 - accuracy: 0.5209 - val_loss: 5.0594 - val_accuracy: 0.5386\n",
      "Epoch 285/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2596 - accuracy: 0.5260 - val_loss: 5.0258 - val_accuracy: 0.5628\n",
      "Epoch 286/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.1963 - accuracy: 0.5267 - val_loss: 5.1817 - val_accuracy: 0.5310\n",
      "Epoch 287/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2426 - accuracy: 0.5250 - val_loss: 5.1576 - val_accuracy: 0.5144\n",
      "Epoch 288/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2364 - accuracy: 0.5277 - val_loss: 5.0580 - val_accuracy: 0.5537\n",
      "Epoch 289/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2332 - accuracy: 0.5235 - val_loss: 5.0481 - val_accuracy: 0.5197\n",
      "Epoch 290/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2511 - accuracy: 0.5255 - val_loss: 5.4856 - val_accuracy: 0.5514\n",
      "Epoch 291/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2586 - accuracy: 0.5328 - val_loss: 5.0818 - val_accuracy: 0.5507\n",
      "Epoch 292/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2122 - accuracy: 0.5293 - val_loss: 5.1070 - val_accuracy: 0.5635\n",
      "Epoch 293/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2399 - accuracy: 0.5257 - val_loss: 5.0456 - val_accuracy: 0.5688\n",
      "Epoch 294/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2371 - accuracy: 0.5252 - val_loss: 5.1208 - val_accuracy: 0.5651\n",
      "Epoch 295/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2888 - accuracy: 0.5265 - val_loss: 5.0843 - val_accuracy: 0.5537\n",
      "Epoch 296/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2318 - accuracy: 0.5298 - val_loss: 5.0916 - val_accuracy: 0.5182\n",
      "Epoch 297/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2586 - accuracy: 0.5237 - val_loss: 5.0955 - val_accuracy: 0.4962\n",
      "Epoch 298/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2291 - accuracy: 0.5240 - val_loss: 5.0152 - val_accuracy: 0.5651\n",
      "Epoch 299/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2097 - accuracy: 0.5330 - val_loss: 5.2732 - val_accuracy: 0.5348\n",
      "Epoch 300/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2296 - accuracy: 0.5240 - val_loss: 5.0127 - val_accuracy: 0.5514\n",
      "Epoch 301/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2260 - accuracy: 0.5245 - val_loss: 5.0173 - val_accuracy: 0.5575\n",
      "Epoch 302/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2622 - accuracy: 0.5189 - val_loss: 5.1146 - val_accuracy: 0.5545\n",
      "Epoch 303/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2545 - accuracy: 0.5300 - val_loss: 5.0290 - val_accuracy: 0.5582\n",
      "Epoch 304/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2622 - accuracy: 0.5280 - val_loss: 5.0558 - val_accuracy: 0.5530\n",
      "Epoch 305/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2463 - accuracy: 0.5255 - val_loss: 5.1374 - val_accuracy: 0.5635\n",
      "Epoch 306/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2307 - accuracy: 0.5230 - val_loss: 5.0728 - val_accuracy: 0.5666\n",
      "Epoch 307/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2561 - accuracy: 0.5252 - val_loss: 5.0855 - val_accuracy: 0.5666\n",
      "Epoch 308/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2489 - accuracy: 0.5293 - val_loss: 5.1629 - val_accuracy: 0.5598\n",
      "Epoch 309/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2401 - accuracy: 0.5247 - val_loss: 5.0164 - val_accuracy: 0.5113\n",
      "Epoch 310/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2573 - accuracy: 0.5242 - val_loss: 5.0199 - val_accuracy: 0.5038\n",
      "Epoch 311/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2302 - accuracy: 0.5303 - val_loss: 5.0997 - val_accuracy: 0.5454\n",
      "Epoch 312/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2406 - accuracy: 0.5267 - val_loss: 5.0051 - val_accuracy: 0.5681\n",
      "Epoch 313/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2196 - accuracy: 0.5336 - val_loss: 5.1432 - val_accuracy: 0.5673\n",
      "Epoch 314/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2483 - accuracy: 0.5280 - val_loss: 5.0269 - val_accuracy: 0.5325\n",
      "Epoch 315/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2280 - accuracy: 0.5293 - val_loss: 5.0737 - val_accuracy: 0.5371\n",
      "Epoch 316/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2845 - accuracy: 0.5272 - val_loss: 5.2085 - val_accuracy: 0.5242\n",
      "Epoch 317/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2543 - accuracy: 0.5207 - val_loss: 5.0652 - val_accuracy: 0.5711\n",
      "Epoch 318/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2327 - accuracy: 0.5295 - val_loss: 5.1214 - val_accuracy: 0.5628\n",
      "Epoch 319/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2265 - accuracy: 0.5275 - val_loss: 5.0829 - val_accuracy: 0.5537\n",
      "Epoch 320/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2287 - accuracy: 0.5230 - val_loss: 5.0737 - val_accuracy: 0.5582\n",
      "Epoch 321/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2463 - accuracy: 0.5182 - val_loss: 5.0734 - val_accuracy: 0.5499\n",
      "Epoch 322/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2754 - accuracy: 0.5225 - val_loss: 5.0693 - val_accuracy: 0.5431\n",
      "Epoch 323/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2331 - accuracy: 0.5257 - val_loss: 5.0931 - val_accuracy: 0.5522\n",
      "Epoch 324/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.1939 - accuracy: 0.5265 - val_loss: 5.0579 - val_accuracy: 0.5318\n",
      "Epoch 325/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2351 - accuracy: 0.5303 - val_loss: 5.1759 - val_accuracy: 0.5371\n",
      "Epoch 326/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2354 - accuracy: 0.5265 - val_loss: 5.3013 - val_accuracy: 0.4894\n",
      "Epoch 327/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2261 - accuracy: 0.5320 - val_loss: 5.2624 - val_accuracy: 0.5325\n",
      "Epoch 328/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2351 - accuracy: 0.5277 - val_loss: 5.0887 - val_accuracy: 0.5068\n",
      "Epoch 329/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2348 - accuracy: 0.5255 - val_loss: 5.1029 - val_accuracy: 0.5439\n",
      "Epoch 330/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2784 - accuracy: 0.5240 - val_loss: 5.0342 - val_accuracy: 0.4871\n",
      "Epoch 331/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2473 - accuracy: 0.5310 - val_loss: 5.1364 - val_accuracy: 0.5234\n",
      "Epoch 332/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2643 - accuracy: 0.5245 - val_loss: 5.0543 - val_accuracy: 0.5628\n",
      "Epoch 333/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2402 - accuracy: 0.5245 - val_loss: 5.0428 - val_accuracy: 0.5643\n",
      "Epoch 334/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2261 - accuracy: 0.5255 - val_loss: 5.0790 - val_accuracy: 0.5250\n",
      "Epoch 335/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2627 - accuracy: 0.5290 - val_loss: 5.0329 - val_accuracy: 0.5272\n",
      "Epoch 336/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2153 - accuracy: 0.5343 - val_loss: 5.0088 - val_accuracy: 0.5560\n",
      "Epoch 337/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2470 - accuracy: 0.5237 - val_loss: 5.0665 - val_accuracy: 0.5582\n",
      "Epoch 338/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2520 - accuracy: 0.5242 - val_loss: 5.0987 - val_accuracy: 0.5242\n",
      "Epoch 339/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2586 - accuracy: 0.5265 - val_loss: 4.9942 - val_accuracy: 0.5333\n",
      "Epoch 340/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2557 - accuracy: 0.5255 - val_loss: 5.0835 - val_accuracy: 0.5038\n",
      "Epoch 341/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2289 - accuracy: 0.5346 - val_loss: 5.0639 - val_accuracy: 0.5303\n",
      "Epoch 342/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2938 - accuracy: 0.5217 - val_loss: 5.1953 - val_accuracy: 0.5446\n",
      "Epoch 343/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2298 - accuracy: 0.5227 - val_loss: 5.0293 - val_accuracy: 0.5424\n",
      "Epoch 344/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2461 - accuracy: 0.5197 - val_loss: 5.1990 - val_accuracy: 0.5318\n",
      "Epoch 345/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2170 - accuracy: 0.5305 - val_loss: 5.0336 - val_accuracy: 0.5598\n",
      "Epoch 346/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2813 - accuracy: 0.5209 - val_loss: 5.0646 - val_accuracy: 0.5477\n",
      "Epoch 347/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2719 - accuracy: 0.5194 - val_loss: 5.0871 - val_accuracy: 0.5386\n",
      "Epoch 348/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2170 - accuracy: 0.5230 - val_loss: 5.0689 - val_accuracy: 0.5696\n",
      "Epoch 349/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2437 - accuracy: 0.5277 - val_loss: 5.0756 - val_accuracy: 0.5628\n",
      "Epoch 350/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2184 - accuracy: 0.5280 - val_loss: 5.1384 - val_accuracy: 0.5628\n",
      "Epoch 351/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2122 - accuracy: 0.5237 - val_loss: 5.1146 - val_accuracy: 0.5605\n",
      "Epoch 352/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2426 - accuracy: 0.5275 - val_loss: 5.1090 - val_accuracy: 0.5030\n",
      "Epoch 353/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2271 - accuracy: 0.5275 - val_loss: 5.0786 - val_accuracy: 0.5582\n",
      "Epoch 354/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2775 - accuracy: 0.5272 - val_loss: 5.0485 - val_accuracy: 0.4728\n",
      "Epoch 355/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2008 - accuracy: 0.5288 - val_loss: 5.1373 - val_accuracy: 0.5545\n",
      "Epoch 356/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2349 - accuracy: 0.5272 - val_loss: 5.0694 - val_accuracy: 0.5280\n",
      "Epoch 357/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2166 - accuracy: 0.5290 - val_loss: 4.9741 - val_accuracy: 0.5371\n",
      "Epoch 358/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2316 - accuracy: 0.5267 - val_loss: 4.9845 - val_accuracy: 0.5461\n",
      "Epoch 359/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2285 - accuracy: 0.5227 - val_loss: 5.0802 - val_accuracy: 0.5371\n",
      "Epoch 360/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2037 - accuracy: 0.5235 - val_loss: 4.9873 - val_accuracy: 0.5613\n",
      "Epoch 361/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2115 - accuracy: 0.5283 - val_loss: 5.3832 - val_accuracy: 0.4660\n",
      "Epoch 362/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2526 - accuracy: 0.5250 - val_loss: 5.1639 - val_accuracy: 0.5605\n",
      "Epoch 363/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2270 - accuracy: 0.5280 - val_loss: 4.9925 - val_accuracy: 0.5144\n",
      "Epoch 364/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2097 - accuracy: 0.5285 - val_loss: 5.1583 - val_accuracy: 0.5303\n",
      "Epoch 365/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2153 - accuracy: 0.5275 - val_loss: 4.9695 - val_accuracy: 0.5378\n",
      "Epoch 366/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2421 - accuracy: 0.5270 - val_loss: 5.0596 - val_accuracy: 0.5477\n",
      "Epoch 367/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2288 - accuracy: 0.5270 - val_loss: 5.1595 - val_accuracy: 0.5287\n",
      "Epoch 368/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2365 - accuracy: 0.5227 - val_loss: 5.0823 - val_accuracy: 0.5318\n",
      "Epoch 369/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2356 - accuracy: 0.5260 - val_loss: 5.4807 - val_accuracy: 0.4758\n",
      "Epoch 370/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2501 - accuracy: 0.5318 - val_loss: 5.0075 - val_accuracy: 0.5560\n",
      "Epoch 371/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2039 - accuracy: 0.5280 - val_loss: 5.0105 - val_accuracy: 0.4992\n",
      "Epoch 372/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2327 - accuracy: 0.5293 - val_loss: 5.0834 - val_accuracy: 0.5628\n",
      "Epoch 373/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2500 - accuracy: 0.5275 - val_loss: 5.0511 - val_accuracy: 0.5325\n",
      "Epoch 374/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2695 - accuracy: 0.5285 - val_loss: 5.2975 - val_accuracy: 0.5008\n",
      "Epoch 375/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2580 - accuracy: 0.5288 - val_loss: 5.0521 - val_accuracy: 0.5552\n",
      "Epoch 376/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2112 - accuracy: 0.5225 - val_loss: 5.0151 - val_accuracy: 0.5265\n",
      "Epoch 377/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2037 - accuracy: 0.5290 - val_loss: 5.0250 - val_accuracy: 0.5590\n",
      "Epoch 378/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2249 - accuracy: 0.5240 - val_loss: 5.0185 - val_accuracy: 0.5673\n",
      "Epoch 379/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2026 - accuracy: 0.5295 - val_loss: 5.0164 - val_accuracy: 0.5061\n",
      "Epoch 380/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2297 - accuracy: 0.5222 - val_loss: 5.0430 - val_accuracy: 0.5681\n",
      "Epoch 381/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2364 - accuracy: 0.5295 - val_loss: 5.0510 - val_accuracy: 0.5091\n",
      "Epoch 382/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2660 - accuracy: 0.5225 - val_loss: 5.1429 - val_accuracy: 0.5393\n",
      "Epoch 383/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2109 - accuracy: 0.5214 - val_loss: 5.2568 - val_accuracy: 0.5446\n",
      "Epoch 384/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2558 - accuracy: 0.5328 - val_loss: 5.0855 - val_accuracy: 0.5023\n",
      "Epoch 385/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2044 - accuracy: 0.5267 - val_loss: 5.0218 - val_accuracy: 0.5371\n",
      "Epoch 386/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2363 - accuracy: 0.5383 - val_loss: 5.0310 - val_accuracy: 0.5295\n",
      "Epoch 387/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2282 - accuracy: 0.5265 - val_loss: 4.9950 - val_accuracy: 0.5136\n",
      "Epoch 388/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2401 - accuracy: 0.5260 - val_loss: 5.0934 - val_accuracy: 0.5182\n",
      "Epoch 389/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.3065 - accuracy: 0.5184 - val_loss: 5.0269 - val_accuracy: 0.5635\n",
      "Epoch 390/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2446 - accuracy: 0.5330 - val_loss: 5.0265 - val_accuracy: 0.5363\n",
      "Epoch 391/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2053 - accuracy: 0.5235 - val_loss: 5.0199 - val_accuracy: 0.5673\n",
      "Epoch 392/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2091 - accuracy: 0.5298 - val_loss: 4.9987 - val_accuracy: 0.5673\n",
      "Epoch 393/400\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 5.2627 - accuracy: 0.5219 - val_loss: 5.1022 - val_accuracy: 0.5522\n",
      "Epoch 394/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2025 - accuracy: 0.5293 - val_loss: 5.0129 - val_accuracy: 0.5227\n",
      "Epoch 395/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2069 - accuracy: 0.5230 - val_loss: 5.0392 - val_accuracy: 0.5234\n",
      "Epoch 396/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2424 - accuracy: 0.5308 - val_loss: 4.9768 - val_accuracy: 0.5371\n",
      "Epoch 397/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2384 - accuracy: 0.5212 - val_loss: 5.1112 - val_accuracy: 0.4902\n",
      "Epoch 398/400\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.2532 - accuracy: 0.5290 - val_loss: 5.0666 - val_accuracy: 0.5227\n",
      "Epoch 399/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.1933 - accuracy: 0.5247 - val_loss: 4.9584 - val_accuracy: 0.5446\n",
      "Epoch 400/400\n",
      "248/248 [==============================] - 3s 11ms/step - loss: 5.2111 - accuracy: 0.5262 - val_loss: 5.0337 - val_accuracy: 0.4856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a0adc4df0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegnet_model.fit(X_train, y_train, epochs=400, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57fbc32a-5d49-4ee9-a58d-eb476d7e32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = eegnet_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "492a2a4d-a83a-481d-b1eb-ce63d5f3844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9390652 , 2.7643921 , 4.784956  , 5.2399516 ],\n",
       "       [2.9390652 , 2.7643921 , 4.784956  , 5.2399516 ],\n",
       "       [2.9390652 , 2.7643921 , 4.784956  , 5.2399516 ],\n",
       "       ...,\n",
       "       [0.11698437, 9.671267  , 3.1689525 , 0.43675852],\n",
       "       [2.9390652 , 2.7643921 , 4.784956  , 5.2399516 ],\n",
       "       [2.9390652 , 2.7643921 , 4.784956  , 5.2399516 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9970e24-c274-475e-a914-d91d01d05881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  3,  9],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 1,  1,  8,  8],\n",
       "       ...,\n",
       "       [ 1,  9,  4,  1],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  5,  7,  1]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed8599-bfc6-40e2-8569-67107299215d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
