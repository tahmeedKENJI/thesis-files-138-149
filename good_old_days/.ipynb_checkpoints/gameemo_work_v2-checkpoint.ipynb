{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113091eb-ae2e-44ae-92e9-93dd8d8f19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87484007-653e-4ae9-b363-52bd1f045fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e46f74f-6914-4c7b-927f-bc42f6a60011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Boring</th>\n",
       "      <th>Horrible</th>\n",
       "      <th>Calm</th>\n",
       "      <th>Funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Boring  Horrible  Calm  Funny\n",
       "0          1       8         1     3      2\n",
       "1          1       2         1     8      8\n",
       "2          1       2         8     1      1\n",
       "3          1       1         1     3      9\n",
       "4          2       8         1     4      2\n",
       "..       ...     ...       ...   ...    ...\n",
       "107       27       1         1     7      5\n",
       "108       28       7         1     6      1\n",
       "109       28       1         1     8      8\n",
       "110       28       1         7     6      1\n",
       "111       28       1         1     7      7\n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_folder = 'gameemo_database_epochs'\n",
    "epochs_psd_folder = 'gameemo_database_epochs_psd'\n",
    "epochs_ica_folder = 'gameemo_database_epochs_ica'\n",
    "current_dir = epochs_ica_folder \n",
    "labels_path = 'GameLabels\\GAMEEMO_SCORES.xlsx'\n",
    "labels_sheet = 'All'\n",
    "labels_file = pd.read_excel(labels_path, labels_sheet)\n",
    "labels_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ab4f72-dbb4-4008-979f-dbec8f3f6c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  3,  2],\n",
       "       [ 2,  1,  8,  8],\n",
       "       [ 2,  8,  1,  1],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 8,  1,  4,  2],\n",
       "       [ 2,  1,  7,  6],\n",
       "       [ 2,  8,  3,  2],\n",
       "       [ 2,  2,  7,  9],\n",
       "       [ 7,  2,  6,  1],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 8,  1,  3,  1],\n",
       "       [ 3,  1,  9,  6],\n",
       "       [ 1,  9,  2,  1],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 7,  1,  2,  1],\n",
       "       [ 2,  1,  5,  7],\n",
       "       [ 1,  8,  1,  2],\n",
       "       [ 2,  1,  3,  8],\n",
       "       [ 7,  1,  3,  1],\n",
       "       [ 1,  1,  7,  3],\n",
       "       [ 1,  8,  1,  1],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 8,  1,  3,  3],\n",
       "       [ 3,  1,  8,  6],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  1, 10],\n",
       "       [10,  1,  1,  1],\n",
       "       [ 3,  1,  8,  8],\n",
       "       [ 1,  5,  7,  1],\n",
       "       [ 1,  1,  6,  6],\n",
       "       [10,  1,  4,  4],\n",
       "       [ 1,  1,  8,  6],\n",
       "       [ 1,  9,  2,  3],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 8,  1,  5,  4],\n",
       "       [ 1,  1,  7,  2],\n",
       "       [ 1,  8,  2,  1],\n",
       "       [ 1,  1,  5, 10],\n",
       "       [ 7,  1,  7,  4],\n",
       "       [ 1,  1,  8,  6],\n",
       "       [ 7,  8,  2,  3],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 9,  1,  7,  4],\n",
       "       [ 1,  1,  5,  8],\n",
       "       [ 1,  6,  2,  3],\n",
       "       [ 1,  2,  5,  6],\n",
       "       [ 4,  1,  7,  7],\n",
       "       [ 6,  1,  7,  3],\n",
       "       [ 1,  8,  4,  2],\n",
       "       [ 1,  2,  7,  9],\n",
       "       [ 8,  1,  8,  2],\n",
       "       [ 3,  1,  6,  7],\n",
       "       [ 1,  8,  2,  4],\n",
       "       [ 1,  2,  4, 10],\n",
       "       [ 7,  1,  7,  3],\n",
       "       [ 3,  1,  9,  7],\n",
       "       [ 1,  8,  2,  2],\n",
       "       [ 3,  1,  1,  8],\n",
       "       [ 8,  1,  8,  2],\n",
       "       [ 2,  1,  8,  6],\n",
       "       [ 1,  9,  4,  1],\n",
       "       [ 1,  2,  2,  7],\n",
       "       [ 7,  1,  8,  3],\n",
       "       [ 3,  1,  7,  7],\n",
       "       [ 1,  7,  4,  3],\n",
       "       [ 1,  1,  2,  6],\n",
       "       [ 2,  1,  8,  7],\n",
       "       [ 3,  1,  6,  5],\n",
       "       [ 2,  6,  3,  3],\n",
       "       [ 1,  1,  2,  7],\n",
       "       [ 3,  6,  2,  7],\n",
       "       [ 7,  1,  6,  3],\n",
       "       [ 3,  6,  3,  4],\n",
       "       [ 1,  1,  4,  9],\n",
       "       [ 8,  1,  7,  2],\n",
       "       [ 2,  1,  7,  7],\n",
       "       [ 1, 10,  2,  1],\n",
       "       [ 1,  1,  5,  8],\n",
       "       [10,  1, 10,  1],\n",
       "       [ 2,  1,  6,  7],\n",
       "       [ 2, 10,  1,  1],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 9,  1,  7,  2],\n",
       "       [ 2,  1,  8,  8],\n",
       "       [ 1,  8,  3,  3],\n",
       "       [ 1,  1,  1,  6],\n",
       "       [ 9,  1,  8,  2],\n",
       "       [ 3,  1,  9,  6],\n",
       "       [ 1,  6,  5,  8],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 7,  1,  8,  3],\n",
       "       [ 5,  1,  7,  6],\n",
       "       [ 3,  7,  5,  5],\n",
       "       [ 1,  1,  6,  8],\n",
       "       [ 9,  1,  8,  3],\n",
       "       [ 2,  1,  7,  6],\n",
       "       [ 1,  6,  3,  4],\n",
       "       [ 1,  1,  3,  9],\n",
       "       [ 8,  1,  6,  6],\n",
       "       [ 2,  1,  7,  2],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  5,  7],\n",
       "       [ 6,  1,  8,  2],\n",
       "       [ 1,  1, 10,  8],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  1,  7,  5],\n",
       "       [ 7,  1,  6,  1],\n",
       "       [ 1,  1,  8,  8],\n",
       "       [ 1,  7,  6,  1],\n",
       "       [ 1,  1,  7,  7]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array = np.array(labels_file[['Boring', 'Horrible', 'Calm', 'Funny']])\n",
    "labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9f5dce-4859-4ebf-9387-378ed5cb7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:36<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(epochs_folder)):\n",
    "    for game in os.listdir(os.path.join(epochs_folder, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(epochs_folder, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(epochs_folder, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T\n",
    "            epochs_data.append(np.array(read_epoch))\n",
    "            labels_data.append(labels_array[k-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2417c246-a08d-4a59-a298-ced2092ead18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:19<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(epochs_psd_folder)):\n",
    "    for game in os.listdir(os.path.join(epochs_psd_folder, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(epochs_psd_folder, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(epochs_psd_folder, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T\n",
    "            epochs_data.append(np.array(read_epoch))\n",
    "            labels_data.append(labels_array[k-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dcf293c-cc2a-4677-be2f-d944e7a065f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:51<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = []\n",
    "labels_data = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for subject in tqdm(os.listdir(current_dir)):\n",
    "    for game in os.listdir(os.path.join(current_dir, subject)):\n",
    "        k+=1\n",
    "        for epoch in os.listdir(os.path.join(current_dir, subject, game)):\n",
    "            read_epoch = pd.read_csv(os.path.join(current_dir, subject, game, epoch))\n",
    "            read_epoch = read_epoch[channels].T\n",
    "            epochs_data.append(np.array(read_epoch))\n",
    "            labels_data.append(labels_array[k-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f53713-f204-4754-b7ed-96552ba3ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 641) (4,)\n"
     ]
    }
   ],
   "source": [
    "print((epochs_data[0].shape), (labels_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d439a3dd-d753-4a30-b34c-e322d46c02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 14, 641) (6608, 4)\n"
     ]
    }
   ],
   "source": [
    "main_data = np.array(epochs_data)\n",
    "main_labels = np.array(labels_data)\n",
    "print(main_data.shape, main_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98664953-7364-4d91-be51-e2685256010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3964, 14, 641) (3964, 4)\n",
      "Validation set shape: (1322, 14, 641) (1322, 4)\n",
      "Testing set shape: (1322, 14, 641) (1322, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into training+validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(main_data, main_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6110800-bc66-4777-b51a-64427d847f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2caf0f20-2e45-4be6-8e5f-14f8d12fd348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75c3805-8a1c-4015-9f0f-df2a46b4f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def EEGNet(nb_classes = 4, Chans = 14, Samples = 129, \n",
    "#              dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "#              D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "def EEGNet(nb_classes = 4, Chans = 14, Samples = 641, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 4, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    # input1   = Input(shape = (Chans, Samples, 1))\n",
    "    # block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "    #                                input_shape = (Chans, Samples, 1),\n",
    "    #                                use_bias = False)(input1)\n",
    "    # block1       = BatchNormalization()(block1)\n",
    "    # block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "    #                                depth_multiplier = D,\n",
    "    #                                depthwise_constraint = max_norm(1.))(block1)\n",
    "    # block1       = BatchNormalization()(block1)\n",
    "    # block1       = Activation('elu')(block1)\n",
    "    # block1       = AveragePooling2D((1, 4))(block1)\n",
    "    # block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    # block2       = SeparableConv2D(F2, (1, 16),\n",
    "    #                                use_bias = False, padding = 'same')(block1)\n",
    "    # block2       = BatchNormalization()(block2)\n",
    "    # block2       = Activation('elu')(block2)\n",
    "    # block2       = AveragePooling2D((1, 8))(block2)\n",
    "    # block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    # flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    # dense        = Dense(nb_classes, name = 'dense', \n",
    "    #                      kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    # # softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    # output      = Activation('linear', name = 'linear')(dense)\n",
    "    # return Model(inputs=input1, outputs=output)\n",
    "\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    # block1       = Conv2D(25, (Chans, 1),\n",
    "    #                              kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = Conv2D(25, (Chans, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block4)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    output      = Activation('linear')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991eff3f-2eed-4b76-a7ee-d2769c429604",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model = EEGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e45189f2-ccf9-443a-b17b-6527587921d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 641, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 637, 25)       150       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 637, 25)      100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 14, 637, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 318, 25)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 318, 25)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 314, 50)       6300      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 314, 50)      200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 314, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 157, 50)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 157, 50)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 153, 100)      25100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 153, 100)     400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14, 153, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 76, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 76, 100)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 72, 200)       100200    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 72, 25)         70025     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 72, 25)        100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1, 72, 25)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 36, 25)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 36, 25)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 900)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 3604      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206,179\n",
      "Trainable params: 205,779\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eegnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b72f519-1158-4274-ba9f-77aab74c7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2763bcc-b3d4-435f-91da-811bac9b2fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "248/248 [==============================] - 5s 18ms/step - loss: 2.7797 - accuracy: 0.7344 - val_loss: 2.0915 - val_accuracy: 0.8200\n",
      "Epoch 2/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8949 - accuracy: 0.7260 - val_loss: 2.2174 - val_accuracy: 0.7005\n",
      "Epoch 3/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7586 - accuracy: 0.7422 - val_loss: 2.9455 - val_accuracy: 0.7511\n",
      "Epoch 4/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8324 - accuracy: 0.7260 - val_loss: 1.8850 - val_accuracy: 0.7489\n",
      "Epoch 5/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8886 - accuracy: 0.7278 - val_loss: 2.1411 - val_accuracy: 0.7050\n",
      "Epoch 6/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8337 - accuracy: 0.7341 - val_loss: 2.1636 - val_accuracy: 0.7413\n",
      "Epoch 7/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7515 - accuracy: 0.7364 - val_loss: 4.9820 - val_accuracy: 0.5484\n",
      "Epoch 8/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7668 - accuracy: 0.7268 - val_loss: 2.0713 - val_accuracy: 0.7829\n",
      "Epoch 9/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7291 - accuracy: 0.7455 - val_loss: 2.3598 - val_accuracy: 0.6861\n",
      "Epoch 10/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8603 - accuracy: 0.7253 - val_loss: 4.6541 - val_accuracy: 0.5401\n",
      "Epoch 11/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8035 - accuracy: 0.7321 - val_loss: 3.8531 - val_accuracy: 0.8593\n",
      "Epoch 12/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7755 - accuracy: 0.7376 - val_loss: 2.1543 - val_accuracy: 0.6664\n",
      "Epoch 13/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7949 - accuracy: 0.7379 - val_loss: 3.1892 - val_accuracy: 0.7496\n",
      "Epoch 14/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8478 - accuracy: 0.7197 - val_loss: 2.4533 - val_accuracy: 0.6354\n",
      "Epoch 15/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7820 - accuracy: 0.7402 - val_loss: 2.2358 - val_accuracy: 0.6936\n",
      "Epoch 16/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7306 - accuracy: 0.7434 - val_loss: 1.8306 - val_accuracy: 0.7716\n",
      "Epoch 17/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8204 - accuracy: 0.7265 - val_loss: 5.9210 - val_accuracy: 0.6195\n",
      "Epoch 18/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7522 - accuracy: 0.7344 - val_loss: 4.9559 - val_accuracy: 0.7360\n",
      "Epoch 19/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7899 - accuracy: 0.7318 - val_loss: 5.4904 - val_accuracy: 0.6520\n",
      "Epoch 20/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7470 - accuracy: 0.7374 - val_loss: 2.6701 - val_accuracy: 0.7874\n",
      "Epoch 21/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7816 - accuracy: 0.7369 - val_loss: 3.2216 - val_accuracy: 0.7655\n",
      "Epoch 22/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7749 - accuracy: 0.7392 - val_loss: 2.4246 - val_accuracy: 0.8843\n",
      "Epoch 23/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8005 - accuracy: 0.7351 - val_loss: 5.9932 - val_accuracy: 0.6483\n",
      "Epoch 24/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8131 - accuracy: 0.7361 - val_loss: 4.1067 - val_accuracy: 0.6702\n",
      "Epoch 25/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8460 - accuracy: 0.7275 - val_loss: 2.9237 - val_accuracy: 0.7458\n",
      "Epoch 26/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8032 - accuracy: 0.7344 - val_loss: 2.5270 - val_accuracy: 0.7088\n",
      "Epoch 27/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8029 - accuracy: 0.7384 - val_loss: 2.2776 - val_accuracy: 0.7322\n",
      "Epoch 28/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7767 - accuracy: 0.7414 - val_loss: 3.2649 - val_accuracy: 0.8192\n",
      "Epoch 29/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.9151 - accuracy: 0.7296 - val_loss: 3.0447 - val_accuracy: 0.6430\n",
      "Epoch 30/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7874 - accuracy: 0.7397 - val_loss: 3.9965 - val_accuracy: 0.6566\n",
      "Epoch 31/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8352 - accuracy: 0.7316 - val_loss: 3.2525 - val_accuracy: 0.6952\n",
      "Epoch 32/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8316 - accuracy: 0.7321 - val_loss: 5.8547 - val_accuracy: 0.5900\n",
      "Epoch 33/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8043 - accuracy: 0.7361 - val_loss: 2.6846 - val_accuracy: 0.8268\n",
      "Epoch 34/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7199 - accuracy: 0.7397 - val_loss: 3.0789 - val_accuracy: 0.6467\n",
      "Epoch 35/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8027 - accuracy: 0.7412 - val_loss: 2.7719 - val_accuracy: 0.6354\n",
      "Epoch 36/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7462 - accuracy: 0.7392 - val_loss: 1.8998 - val_accuracy: 0.8079\n",
      "Epoch 37/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8530 - accuracy: 0.7354 - val_loss: 1.7889 - val_accuracy: 0.8056\n",
      "Epoch 38/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8441 - accuracy: 0.7281 - val_loss: 1.9268 - val_accuracy: 0.8328\n",
      "Epoch 39/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8220 - accuracy: 0.7263 - val_loss: 5.9250 - val_accuracy: 0.5809\n",
      "Epoch 40/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7745 - accuracy: 0.7351 - val_loss: 2.2791 - val_accuracy: 0.8147\n",
      "Epoch 41/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7149 - accuracy: 0.7414 - val_loss: 2.2024 - val_accuracy: 0.8351\n",
      "Epoch 42/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8263 - accuracy: 0.7346 - val_loss: 3.6982 - val_accuracy: 0.7390\n",
      "Epoch 43/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8108 - accuracy: 0.7336 - val_loss: 3.5778 - val_accuracy: 0.6392\n",
      "Epoch 44/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8375 - accuracy: 0.7248 - val_loss: 5.9110 - val_accuracy: 0.5923\n",
      "Epoch 45/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7163 - accuracy: 0.7270 - val_loss: 1.9150 - val_accuracy: 0.7912\n",
      "Epoch 46/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6531 - accuracy: 0.7437 - val_loss: 2.7112 - val_accuracy: 0.6505\n",
      "Epoch 47/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7421 - accuracy: 0.7445 - val_loss: 1.7350 - val_accuracy: 0.7126\n",
      "Epoch 48/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7398 - accuracy: 0.7450 - val_loss: 3.1334 - val_accuracy: 0.6732\n",
      "Epoch 49/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7457 - accuracy: 0.7414 - val_loss: 6.5080 - val_accuracy: 0.6225\n",
      "Epoch 50/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8734 - accuracy: 0.7291 - val_loss: 3.4146 - val_accuracy: 0.7209\n",
      "Epoch 51/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6694 - accuracy: 0.7386 - val_loss: 2.3293 - val_accuracy: 0.6672\n",
      "Epoch 52/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7856 - accuracy: 0.7404 - val_loss: 2.7593 - val_accuracy: 0.8638\n",
      "Epoch 53/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7504 - accuracy: 0.7361 - val_loss: 1.8728 - val_accuracy: 0.8495\n",
      "Epoch 54/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7090 - accuracy: 0.7467 - val_loss: 5.1145 - val_accuracy: 0.7035\n",
      "Epoch 55/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8022 - accuracy: 0.7414 - val_loss: 2.9817 - val_accuracy: 0.6551\n",
      "Epoch 56/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6933 - accuracy: 0.7341 - val_loss: 3.5376 - val_accuracy: 0.7118\n",
      "Epoch 57/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7543 - accuracy: 0.7460 - val_loss: 3.4500 - val_accuracy: 0.6702\n",
      "Epoch 58/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7496 - accuracy: 0.7470 - val_loss: 2.9977 - val_accuracy: 0.6021\n",
      "Epoch 59/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8055 - accuracy: 0.7308 - val_loss: 1.8766 - val_accuracy: 0.8071\n",
      "Epoch 60/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7144 - accuracy: 0.7465 - val_loss: 3.3908 - val_accuracy: 0.7057\n",
      "Epoch 61/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7773 - accuracy: 0.7409 - val_loss: 6.3536 - val_accuracy: 0.5930\n",
      "Epoch 62/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8407 - accuracy: 0.7349 - val_loss: 3.6919 - val_accuracy: 0.5666\n",
      "Epoch 63/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8077 - accuracy: 0.7477 - val_loss: 1.8961 - val_accuracy: 0.7148\n",
      "Epoch 64/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8219 - accuracy: 0.7288 - val_loss: 6.5251 - val_accuracy: 0.3510\n",
      "Epoch 65/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7319 - accuracy: 0.7386 - val_loss: 4.4742 - val_accuracy: 0.7269\n",
      "Epoch 66/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7657 - accuracy: 0.7359 - val_loss: 2.8813 - val_accuracy: 0.7708\n",
      "Epoch 67/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6851 - accuracy: 0.7404 - val_loss: 5.6851 - val_accuracy: 0.4387\n",
      "Epoch 68/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6716 - accuracy: 0.7495 - val_loss: 3.6857 - val_accuracy: 0.6309\n",
      "Epoch 69/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7664 - accuracy: 0.7399 - val_loss: 3.4667 - val_accuracy: 0.6346\n",
      "Epoch 70/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7762 - accuracy: 0.7288 - val_loss: 3.6525 - val_accuracy: 0.6846\n",
      "Epoch 71/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6451 - accuracy: 0.7397 - val_loss: 2.2885 - val_accuracy: 0.8260\n",
      "Epoch 72/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7634 - accuracy: 0.7339 - val_loss: 2.9519 - val_accuracy: 0.6710\n",
      "Epoch 73/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7561 - accuracy: 0.7303 - val_loss: 9.8792 - val_accuracy: 0.4939\n",
      "Epoch 74/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7043 - accuracy: 0.7366 - val_loss: 2.3616 - val_accuracy: 0.6528\n",
      "Epoch 75/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7951 - accuracy: 0.7228 - val_loss: 2.2644 - val_accuracy: 0.7610\n",
      "Epoch 76/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7217 - accuracy: 0.7497 - val_loss: 2.3429 - val_accuracy: 0.6687\n",
      "Epoch 77/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.8082 - accuracy: 0.7323 - val_loss: 2.3817 - val_accuracy: 0.6800\n",
      "Epoch 78/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6920 - accuracy: 0.7412 - val_loss: 1.9928 - val_accuracy: 0.7950\n",
      "Epoch 79/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7041 - accuracy: 0.7588 - val_loss: 3.3927 - val_accuracy: 0.7073\n",
      "Epoch 80/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6709 - accuracy: 0.7465 - val_loss: 3.4673 - val_accuracy: 0.7088\n",
      "Epoch 81/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6769 - accuracy: 0.7518 - val_loss: 1.7544 - val_accuracy: 0.7988\n",
      "Epoch 82/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7411 - accuracy: 0.7414 - val_loss: 3.5658 - val_accuracy: 0.7678\n",
      "Epoch 83/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6539 - accuracy: 0.7404 - val_loss: 3.2149 - val_accuracy: 0.6029\n",
      "Epoch 84/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7022 - accuracy: 0.7429 - val_loss: 3.6110 - val_accuracy: 0.7156\n",
      "Epoch 85/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6674 - accuracy: 0.7487 - val_loss: 2.4699 - val_accuracy: 0.8154\n",
      "Epoch 86/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6759 - accuracy: 0.7508 - val_loss: 2.3584 - val_accuracy: 0.6755\n",
      "Epoch 87/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7528 - accuracy: 0.7364 - val_loss: 2.1059 - val_accuracy: 0.7042\n",
      "Epoch 88/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6622 - accuracy: 0.7480 - val_loss: 3.8526 - val_accuracy: 0.8139\n",
      "Epoch 89/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7024 - accuracy: 0.7414 - val_loss: 2.1226 - val_accuracy: 0.7731\n",
      "Epoch 90/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7380 - accuracy: 0.7450 - val_loss: 2.9975 - val_accuracy: 0.7988\n",
      "Epoch 91/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7156 - accuracy: 0.7465 - val_loss: 2.4807 - val_accuracy: 0.6467\n",
      "Epoch 92/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7098 - accuracy: 0.7392 - val_loss: 2.5701 - val_accuracy: 0.6740\n",
      "Epoch 93/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7178 - accuracy: 0.7386 - val_loss: 2.8550 - val_accuracy: 0.6422\n",
      "Epoch 94/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6831 - accuracy: 0.7404 - val_loss: 5.1864 - val_accuracy: 0.6589\n",
      "Epoch 95/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6647 - accuracy: 0.7414 - val_loss: 3.1218 - val_accuracy: 0.6596\n",
      "Epoch 96/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7578 - accuracy: 0.7318 - val_loss: 2.1673 - val_accuracy: 0.7648\n",
      "Epoch 97/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7079 - accuracy: 0.7389 - val_loss: 2.0044 - val_accuracy: 0.7330\n",
      "Epoch 98/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6346 - accuracy: 0.7523 - val_loss: 2.3901 - val_accuracy: 0.6823\n",
      "Epoch 99/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7199 - accuracy: 0.7472 - val_loss: 2.7413 - val_accuracy: 0.8616\n",
      "Epoch 100/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6837 - accuracy: 0.7354 - val_loss: 2.4243 - val_accuracy: 0.7542\n",
      "Epoch 101/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6203 - accuracy: 0.7503 - val_loss: 2.2239 - val_accuracy: 0.7504\n",
      "Epoch 102/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6961 - accuracy: 0.7465 - val_loss: 2.1900 - val_accuracy: 0.6747\n",
      "Epoch 103/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7284 - accuracy: 0.7407 - val_loss: 2.6189 - val_accuracy: 0.8404\n",
      "Epoch 104/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6683 - accuracy: 0.7508 - val_loss: 2.6138 - val_accuracy: 0.6369\n",
      "Epoch 105/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.8207 - accuracy: 0.7409 - val_loss: 2.4212 - val_accuracy: 0.7882\n",
      "Epoch 106/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6897 - accuracy: 0.7364 - val_loss: 2.0713 - val_accuracy: 0.7277\n",
      "Epoch 107/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6794 - accuracy: 0.7366 - val_loss: 2.2813 - val_accuracy: 0.7179\n",
      "Epoch 108/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6636 - accuracy: 0.7611 - val_loss: 3.2308 - val_accuracy: 0.7489\n",
      "Epoch 109/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7258 - accuracy: 0.7399 - val_loss: 1.9442 - val_accuracy: 0.7511\n",
      "Epoch 110/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6545 - accuracy: 0.7513 - val_loss: 2.2536 - val_accuracy: 0.7254\n",
      "Epoch 111/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7629 - accuracy: 0.7394 - val_loss: 5.1996 - val_accuracy: 0.5507\n",
      "Epoch 112/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7488 - accuracy: 0.7480 - val_loss: 2.3798 - val_accuracy: 0.7716\n",
      "Epoch 113/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7615 - accuracy: 0.7437 - val_loss: 2.0837 - val_accuracy: 0.7511\n",
      "Epoch 114/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6757 - accuracy: 0.7465 - val_loss: 5.0554 - val_accuracy: 0.7163\n",
      "Epoch 115/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7241 - accuracy: 0.7291 - val_loss: 2.7367 - val_accuracy: 0.7005\n",
      "Epoch 116/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7019 - accuracy: 0.7422 - val_loss: 1.9663 - val_accuracy: 0.7995\n",
      "Epoch 117/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6334 - accuracy: 0.7566 - val_loss: 2.2912 - val_accuracy: 0.7519\n",
      "Epoch 118/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6506 - accuracy: 0.7545 - val_loss: 2.6831 - val_accuracy: 0.7496\n",
      "Epoch 119/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6633 - accuracy: 0.7450 - val_loss: 2.6995 - val_accuracy: 0.7519\n",
      "Epoch 120/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.7064 - accuracy: 0.7508 - val_loss: 2.3817 - val_accuracy: 0.7095\n",
      "Epoch 121/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6236 - accuracy: 0.7462 - val_loss: 1.8458 - val_accuracy: 0.6952\n",
      "Epoch 122/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7134 - accuracy: 0.7447 - val_loss: 2.5121 - val_accuracy: 0.7148\n",
      "Epoch 123/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6383 - accuracy: 0.7495 - val_loss: 1.7618 - val_accuracy: 0.7254\n",
      "Epoch 124/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7520 - accuracy: 0.7462 - val_loss: 2.4852 - val_accuracy: 0.7890\n",
      "Epoch 125/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6905 - accuracy: 0.7376 - val_loss: 5.9978 - val_accuracy: 0.6657\n",
      "Epoch 126/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6496 - accuracy: 0.7515 - val_loss: 1.9432 - val_accuracy: 0.7920\n",
      "Epoch 127/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5864 - accuracy: 0.7497 - val_loss: 2.1945 - val_accuracy: 0.6120\n",
      "Epoch 128/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7411 - accuracy: 0.7389 - val_loss: 3.1393 - val_accuracy: 0.7897\n",
      "Epoch 129/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6022 - accuracy: 0.7518 - val_loss: 3.4895 - val_accuracy: 0.8003\n",
      "Epoch 130/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6182 - accuracy: 0.7553 - val_loss: 3.5496 - val_accuracy: 0.8336\n",
      "Epoch 131/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7069 - accuracy: 0.7334 - val_loss: 2.6898 - val_accuracy: 0.7413\n",
      "Epoch 132/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6458 - accuracy: 0.7495 - val_loss: 2.2060 - val_accuracy: 0.7890\n",
      "Epoch 133/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7048 - accuracy: 0.7492 - val_loss: 2.6868 - val_accuracy: 0.6884\n",
      "Epoch 134/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6728 - accuracy: 0.7480 - val_loss: 4.0257 - val_accuracy: 0.7163\n",
      "Epoch 135/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7161 - accuracy: 0.7384 - val_loss: 1.9751 - val_accuracy: 0.8101\n",
      "Epoch 136/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6392 - accuracy: 0.7591 - val_loss: 3.4203 - val_accuracy: 0.7405\n",
      "Epoch 137/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6882 - accuracy: 0.7409 - val_loss: 2.6730 - val_accuracy: 0.6430\n",
      "Epoch 138/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7354 - accuracy: 0.7462 - val_loss: 2.6569 - val_accuracy: 0.7194\n",
      "Epoch 139/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6201 - accuracy: 0.7523 - val_loss: 1.9543 - val_accuracy: 0.8011\n",
      "Epoch 140/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6843 - accuracy: 0.7452 - val_loss: 2.8135 - val_accuracy: 0.7035\n",
      "Epoch 141/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6008 - accuracy: 0.7540 - val_loss: 2.6473 - val_accuracy: 0.7965\n",
      "Epoch 142/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7042 - accuracy: 0.7437 - val_loss: 5.0537 - val_accuracy: 0.5870\n",
      "Epoch 143/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6600 - accuracy: 0.7392 - val_loss: 2.9564 - val_accuracy: 0.6641\n",
      "Epoch 144/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5745 - accuracy: 0.7500 - val_loss: 2.2956 - val_accuracy: 0.6785\n",
      "Epoch 145/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6370 - accuracy: 0.7434 - val_loss: 2.4179 - val_accuracy: 0.7436\n",
      "Epoch 146/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6927 - accuracy: 0.7334 - val_loss: 2.6920 - val_accuracy: 0.7133\n",
      "Epoch 147/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6549 - accuracy: 0.7422 - val_loss: 2.4239 - val_accuracy: 0.8502\n",
      "Epoch 148/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5923 - accuracy: 0.7576 - val_loss: 4.2274 - val_accuracy: 0.7405\n",
      "Epoch 149/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7162 - accuracy: 0.7434 - val_loss: 2.6815 - val_accuracy: 0.6067\n",
      "Epoch 150/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6603 - accuracy: 0.7510 - val_loss: 5.1420 - val_accuracy: 0.6346\n",
      "Epoch 151/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6211 - accuracy: 0.7497 - val_loss: 2.7542 - val_accuracy: 0.6392\n",
      "Epoch 152/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5831 - accuracy: 0.7452 - val_loss: 2.1263 - val_accuracy: 0.8411\n",
      "Epoch 153/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6017 - accuracy: 0.7525 - val_loss: 2.5781 - val_accuracy: 0.7224\n",
      "Epoch 154/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5425 - accuracy: 0.7500 - val_loss: 1.9136 - val_accuracy: 0.8003\n",
      "Epoch 155/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6929 - accuracy: 0.7386 - val_loss: 2.1490 - val_accuracy: 0.7761\n",
      "Epoch 156/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7271 - accuracy: 0.7427 - val_loss: 2.4136 - val_accuracy: 0.7352\n",
      "Epoch 157/200\n",
      "248/248 [==============================] - 4s 17ms/step - loss: 2.6557 - accuracy: 0.7497 - val_loss: 2.9962 - val_accuracy: 0.7345\n",
      "Epoch 158/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6682 - accuracy: 0.7455 - val_loss: 2.0663 - val_accuracy: 0.7882\n",
      "Epoch 159/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5218 - accuracy: 0.7523 - val_loss: 1.9782 - val_accuracy: 0.7088\n",
      "Epoch 160/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6501 - accuracy: 0.7467 - val_loss: 2.2439 - val_accuracy: 0.6415\n",
      "Epoch 161/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6971 - accuracy: 0.7437 - val_loss: 2.4361 - val_accuracy: 0.7012\n",
      "Epoch 162/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7238 - accuracy: 0.7460 - val_loss: 2.6573 - val_accuracy: 0.6853\n",
      "Epoch 163/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6638 - accuracy: 0.7528 - val_loss: 2.4974 - val_accuracy: 0.7874\n",
      "Epoch 164/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6970 - accuracy: 0.7424 - val_loss: 2.3560 - val_accuracy: 0.7579\n",
      "Epoch 165/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6685 - accuracy: 0.7533 - val_loss: 6.5922 - val_accuracy: 0.5121\n",
      "Epoch 166/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6389 - accuracy: 0.7528 - val_loss: 2.2297 - val_accuracy: 0.7065\n",
      "Epoch 167/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6482 - accuracy: 0.7371 - val_loss: 2.1789 - val_accuracy: 0.7375\n",
      "Epoch 168/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5484 - accuracy: 0.7503 - val_loss: 2.4077 - val_accuracy: 0.8359\n",
      "Epoch 169/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6358 - accuracy: 0.7550 - val_loss: 3.2096 - val_accuracy: 0.6891\n",
      "Epoch 170/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5688 - accuracy: 0.7558 - val_loss: 2.9557 - val_accuracy: 0.6278\n",
      "Epoch 171/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6649 - accuracy: 0.7472 - val_loss: 2.5313 - val_accuracy: 0.8321\n",
      "Epoch 172/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6192 - accuracy: 0.7495 - val_loss: 2.4668 - val_accuracy: 0.7534\n",
      "Epoch 173/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5842 - accuracy: 0.7571 - val_loss: 2.2070 - val_accuracy: 0.7648\n",
      "Epoch 174/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6848 - accuracy: 0.7553 - val_loss: 4.8881 - val_accuracy: 0.6392\n",
      "Epoch 175/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5783 - accuracy: 0.7538 - val_loss: 3.2400 - val_accuracy: 0.7587\n",
      "Epoch 176/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.7017 - accuracy: 0.7445 - val_loss: 6.4239 - val_accuracy: 0.5424\n",
      "Epoch 177/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5911 - accuracy: 0.7606 - val_loss: 2.4210 - val_accuracy: 0.8064\n",
      "Epoch 178/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6728 - accuracy: 0.7404 - val_loss: 2.3737 - val_accuracy: 0.7716\n",
      "Epoch 179/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6101 - accuracy: 0.7573 - val_loss: 2.2445 - val_accuracy: 0.7375\n",
      "Epoch 180/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6234 - accuracy: 0.7467 - val_loss: 3.6451 - val_accuracy: 0.6316\n",
      "Epoch 181/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5850 - accuracy: 0.7540 - val_loss: 4.0941 - val_accuracy: 0.8616\n",
      "Epoch 182/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5706 - accuracy: 0.7482 - val_loss: 2.5678 - val_accuracy: 0.7769\n",
      "Epoch 183/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5619 - accuracy: 0.7631 - val_loss: 3.8209 - val_accuracy: 0.7035\n",
      "Epoch 184/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6632 - accuracy: 0.7447 - val_loss: 2.2812 - val_accuracy: 0.7179\n",
      "Epoch 185/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6254 - accuracy: 0.7545 - val_loss: 2.4928 - val_accuracy: 0.7648\n",
      "Epoch 186/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5799 - accuracy: 0.7535 - val_loss: 2.7662 - val_accuracy: 0.8101\n",
      "Epoch 187/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6273 - accuracy: 0.7495 - val_loss: 2.5046 - val_accuracy: 0.7920\n",
      "Epoch 188/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5166 - accuracy: 0.7535 - val_loss: 2.9675 - val_accuracy: 0.7700\n",
      "Epoch 189/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6448 - accuracy: 0.7555 - val_loss: 3.4109 - val_accuracy: 0.5998\n",
      "Epoch 190/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6242 - accuracy: 0.7404 - val_loss: 4.5074 - val_accuracy: 0.5915\n",
      "Epoch 191/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6254 - accuracy: 0.7545 - val_loss: 2.6655 - val_accuracy: 0.7269\n",
      "Epoch 192/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6017 - accuracy: 0.7434 - val_loss: 2.8226 - val_accuracy: 0.6967\n",
      "Epoch 193/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6698 - accuracy: 0.7492 - val_loss: 2.9861 - val_accuracy: 0.7927\n",
      "Epoch 194/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5568 - accuracy: 0.7616 - val_loss: 2.8148 - val_accuracy: 0.6740\n",
      "Epoch 195/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6270 - accuracy: 0.7513 - val_loss: 5.1265 - val_accuracy: 0.6014\n",
      "Epoch 196/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5404 - accuracy: 0.7555 - val_loss: 4.4173 - val_accuracy: 0.6906\n",
      "Epoch 197/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6372 - accuracy: 0.7497 - val_loss: 3.1440 - val_accuracy: 0.7716\n",
      "Epoch 198/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6101 - accuracy: 0.7508 - val_loss: 2.2865 - val_accuracy: 0.8192\n",
      "Epoch 199/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.6433 - accuracy: 0.7465 - val_loss: 3.8525 - val_accuracy: 0.6778\n",
      "Epoch 200/200\n",
      "248/248 [==============================] - 4s 18ms/step - loss: 2.5909 - accuracy: 0.7523 - val_loss: 2.4176 - val_accuracy: 0.7890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209b7c45600>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegnet_model.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf31224e-020b-4ab0-af83-bac0f8f0a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = eegnet_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a4d3791-9b1d-48a6-a67c-b881a1fa1914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.6464055 ,  2.2109618 ,  3.8416748 ,  6.658555  ],\n",
       "       [ 1.4929574 ,  1.6116067 ,  3.2259116 ,  7.704205  ],\n",
       "       [ 1.5229623 ,  1.8281201 ,  5.4464436 ,  7.7252007 ],\n",
       "       ...,\n",
       "       [ 0.34117293, 12.1533165 ,  2.9869742 ,  0.14031982],\n",
       "       [ 1.4027517 ,  8.893457  ,  1.3215837 ,  1.5881844 ],\n",
       "       [ 2.9297025 ,  4.430632  ,  6.361498  ,  3.5100381 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bc6cc3c-6eb5-44fe-90eb-f6217a7efb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  3,  9],\n",
       "       [ 1,  1,  2,  8],\n",
       "       [ 1,  1,  8,  8],\n",
       "       ...,\n",
       "       [ 1,  9,  4,  1],\n",
       "       [ 1, 10,  1,  1],\n",
       "       [ 1,  5,  7,  1]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7b20c-f876-474e-a24b-76be17a0ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
