{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f736da39-1208-4d7f-aee6-0c7065304b8e",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7263048-e3e2-4b92-b453-cb0202179ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "%matplotlib qt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from snntorch import surrogate\n",
    "from snntorch import utils\n",
    "import snntorch.functional as SF\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b5821-f367-47c4-bd52-d188c508e34d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae22bd7-283c-4a37-8a89-ff00a3f69346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 10 non-empty values\n",
      " bads: []\n",
      " ch_names: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4\n",
      " chs: 14 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 17 items (3 Cardinal, 14 EEG)\n",
      " file_id: 4 items (dict)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 64.0 Hz\n",
      " meas_date: unspecified\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 14\n",
      " projs: []\n",
      " sfreq: 128.0 Hz\n",
      ">\n",
      "['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n"
     ]
    }
   ],
   "source": [
    "main_folder = \"ThesisFolder\"\n",
    "extras_folder = \"Extras\"\n",
    "\n",
    "data_folder_py = os.path.join(extras_folder, \"GAMEEMO_PY\")\n",
    "data_folder_mat = os.path.join(extras_folder,\"GAMEEMO_MAT\")\n",
    "data_folder_fif = os.path.join(main_folder,\"GAMEEMO_FIF\")\n",
    "data_folder_epoch = os.path.join(extras_folder,\"GAMEEMO_EPOCH\")\n",
    "\n",
    "files_py = os.listdir(data_folder_py)\n",
    "files_mat = os.listdir(data_folder_mat)\n",
    "files_fif = os.listdir(data_folder_fif)\n",
    "\n",
    "filename = os.path.join(data_folder_fif, files_fif[0])\n",
    "raw = mne.io.read_raw_fif(filename, preload=True)\n",
    "info = raw.info\n",
    "channels = raw.info[\"ch_names\"]\n",
    "print(info)\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8ad7b-4002-4ee8-806e-4bc0da3ef759",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Function Definition space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328189f2-4699-4777-8829-31ad5242ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_law_encode(x, A):\n",
    "    abs_x = np.abs(x)\n",
    "    encoded = np.where(abs_x < 1/A, A * abs_x / (1 + np.log(A)), (1 + np.log(A * abs_x)) / (1 + np.log(A)))\n",
    "    return np.sign(x) * encoded\n",
    "\n",
    "def a_law_decode(y, A):\n",
    "    abs_y = np.abs(y)\n",
    "    decoded = np.where(abs_y < 1 / (1 + np.log(A)), abs_y * (1 + np.log(A)) / A, np.exp(abs_y * (1 + np.log(A)) - 1))\n",
    "    return np.sign(y) * decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a5a689-4b6f-484d-9ac1-6d75b298a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth_bandpass_filter(lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def plot_frequency_response(b, a, fs, nfft=8000, window='hamming'):\n",
    "    w, h = signal.freqz(b, a, worN=nfft)\n",
    "    plt.figure()\n",
    "    plt.plot(0.5 * fs * w / np.pi, np.abs(h), 'b')\n",
    "    plt.title('Bandpass Filter Frequency Response')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Gain')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def apply_filter(data, b, a):\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f3708-53ee-4009-a385-e89e69bf85ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Particle Swarm Optimization - Shuvankar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75217ca5-52b1-4268-9175-ed2539ca60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSA_encode(S, thresholdBSA):\n",
    "    B = (S > thresholdBSA).astype(int)  \n",
    "    S_modified = S * B\n",
    "    return B, S_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66e3988-0f42-4398-822e-fc4f351bb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(original_signal, reconstructed_signal):\n",
    "    mse = mean_squared_error(original_signal, reconstructed_signal)\n",
    "    rmse = np.sqrt(mse)\n",
    "    pcc, _ = pearsonr(original_signal, reconstructed_signal)\n",
    "    snr = 10 * np.log10(np.sum(np.square(original_signal)) / np.sum(np.square(original_signal - reconstructed_signal)))\n",
    "    psnr = 10 * np.log10(np.max(np.square(original_signal)) / mse)\n",
    "    cos_sim = cosine_similarity([original_signal], [reconstructed_signal])[0][0]\n",
    "    ssim_value = ssim(original_signal, reconstructed_signal, data_range=original_signal.max() - original_signal.min())\n",
    "    \n",
    "    # Combine all metrics for the final fitness score\n",
    "    # Minimize MSE and RMSE, maximize SNR, PSNR, PCC, Cosine Similarity, and SSIM\n",
    "    fitness = -mse + -rmse + (snr * 10) + (psnr * 5) + (pcc * 100) + (cos_sim * 100) + (ssim_value * 100)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b5bc8d-8727-41e9-9b71-6fc9d5a35470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_particles(size):\n",
    "    particles = []\n",
    "    for _ in range(size):\n",
    "        # Randomly initialize thresholds for BSA\n",
    "        position = (random.uniform(0.4, 0.7),)  # Threshold BSA\n",
    "        velocity = (random.uniform(-0.1, 0.1),)  # Velocity for BSA threshold\n",
    "        particles.append((position, velocity, position))  # (position, velocity, personal best)\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0c7777-9027-4bc2-83bd-17030b045a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_swarm_optimization(df, num_particles, num_iterations):\n",
    "    inertia_weight = 0.7\n",
    "    cognitive_weight = 1.5\n",
    "    social_weight = 1.5\n",
    "    \n",
    "    particles = initialize_particles(num_particles)\n",
    "    global_best_position = None\n",
    "    global_best_fitness = -np.inf\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(num_particles):\n",
    "            position, velocity, personal_best = particles[i]\n",
    "\n",
    "            # Assume we're processing the first channel for simplicity\n",
    "            eeg_channel_data = df\n",
    "\n",
    "            # Apply BSA and reconstruct\n",
    "            spike_train_bsa, modified_signal_bsa = BSA_encode(eeg_channel_data, position[0])\n",
    "            reconstructed_bsa = modified_signal_bsa\n",
    "\n",
    "            # Calculate fitness\n",
    "            fitness_bsa = calculate_fitness(eeg_channel_data, reconstructed_bsa)\n",
    "\n",
    "            # Update personal best\n",
    "            if fitness_bsa > calculate_fitness(eeg_channel_data, BSA_encode(eeg_channel_data, personal_best[0])[1]):\n",
    "                personal_best = position\n",
    "\n",
    "            # Update global best\n",
    "            if fitness_bsa > global_best_fitness:\n",
    "                global_best_fitness = fitness_bsa\n",
    "                global_best_position = position\n",
    "\n",
    "            # Update velocity and position\n",
    "            new_velocity = (\n",
    "                inertia_weight * velocity[0] +\n",
    "                cognitive_weight * random.random() * (personal_best[0] - position[0]) +\n",
    "                social_weight * random.random() * (global_best_position[0] - position[0]),\n",
    "            )\n",
    "            new_position = (min(max(position[0] + new_velocity[0], 0.0), 1.0),)  # Clamp BSA threshold\n",
    "\n",
    "            particles[i] = (new_position, new_velocity, personal_best)\n",
    "\n",
    "    return global_best_position, global_best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f4ffde-510e-4c69-af58-ea58b1665b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_eeg_signal(signal, num_particles=100, num_iterations=20):\n",
    "    df = signal\n",
    "    global channels\n",
    "\n",
    "    global_best_position, global_best_fitness = particle_swarm_optimization(df, num_particles, num_iterations)\n",
    "    return global_best_position[0], global_best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa31934-1b56-4811-86bb-ce52cefd10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spikes(df, threshold):\n",
    "    spikes_df = []\n",
    "    for channel in df:\n",
    "        eeg_channel_data = channel\n",
    "        spike_train_bsa, _ = BSA_encode(eeg_channel_data, threshold)\n",
    "        spikes_df.append(spike_train_bsa)\n",
    "    return np.array(spikes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2582a4c-65ce-4f7e-b5c9-121b42e39ff0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c84e3-51a5-43b1-920d-92fd6931d369",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filtering Segment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3494ddd3-ee31-43d1-8bfc-df7752bb2d0d",
   "metadata": {},
   "source": [
    "test_rawArray = []\n",
    "test_compressedRaw = []\n",
    "for file in tqdm(files_fif):\n",
    "    filename = os.path.join(data_folder_fif, file)\n",
    "    raw = mne.io.read_raw_fif(filename, preload=True)\n",
    "    raw.filter(8, 42) \n",
    "\n",
    "    raw_data = raw.get_data() * 1e6\n",
    "    compressed_raw = np.zeros_like(raw_data)\n",
    "    \n",
    "    for idx, _ in enumerate(raw_data):\n",
    "        compressed_raw[idx] = raw_data[idx]/np.max(raw_data[idx])\n",
    "        compressed_raw[idx] = a_law_encode(compressed_raw[idx], 80)\n",
    "        compressed_raw[idx] = (compressed_raw[idx]-np.min(compressed_raw[idx]))/(np.max(compressed_raw[idx])-np.min(compressed_raw[idx]))\n",
    "        raw_data[idx] = (raw_data[idx]-np.min(raw_data[idx]))/(np.max(raw_data[idx])-np.min(raw_data[idx]))\n",
    "        \n",
    "    \n",
    "    test_rawArray.append(raw_data)\n",
    "    test_compressedRaw.append(compressed_raw)\n",
    "\n",
    "test_rawArray =np.array(test_rawArray, dtype=np.float32)\n",
    "test_compressedRaw =np.array(test_compressedRaw, dtype=np.float32)\n",
    "\n",
    "print(\"Files: \", test_rawArray.shape[0], \"\\n\",\n",
    "     \"Channels: \", test_rawArray.shape[1], \"\\n\",\n",
    "     \"Samples: \", test_rawArray.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Files: \", test_compressedRaw.shape[0], \"\\n\",\n",
    "     \"Channels: \", test_compressedRaw.shape[1], \"\\n\",\n",
    "     \"Samples: \", test_compressedRaw.shape[2], \"\\n\",)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f511db2d-b065-46fb-8294-47d320df9813",
   "metadata": {},
   "source": [
    "# Customizable parameters\n",
    "# lowcut = 6.0  # Lower cutoff frequency in Hz\n",
    "# highcut = 12.0  # Upper cutoff frequency in Hz\n",
    "# fs = 128.0  # Sampling frequency in Hz\n",
    "order = 2  # Filter order\n",
    "nfft = 1024  # Number of FFT points\n",
    "window = 'hamming'  # Window type\n",
    "\n",
    "# Design filter\n",
    "b_alpha, a_alpha = butterworth_bandpass_filter(8, 13, 128, order)\n",
    "b_beta, a_beta   = butterworth_bandpass_filter(13, 30, 128, order)\n",
    "b_gamma, a_gamma = butterworth_bandpass_filter(30, 60, 128, order)\n",
    "\n",
    "# Plot frequency response\n",
    "# plot_frequency_response(b_alpha, a_alpha, fs, nfft, window)\n",
    "# plot_frequency_response(b_beta, a_beta, fs, nfft, window)\n",
    "# plot_frequency_response(b_gamma, a_gamma, fs, nfft, window)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6e46e52-6ab1-420c-aaf8-ac705f7bcde2",
   "metadata": {},
   "source": [
    "multiplier=111\n",
    "offset=58\n",
    "sample_data = test_rawArray[multiplier][0][offset*641:(offset+1)*641]\n",
    "compressed_sample = test_compressedRaw[multiplier][0][offset*641:(offset+1)*641]\n",
    "\n",
    "sample_data_alpha = apply_filter(sample_data, b_alpha, a_alpha)\n",
    "sample_data_alpha = (sample_data_alpha/np.max(sample_data_alpha))*np.max(sample_data)\n",
    "sample_data_beta = apply_filter(sample_data, b_beta, a_beta)\n",
    "sample_data_beta = (sample_data_beta/np.max(sample_data_beta))*np.max(sample_data)\n",
    "sample_data_gamma = apply_filter(sample_data, b_gamma, a_gamma)\n",
    "sample_data_gamma = (sample_data_gamma/np.max(sample_data_gamma))*np.max(sample_data)\n",
    "\n",
    "compressed_sample_alpha = apply_filter(compressed_sample, b_alpha, a_alpha)\n",
    "compressed_sample_alpha = (compressed_sample_alpha/np.max(compressed_sample_alpha))*np.max(compressed_sample)\n",
    "compressed_sample_beta = apply_filter(compressed_sample, b_beta, a_beta)\n",
    "compressed_sample_beta = (compressed_sample_beta/np.max(compressed_sample_beta))*np.max(compressed_sample)\n",
    "compressed_sample_gamma = apply_filter(compressed_sample, b_gamma, a_gamma)\n",
    "compressed_sample_gamma = (compressed_sample_gamma/np.max(compressed_sample_gamma))*np.max(compressed_sample)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(421)\n",
    "plt.plot(sample_data)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.subplot(422)\n",
    "plt.plot(compressed_sample)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(423)\n",
    "plt.plot(sample_data_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.subplot(424)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(425)\n",
    "plt.plot(sample_data_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.subplot(426)\n",
    "plt.plot(compressed_sample_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(427)\n",
    "plt.plot(sample_data_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.subplot(428)\n",
    "plt.plot(compressed_sample_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9145e-1904-4712-95d7-ef76c0321dba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filter Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ebf4afa-c93f-4bb0-9f1e-f81324fed6aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [00:21<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.0\n",
      "Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawArray = []\n",
    "compressedRaw = []\n",
    "for file in tqdm(files_fif):\n",
    "    filename = os.path.join(data_folder_fif, file)\n",
    "    raw = mne.io.read_raw_fif(filename, preload=True)\n",
    "    raw.filter(8, 42) \n",
    "\n",
    "    epoch_length = 10 \n",
    "    sfreq = raw.info['sfreq']\n",
    "\n",
    "    events = mne.make_fixed_length_events(raw, duration=epoch_length)\n",
    "    epochs = mne.Epochs(raw, events, tmin=0, tmax=epoch_length, baseline=None, preload=True)\n",
    "\n",
    "    raw_data = epochs.get_data() * 1e6\n",
    "    compressed_raw = np.zeros_like(raw_data)\n",
    "    \n",
    "    for epoch in raw_data:\n",
    "        rawEpoch = []\n",
    "        compressedEpoch = []\n",
    "        for channel in epoch:\n",
    "            c_ch = channel/np.max(channel)\n",
    "            c_ch = a_law_encode(c_ch, 80)\n",
    "            c_ch = (c_ch-np.min(c_ch))/(np.max(c_ch)-np.min(c_ch))\n",
    "            channel = (channel-np.min(channel))/(np.max(channel)-np.min(channel))\n",
    "            rawEpoch.append(channel)\n",
    "            compressedEpoch.append(c_ch)\n",
    "        rawArray.append(rawEpoch)\n",
    "        compressedRaw.append(compressedEpoch)\n",
    "        \n",
    "\n",
    "rawArray =np.array(rawArray, dtype=np.float32)\n",
    "compressedRaw =np.array(compressedRaw, dtype=np.float32)\n",
    "\n",
    "print(sfreq)\n",
    "print(\"Files: \", rawArray.shape[0], \"\\n\",\n",
    "     \"Channels: \", rawArray.shape[1], \"\\n\",\n",
    "     \"Samples: \", rawArray.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Files: \", compressedRaw.shape[0], \"\\n\",\n",
    "     \"Channels: \", compressedRaw.shape[1], \"\\n\",\n",
    "     \"Samples: \", compressedRaw.shape[2], \"\\n\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab89f23-6cab-460d-b416-54bd85af3e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 14, 1281)\n"
     ]
    }
   ],
   "source": [
    "files = raw_data.shape[0]\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559265d6-8fe4-4f24-9f47-9d659da60498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowcut = 6.0 \n",
    "# highcut = 12.0  \n",
    "# fs = 128.0  \n",
    "order = 2  \n",
    "\n",
    "b_alpha, a_alpha = butterworth_bandpass_filter(8, 13, 128, order)\n",
    "b_beta, a_beta   = butterworth_bandpass_filter(13, 30, 128, order)\n",
    "b_gamma, a_gamma = butterworth_bandpass_filter(30, 60, 128, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98121da6-3a7e-4ea8-adae-d86b39633a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3248/3248 [00:21<00:00, 153.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3248/3248 [00:21<00:00, 147.96it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha_band_raw = []\n",
    "beta_band_raw = []\n",
    "gamma_band_raw = []\n",
    "\n",
    "for epoch in tqdm(rawArray):\n",
    "    epochArrayA = []\n",
    "    epochArrayB = []\n",
    "    epochArrayG = []\n",
    "    for channel in epoch:\n",
    "        data_alpha = apply_filter(channel, b_alpha, a_alpha)\n",
    "        data_alpha = ((data_alpha-np.min(data_alpha))/(np.max(data_alpha)-np.min(data_alpha)))*(np.max(channel))\n",
    "        data_beta = apply_filter(channel, b_beta, a_beta)\n",
    "        data_beta = ((data_beta-np.min(data_beta))/(np.max(data_beta)-np.min(data_beta)))*(np.max(channel))\n",
    "        data_gamma = apply_filter(channel, b_gamma, a_gamma)\n",
    "        data_gamma = ((data_gamma-np.min(data_gamma))/(np.max(data_gamma)-np.min(data_gamma)))*(np.max(channel))\n",
    "        epochArrayA.append(data_alpha)\n",
    "        epochArrayB.append(data_beta)\n",
    "        epochArrayG.append(data_gamma)\n",
    "    alpha_band_raw.append(epochArrayA)\n",
    "    beta_band_raw.append(epochArrayB)\n",
    "    gamma_band_raw.append(epochArrayG)\n",
    "\n",
    "\n",
    "alpha_band_compressed = []\n",
    "beta_band_compressed = []\n",
    "gamma_band_compressed = []\n",
    "\n",
    "for epoch in tqdm(compressedRaw):\n",
    "    epochArrayA = []\n",
    "    epochArrayB = []\n",
    "    epochArrayG = []\n",
    "    for channel in epoch:\n",
    "        data_alpha = apply_filter(channel, b_alpha, a_alpha)\n",
    "        data_alpha = ((data_alpha-np.min(data_alpha))/(np.max(data_alpha)-np.min(data_alpha)))*(np.max(channel))\n",
    "        data_beta = apply_filter(channel, b_beta, a_beta)\n",
    "        data_beta = ((data_beta-np.min(data_beta))/(np.max(data_beta)-np.min(data_beta)))*(np.max(channel))\n",
    "        data_gamma = apply_filter(channel, b_gamma, a_gamma)\n",
    "        data_gamma = ((data_gamma-np.min(data_gamma))/(np.max(data_gamma)-np.min(data_gamma)))*(np.max(channel))\n",
    "        epochArrayA.append(data_alpha)\n",
    "        epochArrayB.append(data_beta)\n",
    "        epochArrayG.append(data_gamma)\n",
    "    alpha_band_compressed.append(epochArrayA)\n",
    "    beta_band_compressed.append(epochArrayB)\n",
    "    gamma_band_compressed.append(epochArrayG)\n",
    "\n",
    "alpha_band_raw = np.array(alpha_band_raw)\n",
    "beta_band_raw = np.array(beta_band_raw)\n",
    "gamma_band_raw = np.array(gamma_band_raw)\n",
    "alpha_band_compressed = np.array(alpha_band_compressed)\n",
    "beta_band_compressed = np.array(beta_band_compressed)\n",
    "gamma_band_compressed = np.array(gamma_band_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56328e4d-7ab1-4f6b-9817-aa4cafb918be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Files: \", alpha_band_raw.shape[0], \"\\n\",\n",
    "     \"Channels: \", alpha_band_raw.shape[1], \"\\n\",\n",
    "     \"Samples: \", alpha_band_raw.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Files: \", alpha_band_compressed.shape[0], \"\\n\",\n",
    "     \"Channels: \", alpha_band_compressed.shape[1], \"\\n\",\n",
    "     \"Samples: \", alpha_band_compressed.shape[2], \"\\n\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504091fb-4cc7-4258-bb3c-9d8e91c58407",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 48\n",
    "multiplier = 95\n",
    "epoch = (files * multiplier) + offset\n",
    "channel = 7\n",
    "sample_data = rawArray[epoch][channel]\n",
    "compressed_sample = compressedRaw[epoch][channel]\n",
    "\n",
    "sample_data_alpha = alpha_band_raw[epoch][channel]\n",
    "compressed_sample_alpha = alpha_band_compressed[epoch][channel]\n",
    "\n",
    "sample_data_beta = beta_band_raw[epoch][channel]\n",
    "compressed_sample_beta = beta_band_compressed[epoch][channel]\n",
    "\n",
    "sample_data_gamma = gamma_band_raw[epoch][channel]\n",
    "compressed_sample_gamma = gamma_band_compressed[epoch][channel]\n",
    "\n",
    "plt.figure(2)\n",
    "plt.subplot(421)\n",
    "plt.plot(sample_data)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(422)\n",
    "plt.plot(compressed_sample)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(423)\n",
    "plt.plot(sample_data_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Alpha file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(424)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Alpha file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(425)\n",
    "plt.plot(sample_data_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Beta file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(426)\n",
    "plt.plot(compressed_sample_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Beta file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(427)\n",
    "plt.plot(sample_data_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Gamma file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(428)\n",
    "plt.plot(compressed_sample_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Gamma file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38f04cb7-856f-4ec7-b35d-8ac9c18e82b9",
   "metadata": {},
   "source": [
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"rawArray.npy\"), rawArray)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"compressedRaw.npy\"), compressedRaw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"alpha_band_raw.npy\"), alpha_band_raw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"beta_band_raw.npy\"), beta_band_raw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"gamma_band_raw.npy\"), gamma_band_raw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"alpha_band_compressed.npy\"), alpha_band_compressed)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"beta_band_compressed.npy\"), beta_band_compressed)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset5sec\", \"gamma_band_compressed.npy\"), gamma_band_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e233a2-4c63-4447-bf05-000f4cf91836",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawArray_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"rawArray.npy\"))\n",
    "compressedRaw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"compressedRaw.npy\"))\n",
    "alpha_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"alpha_band_raw.npy\"))\n",
    "beta_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"beta_band_raw.npy\"))\n",
    "gamma_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"gamma_band_raw.npy\"))\n",
    "alpha_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"alpha_band_compressed.npy\"))\n",
    "beta_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"beta_band_compressed.npy\"))\n",
    "gamma_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"gamma_band_compressed.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426054c7-47eb-47f8-8c09-5e51d02b22ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Compressed\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Raw Alpha\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Compressed Alpha\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Raw Beta\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Compressed Beta\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Raw Gamma\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n",
      "Compressed Gamma\n",
      " Files:  6608 \n",
      " Channels:  14 \n",
      " Samples:  641 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 48\n",
    "multiplier = 48\n",
    "epoch = (59 * multiplier) + offset\n",
    "channel = 7\n",
    "sample_data = rawArray_loaded[epoch][channel]\n",
    "compressed_sample = compressedRaw_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw\\n Files: \", rawArray_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", rawArray_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", rawArray_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed\\n Files: \", compressedRaw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", compressedRaw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", compressedRaw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "sample_data_alpha = alpha_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_alpha = alpha_band_compressed_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw Alpha\\n Files: \", alpha_band_raw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", alpha_band_raw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", alpha_band_raw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed Alpha\\n Files: \", alpha_band_compressed_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", alpha_band_compressed_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", alpha_band_compressed_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "sample_data_beta = beta_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_beta = beta_band_compressed_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw Beta\\n Files: \", beta_band_raw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", beta_band_raw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", beta_band_raw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed Beta\\n Files: \", beta_band_compressed_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", beta_band_compressed_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", beta_band_compressed_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "sample_data_gamma = gamma_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_gamma = gamma_band_compressed_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw Gamma\\n Files: \", gamma_band_raw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", gamma_band_raw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", gamma_band_raw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed Gamma\\n Files: \", gamma_band_compressed_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", gamma_band_compressed_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", gamma_band_compressed_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.subplot(421)\n",
    "plt.plot(sample_data)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(422)\n",
    "plt.plot(compressed_sample)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(423)\n",
    "plt.plot(sample_data_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Alpha file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(424)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Alpha file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(425)\n",
    "plt.plot(sample_data_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Beta file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(426)\n",
    "plt.plot(compressed_sample_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Beta file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(427)\n",
    "plt.plot(sample_data_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Gamma file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(428)\n",
    "plt.plot(compressed_sample_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Gamma file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b5c3c41-e692-42b1-af7c-124f20e08f4f",
   "metadata": {},
   "source": [
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"rawArray.npy\"), rawArray)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"compressedRaw.npy\"), compressedRaw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"alpha_band_raw.npy\"), alpha_band_raw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"beta_band_raw.npy\"), beta_band_raw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"gamma_band_raw.npy\"), gamma_band_raw)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"alpha_band_compressed.npy\"), alpha_band_compressed)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"beta_band_compressed.npy\"), beta_band_compressed)\n",
    "np.save(os.path.join(\"HolyMotherOfDataset10sec\", \"gamma_band_compressed.npy\"), gamma_band_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc5459e-b751-40e0-81d0-9d0b040f647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawArray_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"rawArray.npy\"))\n",
    "compressedRaw_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"compressedRaw.npy\"))\n",
    "alpha_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"alpha_band_raw.npy\"))\n",
    "beta_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"beta_band_raw.npy\"))\n",
    "gamma_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"gamma_band_raw.npy\"))\n",
    "alpha_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"alpha_band_compressed.npy\"))\n",
    "beta_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"beta_band_compressed.npy\"))\n",
    "gamma_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset10sec\", \"gamma_band_compressed.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4af5e20-3699-48a7-8a0b-8f995277d8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Compressed\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Raw Alpha\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Compressed Alpha\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Raw Beta\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Compressed Beta\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Raw Gamma\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n",
      "Compressed Gamma\n",
      " Files:  3248 \n",
      " Channels:  14 \n",
      " Samples:  1281 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 23\n",
    "multiplier = 48\n",
    "epoch = (29 * multiplier) + offset\n",
    "channel = 7\n",
    "sample_data = rawArray_loaded[epoch][channel]\n",
    "compressed_sample = compressedRaw_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw\\n Files: \", rawArray_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", rawArray_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", rawArray_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed\\n Files: \", compressedRaw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", compressedRaw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", compressedRaw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "sample_data_alpha = alpha_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_alpha = alpha_band_compressed_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw Alpha\\n Files: \", alpha_band_raw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", alpha_band_raw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", alpha_band_raw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed Alpha\\n Files: \", alpha_band_compressed_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", alpha_band_compressed_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", alpha_band_compressed_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "sample_data_beta = beta_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_beta = beta_band_compressed_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw Beta\\n Files: \", beta_band_raw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", beta_band_raw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", beta_band_raw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed Beta\\n Files: \", beta_band_compressed_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", beta_band_compressed_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", beta_band_compressed_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "sample_data_gamma = gamma_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_gamma = gamma_band_compressed_loaded[epoch][channel]\n",
    "\n",
    "print(\"Raw Gamma\\n Files: \", gamma_band_raw_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", gamma_band_raw_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", gamma_band_raw_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Compressed Gamma\\n Files: \", gamma_band_compressed_loaded.shape[0], \"\\n\",\n",
    "     \"Channels: \", gamma_band_compressed_loaded.shape[1], \"\\n\",\n",
    "     \"Samples: \", gamma_band_compressed_loaded.shape[2], \"\\n\",)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.subplot(421)\n",
    "plt.plot(sample_data)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(422)\n",
    "plt.plot(compressed_sample)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(423)\n",
    "plt.plot(sample_data_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Alpha file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(424)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Alpha file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(425)\n",
    "plt.plot(sample_data_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Beta file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(426)\n",
    "plt.plot(compressed_sample_beta)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Beta file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(427)\n",
    "plt.plot(sample_data_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Raw Array Gamma file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.subplot(428)\n",
    "plt.plot(compressed_sample_gamma)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.title(f\"Compressed Array Gamma file: {multiplier+1}, Channel: {channel+1}, segment: {offset+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c8989-bc4e-4c9b-815f-7f4f243dc57c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Encoder workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4644c0b-f496-4f1b-b362-b73118fdc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdBasedRepresentation:\n",
    "    def __init__(self):\n",
    "        self.threshold = 0\n",
    "        self.signal = []\n",
    "\n",
    "    def generate_EEG_TBR(self, dataArray):\n",
    "        if len(dataArray.shape) > 1:\n",
    "            print(\"Invalid Data Dimension. Expected 1D Array\")\n",
    "            return np.zeros_like(dataArray)\n",
    "        dataArray_t = np.concatenate((dataArray, [dataArray[-1]]))\n",
    "        dataArray_tminus1 = np.concatenate(([dataArray[-1]], dataArray))\n",
    "        spike_train = dataArray_t - dataArray_tminus1\n",
    "        spike_train = spike_train[0:-1]\n",
    "        self.threshold = np.mean(spike_train) + 0.5 * np.std(spike_train)\n",
    "        spike_train = np.where(spike_train > self.threshold, 1, 0)\n",
    "        return spike_train, self.threshold\n",
    "\n",
    "    def generate_EEG_SF(self, dataArray, threshold):\n",
    "        if len(dataArray.shape) > 1:\n",
    "            print(\"Invalid Data Dimension. Expected 1D Array\")\n",
    "            return np.zeros_like(dataArray)\n",
    "        self.threshold = threshold\n",
    "        baseline = dataArray[0]\n",
    "        out = np.zeros_like(dataArray)\n",
    "        bases = np.zeros_like(dataArray)\n",
    "        for i, s_t in enumerate(dataArray):\n",
    "            if s_t >= baseline + self.threshold:\n",
    "                out[i] = 1\n",
    "                bases[i] = baseline\n",
    "                baseline += self.threshold\n",
    "            elif s_t < baseline - self.threshold:\n",
    "                out[i] = -1\n",
    "                bases[i] = baseline\n",
    "                baseline -= self.threshold\n",
    "        return out, bases\n",
    "\n",
    "    def generate_EEG_MW(self, dataArray, n_window, threshold):\n",
    "        if len(dataArray.shape) > 1:\n",
    "            print(\"Invalid Data Dimension. Expected 1D Array\")\n",
    "            return np.zeros_like(dataArray)\n",
    "\n",
    "        L_original = len(dataArray)\n",
    "        dataArray = np.concatenate(\n",
    "            (dataArray, np.zeros(\n",
    "                np.mod(L_original, n_window)\n",
    "            ))\n",
    "        )\n",
    "        L = len(dataArray)\n",
    "        self.threshold = threshold\n",
    "        spike_train = np.zeros_like(dataArray)\n",
    "        \n",
    "        for window in np.arange(int(np.divide(L, n_window)-1)):\n",
    "            dataChunk = dataArray[(window)*n_window:(window+1)*(n_window)]\n",
    "            baseline = np.mean(dataChunk)\n",
    "            for i, s_t in enumerate(dataChunk):\n",
    "                if s_t >= baseline + self.threshold:\n",
    "                    spike_train[(window)*n_window + i] = 1\n",
    "                    baseline += self.threshold\n",
    "                elif s_t < baseline - self.threshold:\n",
    "                    spike_train[(window)*n_window + i] = -1\n",
    "                    baseline -= self.threshold\n",
    "\n",
    "        return spike_train[0:L_original]\n",
    "\n",
    "    def generate_EEG_BSA(self, signal, fir, threshold):\n",
    "        self.signal = np.copy(signal)\n",
    "        if len(self.signal.shape) > 1:\n",
    "            print(\"Invalid Data Dimension. Expected 1D Array\")\n",
    "            return np.zeros_like(self.signal)   \n",
    "        L = len(self.signal)\n",
    "        F = len(fir)\n",
    "        spike_train = np.zeros(L)\n",
    "        self.threshold = threshold\n",
    "        for t in range(L - F):\n",
    "            err1 = 0\n",
    "            err2 = 0\n",
    "            for k in range(F):\n",
    "                err1 += abs(self.signal[t + k] - fir[k])\n",
    "                err2 += abs(self.signal[t + k - 1])\n",
    "            if err1 <= (err2 * self.threshold):\n",
    "                spike_train[t] = 1\n",
    "                for k in range(F):\n",
    "                    self.signal[t + k + 1] -= fir[k]     \n",
    "        return spike_train\n",
    "    def apply_butterworth_filter(self, data, lowcut, highcut, fs, order=5):\n",
    "        nyquist = 0.5 * fs\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = signal.butter(order, [low, high], btype='band')\n",
    "        y = signal.filtfilt(b, a, data)\n",
    "        return y \n",
    "        \n",
    "    def decode_time_contrast(self, spike_train, threshold, encode_type):\n",
    "        self.threshold = threshold\n",
    "        recon = np.zeros_like(spike_train, dtype=np.float16)\n",
    "        recon[-1] = self.threshold\n",
    "        print(threshold)\n",
    "\n",
    "        if encode_type=='tbr':\n",
    "            recon = self.apply_butterworth_filter(spike_train, 1, 20, 128, 2)\n",
    "        else:\n",
    "            for idx, spike in enumerate(np.copy(spike_train)):\n",
    "                if spike == 1:\n",
    "                    recon[idx] = recon[idx-1] + threshold\n",
    "                elif spike == -1:\n",
    "                    recon[idx] = recon[idx-1] - threshold\n",
    "                else:\n",
    "                    recon[idx] = recon[idx-1]\n",
    "\n",
    "        return recon\n",
    "\n",
    "    def decode_BSA(self, spike_train, fir):\n",
    "        recon = np.convolve(spike_train, fir, mode=\"same\")\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "730bddcf-f6fd-4f47-9aca-d13c20a7d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6608it [08:33, 12.87it/s]\n",
      "6608it [08:24, 13.10it/s]\n",
      "6608it [04:15, 25.89it/s]\n",
      "6608it [04:21, 25.25it/s]\n",
      "6608it [04:15, 25.91it/s]\n",
      "6608it [04:10, 26.42it/s]\n",
      "6608it [04:17, 25.66it/s]\n",
      "6608it [04:15, 25.86it/s]\n"
     ]
    }
   ],
   "source": [
    "tbr_encoder = ThresholdBasedRepresentation()\n",
    "encoding_types = ['tbr', 'sf', 'mw', 'bsa']\n",
    "current_encode = 'bsa'\n",
    "# spike_data_gamma, threshold = tbr_encoder.generate_EEG_TBR(compressed_sample_alpha)\n",
    "# spike_data_gamma, threshold = tbr_encoder.generate_EEG_SF(compressed_sample_alpha, 0.05)\n",
    "# spike_data_gamma = tbr_encoder.generate_EEG_MW(compressed_sample_alpha, 16, 0.05)\n",
    "# fir = (np.array([16, 8, 4, 2], dtype=np.float16))/32\n",
    "# spike_data_gamma = tbr_encoder.generate_EEG_BSA(compressed_sample_alpha, fir , 0.7)\n",
    "\n",
    "spike_read_dir = \"HolyMotherOfDataset5sec\"\n",
    "read_filenames = [\"rawArray.npy\",\n",
    "            \"compressedRaw.npy\",\n",
    "            \"alpha_band_raw.npy\",\n",
    "            \"beta_band_raw.npy\",\n",
    "            \"gamma_band_raw.npy\",\n",
    "            \"alpha_band_compressed.npy\",\n",
    "            \"beta_band_compressed.npy\",\n",
    "            \"gamma_band_compressed.npy\",]\n",
    "spike_save_dir = \"HolySpikes5s\"+current_encode\n",
    "os.makedirs(spike_save_dir, exist_ok=True)\n",
    "filenames = [\"rawArraySpikes.npy\",\n",
    "            \"compressedRawSpikes.npy\",\n",
    "            \"alpha_band_rawSpikes.npy\",\n",
    "            \"beta_band_rawSpikes.npy\",\n",
    "            \"gamma_band_rawSpikes.npy\",\n",
    "            \"alpha_band_compressedSpikes.npy\",\n",
    "            \"beta_band_compressedSpikes.npy\",\n",
    "            \"gamma_band_compressedSpikes.npy\",]\n",
    "\n",
    "for fileID, filename in enumerate(read_filenames):\n",
    "    filepath = os.path.join(spike_read_dir, filename)\n",
    "    load_data = np.load(filepath)\n",
    "    save_data = np.zeros_like(load_data)\n",
    "    for idx, example in tqdm(enumerate(load_data)):\n",
    "        ch_data = np.zeros_like(example)\n",
    "        for i, channel in enumerate(example):\n",
    "            if current_encode=='tbr':\n",
    "                ch_data[i, :], _ = tbr_encoder.generate_EEG_TBR(channel)\n",
    "            elif current_encode == 'sf':\n",
    "                ch_data[i, :], _ = tbr_encoder.generate_EEG_SF(channel, 0.05)\n",
    "            elif current_encode == 'mw':\n",
    "                ch_data[i, :] = tbr_encoder.generate_EEG_MW(channel, 16, 0.05)\n",
    "            elif current_encode == 'bsa':\n",
    "                fir = (np.array([16, 8, 4, 2], dtype=np.float16))/32\n",
    "                ch_data[i, :] = tbr_encoder.generate_EEG_BSA(channel, fir , 0.7)\n",
    "        save_data[idx,:,:] = ch_data\n",
    "    save_filepath = os.path.join(spike_save_dir, filenames[fileID])\n",
    "    np.save(save_filepath, save_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f30952e1-4ce8-4d2f-9e33-28a62cebc319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbr in Use\n"
     ]
    }
   ],
   "source": [
    "encoding_types = ['tbr', 'sf', 'mw', 'bsa']\n",
    "current_encoder = 'tbr'\n",
    "\n",
    "read_dir = \"HolyMotherOfDataset5sec\"\n",
    "read_filenames = [\"rawArray.npy\",\n",
    "            \"compressedRaw.npy\",\n",
    "            \"alpha_band_raw.npy\",\n",
    "            \"beta_band_raw.npy\",\n",
    "            \"gamma_band_raw.npy\",\n",
    "            \"alpha_band_compressed.npy\",\n",
    "            \"beta_band_compressed.npy\",\n",
    "            \"gamma_band_compressed.npy\",]\n",
    "\n",
    "type_ = 0\n",
    "load_waveform = np.load(os.path.join(read_dir, read_filenames[type_]))\n",
    "conv1 = nn.Conv1d(1, 1, kernel_size=15, padding=7, bias=True)\n",
    "\n",
    "mx = 1 * int(len(load_waveform) / 112)\n",
    "offset = 54\n",
    "channel = 4\n",
    "section = np.arange(600)+20\n",
    "plt.subplot(511)\n",
    "plt.plot(conv1(torch.tensor(load_waveform[mx + offset][channel][section], dtype=torch.float).unsqueeze(0)).squeeze(0).detach().cpu().numpy())\n",
    "plt.plot(load_waveform[mx + offset][channel][section])\n",
    "for i in np.arange(4):\n",
    "    spike_dir = \"HolySpikes5s\"+encoding_types[i]\n",
    "    filenames = [\"rawArraySpikes.npy\",\n",
    "                \"compressedRawSpikes.npy\",\n",
    "                \"alpha_band_rawSpikes.npy\",\n",
    "                \"beta_band_rawSpikes.npy\",\n",
    "                \"gamma_band_rawSpikes.npy\",\n",
    "                \"alpha_band_compressedSpikes.npy\",\n",
    "                \"beta_band_compressedSpikes.npy\",\n",
    "                \"gamma_band_compressedSpikes.npy\",]\n",
    "    load_spike = np.load(os.path.join(spike_dir, filenames[type_]))\n",
    "    plt.subplot(5, 1, i+2)\n",
    "    plt.stairs(load_spike[mx + offset][channel][section])\n",
    "    if encoding_types[i]==current_encoder:\n",
    "        print(f\"{current_encoder} in Use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e667849-2279-43ae-9602-5a57c455e0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16309fd9c30>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(load_waveform[mx + offset][channel][section], dtype=torch.float).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d60719-f503-438a-83a7-79a1a606f350",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Relevant codes "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fd7624a-8bce-40d3-9ebf-daba8fe5100c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "class SimpleRateEncoder:\n",
    "    def __init__(self, max_rate=100, time_window=1.0):\n",
    "        self.max_rate = max_rate  # Maximum firing rate (spikes per second)\n",
    "        self.time_window = time_window  # Time window for encoding (seconds)\n",
    "\n",
    "    def encode(self, data):\n",
    "        normalized_data = data\n",
    "        spike_counts = (normalized_data * self.max_rate * self.time_window).astype(int)\n",
    "        # print(spike_counts)\n",
    "        spike_trains = []\n",
    "        for count in spike_counts:\n",
    "            spike_train = np.zeros(int(self.max_rate * self.time_window))\n",
    "            spike_indices = np.random.choice(len(spike_train), count, replace=False)\n",
    "            spike_train[spike_indices] = 1\n",
    "            spike_trains.append(spike_train)\n",
    "        \n",
    "        return np.array(spike_trains)\n",
    "\n",
    "    def reconstruct(self, spike_trains):\n",
    "        spike_counts = np.sum(spike_trains, axis=1)\n",
    "        max_spikes = self.max_rate * self.time_window\n",
    "        reconstructed_signal = spike_counts / max_spikes\n",
    "        \n",
    "        return reconstructed_signal\n",
    "\n",
    "eeg_data = compressedRaw[12][3][:(128*5)]\n",
    "encoder = SimpleRateEncoder(max_rate=128, time_window=1.0)\n",
    "spike_trains = encoder.encode(eeg_data)\n",
    "# print(spike_trains.shape)\n",
    "\n",
    "reconstructed_signal = encoder.reconstruct(spike_trains)\n",
    "\n",
    "spike_train = spike_trains.reshape((spike_trains.shape[0]*spike_trains.shape[1]))\n",
    "plt.subplot(311)\n",
    "plt.plot(eeg_data)\n",
    "plt.subplot(312)\n",
    "plt.stairs(spike_train)\n",
    "plt.subplot(313)\n",
    "plt.plot(reconstructed_signal)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c125625-5d4a-4f66-b054-fe47ba46066b",
   "metadata": {},
   "source": [
    "from matplotlib.pyplot import plot, subplot, figure, xlabel, ylabel, title, stairs\n",
    "%matplotlib qt\n",
    "\n",
    "class TTFS:\n",
    "    def __init__(self, max_time=10):\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def encode(self, signal):\n",
    "        spike_train = np.zeros((len(signal), self.max_time))\n",
    "        for i, value in enumerate(signal):\n",
    "            spike_time = int((1 - value) * (self.max_time - 1))\n",
    "            spike_train[i, spike_time] = 1\n",
    "        return spike_train\n",
    "\n",
    "    def decode(self, spike_train):\n",
    "        decoded_signal = np.zeros(spike_train.shape[0])\n",
    "        for i, spikes in enumerate(spike_train):\n",
    "            spike_time = np.argmax(spikes)\n",
    "            decoded_signal[i] = 1 - (spike_time / (self.max_time - 1))\n",
    "        return decoded_signal\n",
    "\n",
    "signal = np.array([0.1, 0.4, 0.6, 0.8, 0.3])\n",
    "ttfs = TTFS(max_time=10)\n",
    "spike_train = ttfs.encode(signal)\n",
    "print(\"Spike train:\\n\", spike_train.shape)\n",
    "\n",
    "decoded_signal = ttfs.decode(spike_train)\n",
    "print(\"Decoded signal:\", decoded_signal.shape)\n",
    "\n",
    "spike_train = spike_train.reshape((spike_train.shape[0]*spike_train.shape[1]))\n",
    "subplot(311)\n",
    "plot(signal)\n",
    "subplot(312)\n",
    "stairs(spike_train)\n",
    "subplot(313)\n",
    "plot(decoded_signal)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "358981ec-107d-442b-a655-cbd1875245be",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "sample_data = rawArray[100]\n",
    "compressed_sample = compressedRaw[100]\n",
    "\n",
    "bsa_thresholds = []\n",
    "comp_thresholds = []\n",
    "for channel in tqdm(sample_data):\n",
    "    best_threshold, _ = optimize_eeg_signal(channel, num_particles=10, num_iterations=20)\n",
    "    bsa_thresholds.append(best_threshold)\n",
    "\n",
    "for channel in tqdm(compressed_sample):\n",
    "    best_threshold, _ = optimize_eeg_signal(channel, num_particles=10, num_iterations=20)\n",
    "    comp_thresholds.append(best_threshold)\n",
    "    \n",
    "average_bsa_threshold = np.mean(bsa_thresholds)\n",
    "print(f\"Average BSA Threshold: {average_bsa_threshold}\")\n",
    "\n",
    "average_comp_threshold = np.mean(comp_thresholds)\n",
    "print(f\"Average BSA Threshold: {average_comp_threshold}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b71807d2-803a-4aca-99ef-726700176264",
   "metadata": {},
   "source": [
    "sample_spikes = generate_spikes(sample_data, average_bsa_threshold) \n",
    "compressed_spikes = generate_spikes(compressed_sample, average_comp_threshold)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "channels = channels\n",
    "\n",
    "for i, channel in tqdm(enumerate(channels)):\n",
    "    plt.subplot(len(channels), 1, i + 1)  # Create a subplot for each channel\n",
    "    plt.plot(sample_spikes[i][:2000], drawstyle='steps-post')\n",
    "    plt.title(f\"Spike Train - {channel}\")\n",
    "    plt.ylabel('Spike')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylim(-0.1, 1.1)  # Spikes are binary (0 or 1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "channels = channels\n",
    "\n",
    "for i, channel in tqdm(enumerate(channels)):\n",
    "    plt.subplot(len(channels), 1, i + 1)  # Create a subplot for each channel\n",
    "    plt.plot(compressed_spikes[i][:2000], drawstyle='steps-post')\n",
    "    plt.title(f\"Spike Train - {channel}\")\n",
    "    plt.ylabel('Spike')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylim(-0.1, 1.1)  # Spikes are binary (0 or 1)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22993b78-5d85-4c67-b7ab-9ff9a002301f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Relevant codes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5abd5fe8-96c2-4836-a241-9e080fbfdac3",
   "metadata": {},
   "source": [
    "#apply soft-limiter\n",
    "    # alpha_multiplier = 20\n",
    "    # alpha = alpha_multiplier / np.max(raw_data[idx])\n",
    "    # threshold = 27.0\n",
    "    # raw_data[idx] = raw_data[idx] / (1 + (alpha * np.maximum(0, np.abs(raw_data[idx]) - threshold)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03c0d44e-8737-4c69-8dc6-bfab18f9200d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "class PopulationRateEncoder:\n",
    "    def __init__(self, num_neurons=10, max_rate=100, time_window=1.0):\n",
    "        self.num_neurons = num_neurons  # Number of neurons in the population\n",
    "        self.max_rate = max_rate  # Maximum firing rate (spikes per second)\n",
    "        self.time_window = time_window  # Time window for encoding (seconds)\n",
    "\n",
    "    def encode(self, data):\n",
    "        # Normalize the data to be between 0 and 1\n",
    "        normalized_data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "        \n",
    "        # Calculate the number of spikes for each neuron in the population\n",
    "        spike_counts = (normalized_data[:, None] * self.max_rate * self.time_window).astype(int)\n",
    "        print(spike_counts)\n",
    "        # Generate spike trains for the population\n",
    "        spike_trains = []\n",
    "        for counts in spike_counts:\n",
    "            neuron_spikes = []\n",
    "            for count in counts:\n",
    "                spike_train = np.zeros(int(self.max_rate * self.time_window))\n",
    "                spike_indices = np.random.choice(len(spike_train), count, replace=False)\n",
    "                spike_train[spike_indices] = 1\n",
    "                neuron_spikes.extend(spike_train)\n",
    "            spike_trains.append(neuron_spikes)\n",
    "        \n",
    "        return np.array(spike_trains)\n",
    "\n",
    "    def reconstruct(self, spike_trains):\n",
    "        # Sum the spikes across all neurons for each time point\n",
    "        summed_spikes = np.sum(spike_trains, axis=1)\n",
    "        \n",
    "        # Normalize the summed spikes to approximate the original signal values\n",
    "        max_spikes = self.num_neurons * self.max_rate * self.time_window\n",
    "        reconstructed_signal = summed_spikes / max_spikes\n",
    "        \n",
    "        return reconstructed_signal\n",
    "        \n",
    "# Sample EEG data (e.g., alpha band)\n",
    "eeg_data = np.array([0.1, 0.4, 0.6, 0.2, 0.8, 1.0, 0.3, 0.5])\n",
    "\n",
    "# Initialize the encoder with 10 neurons, a maximum firing rate of 100 Hz, and a time window of 1 second\n",
    "encoder = PopulationRateEncoder(num_neurons=10, max_rate=100, time_window=1.0)\n",
    "\n",
    "# Encode the EEG data\n",
    "spike_trains = encoder.encode(eeg_data)\n",
    "print(spike_trains.shape)\n",
    "\n",
    "reconstructed_signal = encoder.reconstruct(spike_trains)\n",
    "\n",
    "print(\"Original EEG Data:\", eeg_data)\n",
    "print(\"Spike Trains:\")\n",
    "for i, train in enumerate(spike_trains):\n",
    "    print(f\"Data Point {i}:\")\n",
    "    for j, neuron_train in enumerate(train):\n",
    "        print(f\"  Neuron {j}: {neuron_train}\")\n",
    "\n",
    "spike_train = spike_trains.reshape((spike_trains.shape[0]*spike_trains.shape[1]))\n",
    "plt.subplot(311)\n",
    "plt.plot(eeg_data)\n",
    "plt.subplot(312)\n",
    "plt.stairs(spike_train)\n",
    "plt.subplot(313)\n",
    "plt.plot(reconstructed_signal)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7af11b8-fb16-4a96-a19f-010f564405fb",
   "metadata": {},
   "source": [
    "rawArray = []\n",
    "compressedRaw = []\n",
    "for file in tqdm(files_fif):\n",
    "    filename = os.path.join(data_folder_fif, file)\n",
    "    raw = mne.io.read_raw_fif(filename, preload=True)\n",
    "    raw.filter(8, 42) \n",
    "\n",
    "    raw_data = raw.get_data() * 1e6\n",
    "    compressed_raw = np.zeros_like(raw_data)\n",
    "    \n",
    "    for idx, _ in enumerate(raw_data):\n",
    "        compressed_raw[idx] = raw_data[idx]/np.max(raw_data[idx])\n",
    "        compressed_raw[idx] = a_law_encode(compressed_raw[idx], 80)\n",
    "        compressed_raw[idx] = (compressed_raw[idx]-np.min(compressed_raw[idx]))/(np.max(compressed_raw[idx])-np.min(compressed_raw[idx]))\n",
    "        raw_data[idx] = (raw_data[idx]-np.min(raw_data[idx]))/(np.max(raw_data[idx])-np.min(raw_data[idx]))\n",
    "        \n",
    "    \n",
    "    rawArray.append(raw_data)\n",
    "    compressedRaw.append(compressed_raw)\n",
    "\n",
    "rawArray =np.array(rawArray, dtype=np.float32)\n",
    "compressedRaw =np.array(compressedRaw, dtype=np.float32)\n",
    "\n",
    "print(\"Files: \", rawArray.shape[0], \"\\n\",\n",
    "     \"Channels: \", rawArray.shape[1], \"\\n\",\n",
    "     \"Samples: \", rawArray.shape[2], \"\\n\",)\n",
    "\n",
    "print(\"Files: \", compressedRaw.shape[0], \"\\n\",\n",
    "     \"Channels: \", compressedRaw.shape[1], \"\\n\",\n",
    "     \"Samples: \", compressedRaw.shape[2], \"\\n\",)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3d370cf-6e07-4e73-bc25-68cc2b20be08",
   "metadata": {},
   "source": [
    "sample_data = rawArray[100][12]\n",
    "compressed_sample = compressedRaw[100][12]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(sample_data)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(compressed_sample)\n",
    "plt.xlabel(\"samples (n)\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c130e234-156e-4401-b4a6-b42601e444de",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from matplotlib.pyplot import plot, subplot, figure, xlabel, ylabel, title, stairs\n",
    "%matplotlib qt\n",
    "\n",
    "# Sample input data (normalized between 0 and 1)\n",
    "data = torch.tensor(np.arange(10)/10)\n",
    "\n",
    "# Parameters for latency encoding\n",
    "num_steps = 20  # Number of time steps\n",
    "threshold = 0.05  # Threshold for spike generation\n",
    "tau = 0.01  # Time constant for LIF neuron model\n",
    "\n",
    "# Perform latency encoding\n",
    "spikes = spikegen.delta(data, threshold=threshold)\n",
    "\n",
    "print(\"Input Data:\", data)\n",
    "print(\"Encoded Spikes:\\n\", spikes)\n",
    "subplot(211)\n",
    "stairs(data)\n",
    "subplot(212)\n",
    "stairs(spikes)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2df45f9-e75e-45e7-a91f-549c7371e134",
   "metadata": {},
   "source": [
    "rawArray_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"rawArray.npy\"))\n",
    "compressedRaw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"compressedRaw.npy\"))\n",
    "alpha_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"alpha_band_raw.npy\"))\n",
    "beta_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"beta_band_raw.npy\"))\n",
    "gamma_band_raw_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"gamma_band_raw.npy\"))\n",
    "alpha_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"alpha_band_compressed.npy\"))\n",
    "beta_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"beta_band_compressed.npy\"))\n",
    "gamma_band_compressed_loaded = np.load(os.path.join(\"HolyMotherOfDataset5sec\", \"gamma_band_compressed.npy\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "479069fc-e4a2-4a0e-9d1f-49fca1b0bc8c",
   "metadata": {},
   "source": [
    "offset = 48\n",
    "multiplier = 48\n",
    "epoch = (59 * multiplier) + offset\n",
    "channel = 7\n",
    "sample_data = rawArray_loaded[epoch][channel]\n",
    "compressed_sample = compressedRaw_loaded[epoch][channel]\n",
    "sample_data_alpha = alpha_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_alpha = alpha_band_compressed_loaded[epoch][channel]\n",
    "sample_data_beta = beta_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_beta = beta_band_compressed_loaded[epoch][channel]\n",
    "sample_data_gamma = gamma_band_raw_loaded[epoch][channel]\n",
    "compressed_sample_gamma = gamma_band_compressed_loaded[epoch][channel]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87a82e2b-f15c-4167-b65e-9674f788c956",
   "metadata": {},
   "source": [
    "tbr_encoder = ThresholdBasedRepresentation()\n",
    "spike_data_gamma, threshold = tbr_encoder.generate_EEG_TBR(compressed_sample_alpha)\n",
    "encode_type = ['tbr', 'sf', 'mw']\n",
    "recon_data = tbr_encoder.decode_time_contrast(spike_data_gamma, 16, encode_type[0])\n",
    "print(spike_data_gamma.shape)\n",
    "print(threshold)\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.subplot(312)\n",
    "plt.stairs(spike_data_gamma)\n",
    "plt.subplot(313)\n",
    "plt.stairs(recon_data)\n",
    "\n",
    "spike_data_gamma, threshold = tbr_encoder.generate_EEG_SF(compressed_sample_alpha, 0.05)\n",
    "recon_data = tbr_encoder.decode_time_contrast(spike_data_gamma, 0.05, encode_type[1])\n",
    "print(spike_data_gamma.shape)\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.subplot(312)\n",
    "plt.stairs(spike_data_gamma)\n",
    "plt.subplot(313)\n",
    "plt.stairs(recon_data)\n",
    "\n",
    "spike_data_gamma = tbr_encoder.generate_EEG_MW(compressed_sample_alpha, 16, 0.05)\n",
    "recon_data = tbr_encoder.decode_time_contrast(spike_data_gamma, 0.05, encode_type[2])\n",
    "print(spike_data_gamma.shape)\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.subplot(312)\n",
    "plt.stairs(spike_data_gamma)\n",
    "plt.subplot(313)\n",
    "plt.stairs(recon_data)\n",
    "\n",
    "sample_data = np.array([0.1, 0.9, 1, 0.3, 0.35], dtype=np.float16)\n",
    "fir = (np.array([16, 8, 4, 2], dtype=np.float16))/32\n",
    "spike_data_gamma = tbr_encoder.generate_EEG_BSA(compressed_sample_alpha, fir , 0.7)\n",
    "recon_data = tbr_encoder.decode_BSA(spike_data_gamma, fir)\n",
    "print(spike_data_gamma.shape)\n",
    "print(compressed_sample_alpha.shape)\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(compressed_sample_alpha)\n",
    "plt.subplot(312)\n",
    "plt.stairs(1-spike_data_gamma)\n",
    "plt.subplot(313)\n",
    "plt.stairs(recon_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7de1a-e78e-4273-a065-5fd844dcd9f4",
   "metadata": {},
   "source": [
    "# NorseCoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510e160d-5851-441b-b25a-8afc8278ce35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 14, 641) (6608, 14, 641)\n"
     ]
    }
   ],
   "source": [
    "read_dir = \"HolyMotherOfDataset5sec\"\n",
    "read_filenames = [\"rawArray.npy\",\n",
    "            \"compressedRaw.npy\",\n",
    "            \"alpha_band_raw.npy\",\n",
    "            \"beta_band_raw.npy\",\n",
    "            \"gamma_band_raw.npy\",\n",
    "            \"alpha_band_compressed.npy\",\n",
    "            \"beta_band_compressed.npy\",\n",
    "            \"gamma_band_compressed.npy\",]\n",
    "\n",
    "current_encoder = 'bsa'\n",
    "spike_dir = \"HolySpikes5s\"+current_encoder\n",
    "filenames = [\"rawArraySpikes.npy\",\n",
    "            \"compressedRawSpikes.npy\",\n",
    "            \"alpha_band_rawSpikes.npy\",\n",
    "            \"beta_band_rawSpikes.npy\",\n",
    "            \"gamma_band_rawSpikes.npy\",\n",
    "            \"alpha_band_compressedSpikes.npy\",\n",
    "            \"beta_band_compressedSpikes.npy\",\n",
    "            \"gamma_band_compressedSpikes.npy\",]\n",
    "\n",
    "type_ = 0\n",
    "load_waveform = np.load(os.path.join(read_dir, read_filenames[type_]))\n",
    "load_spike = np.load(os.path.join(spike_dir, filenames[type_]))\n",
    "print(load_waveform.shape, load_spike.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7261ae7-2b13-48e9-94f4-0a79104d0c72",
   "metadata": {},
   "source": [
    "rate_encoded_waveform = spikegen.rate(torch.tensor(load_waveform, device=\"cuda\"), num_steps=32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "897af767-2b01-4cb9-9aa0-8b2b42b49456",
   "metadata": {},
   "source": [
    "rate_encoded_waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f72a8e2-c7c4-438e-a3fc-d0e35a1bb5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112,)\n",
      "['boring' 'calm' 'funny' 'horror'] [28 28 28 28]\n",
      "(6608,) ['boring' 'calm' 'funny' 'horror'] [1652 1652 1652 1652]\n"
     ]
    }
   ],
   "source": [
    "label = ['boring', 'horror', 'calm', 'funny']\n",
    "labels = []\n",
    "for i in np.arange(28):\n",
    "    labels.extend(label)\n",
    "\n",
    "labels = np.array(labels)\n",
    "print(labels.shape)\n",
    "hmm, counts = np.unique(labels, return_counts=True)\n",
    "print(hmm, counts)\n",
    "main_labels = np.repeat(labels, 59)\n",
    "hmm, counts = np.unique(main_labels, return_counts=True)\n",
    "print(main_labels.shape, hmm, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b962277a-6444-44b8-8bb5-2d28169ff863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0 0 0 ... 3 3 3]\n",
      "(6608,)\n",
      "(array([0, 1, 2, 3]), array([1652, 1652, 1652, 1652], dtype=int64))\n",
      "(6608, 4)\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "translate = {'boring':0, 'horror':1, 'calm':2, 'funny':3}\n",
    "print(translate.get(main_labels[60]))\n",
    "\n",
    "main_labels = np.array([translate.get(label) for label in main_labels])\n",
    "print(main_labels)\n",
    "\n",
    "print(main_labels.shape)\n",
    "print(np.unique(main_labels, return_counts=True))\n",
    "\n",
    "num_classes = np.max(main_labels) + 1\n",
    "labels = np.eye(num_classes)[main_labels]\n",
    "\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e838d6-549d-4370-8ec2-9b1817b53775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 14, 641)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(load_waveform[:4000, :, :], main_labels[:4000], test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5609e50b-c11c-481a-9726-fdc571cb255c",
   "metadata": {},
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "del X_train\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3f2fc1-7092-4aca-866e-6f3e24135853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "dtype_1 = torch.float32\n",
    "dtype_2 = torch.long\n",
    "num_steps = 32\n",
    "X_train = torch.tensor(X_train, dtype=dtype_1, requires_grad=False).to(\"cuda\")\n",
    "X_test = torch.tensor(X_test, dtype=dtype_1, requires_grad=False).to(\"cuda\")\n",
    "y_train = torch.tensor(y_train, dtype=dtype_2, requires_grad=False).to(\"cuda\")\n",
    "y_test = torch.tensor(y_test, dtype=dtype_2, requires_grad=False).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68410031-8316-4c34-a52e-fe2d553d6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train.unsqueeze(1), y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test.unsqueeze(1), y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97159727-3529-4ad2-81f3-26ecf691d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 14, 641])\n",
      "torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877451d7-4e60-47ac-8e2e-38fb564b21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEEGSNNModel(nn.Module):\n",
    "    def __init__(self, n_outputs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = (1, 7), padding = (0, 3), bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (1, 7), padding = (0, 3), bias=True)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, threshold=1.0, spike_grad=snn.surrogate.sigmoid(), init_hidden=False, learn_beta=True, learn_threshold=True)\n",
    "        self.dense1 = nn.Linear(32*14*641, self.n_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, threshold=1.0, spike_grad=snn.surrogate.sigmoid(), init_hidden=False, learn_beta=True, learn_threshold=True)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        self.n_samples = x.shape[3]\n",
    "        self.n_channel = x.shape[2]\n",
    "        self.batch_size = x.shape[0]\n",
    "        \n",
    "        mem1 = self.lif1.init_leaky() \n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x, mem1 = self.lif1(x, mem1) \n",
    "        x = self.conv2(x)\n",
    "        x = self.dense1(x.view(self.batch_size, -1))\n",
    "        x, mem2 = self.lif2(x, mem2)\n",
    "           \n",
    "        return x, mem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ff2a42-e8a0-4e41-bad0-0eaf13ba2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, timesteps, data):\n",
    "    spk_rec = []\n",
    "    mem_rec = []\n",
    "    utils.reset(model)\n",
    "\n",
    "    for i in range(timesteps):\n",
    "        spk_out, mem_out = model(data)\n",
    "        spk_rec.append(spk_out)\n",
    "        mem_rec.append(mem_out)\n",
    "\n",
    "    return torch.stack(spk_rec).to(\"cuda\"), torch.stack(mem_rec).to(\"cuda\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7541ec42-d5d5-4c5c-90b4-113595e1e26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 14, 641])\n",
      "torch.Size([32, 64, 4])\n",
      "4\n",
      "torch.Size([32, 64, 4])\n",
      "4\n",
      "1.3810564279556274\n"
     ]
    }
   ],
   "source": [
    "model = MyEEGSNNModel(4).to(\"cuda\")\n",
    "criterion = SF.ce_rate_loss()\n",
    "loss = torch.zeros((1), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    ouput, mem_rec = forward_pass(model, 32, inputs)\n",
    "    print(inputs.shape)\n",
    "    print(ouput.shape)\n",
    "    print(ouput.size(-1))\n",
    "    print(mem_rec.shape)\n",
    "    print(mem_rec.size(-1))\n",
    "\n",
    "    loss = criterion(mem_rec, targets)\n",
    "    print(loss.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d24159cd-2ae9-4021-aeb2-c8d661f5deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68602432-3c29-4263-ba4c-ca9fb0d5988a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [06:12<00:00,  8.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [06:11<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 1.3863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [06:11<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 1.3863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████         | 41/46 [05:39<00:41,  8.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()         \n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \n\u001b[1;32m---> 20\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MyEEGSNNModel(4).to(\"cuda\")\n",
    "criterion = SF.ce_rate_loss()\n",
    "n_epochs = 10\n",
    "learning_rate = 5e-2\n",
    "\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        outputs, mem_rec = forward_pass(model, 32, inputs)\n",
    "        # loss = criterion(mem_rec, targets)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()         \n",
    "        optimizer.step()  \n",
    "        epoch_loss += loss.item() \n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {epoch_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74340b52-fc80-4376-87ac-7c9c6741296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    test_data = test_data.permute(1, 2, 3, 0).unsqueeze(1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output, mem_rec = forward_pass(model, test_data)\n",
    "            \n",
    "    return output, mem_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a134e7-2c11-4a34-a8f9-be6fa5313efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.permute(1, 2, 3, 0).unsqueeze(1)\n",
    "spk_out, _ = evaluate_model(model, X_test[:200].squeeze(1).permute(3, 0, 1, 2))\n",
    "accuracy = SF.acc.accuracy_rate(spk_out, y_test[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b83e2cb-74c1-435d-930f-782488e019e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.295\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f262d6-83b1-4876-9504-8845fd21c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm = nn.LogSoftmax()\n",
    "y_pred = lsm(torch.sum(evaluate_model(model, X_test), axis=0))\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994724a-1567-4848-aeb6-403a30fd4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0], torch.argmax(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce171e30-8834-4c40-9a7c-d29bb5d12c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(y_pred, axis=1).shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1d31e-828d-4fd3-a51b-1ee7588cc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = torch.argmax(y_pred, axis=1).cpu().detach().numpy()\n",
    "y_t = y_test.cpu().detach().numpy()\n",
    "print(accuracy_score(y_p, y_t))\n",
    "accuratey = np.sum(y_p == y_t) / len(y_t)\n",
    "print(accuratey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48d8d0-ca83-4505-a40a-823a0cd92baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm = nn.LogSoftmax()\n",
    "y_pred = lsm(torch.sum(evaluate_model(model, X_train), axis=0))\n",
    "print(y_pred.shape)\n",
    "print(torch.argmax(y_pred, axis=1).shape)\n",
    "print(y_train.shape)\n",
    "y_p = torch.argmax(y_pred, axis=1).cpu().detach().numpy()\n",
    "y_t = y_train.cpu().detach().numpy()\n",
    "print(accuracy_score(y_p, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc2e16-8237-4342-9a38-490567987c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"SNNEEG_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ad2d79-fa3b-4b8b-94a4-51444c3f31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 4         \n",
    "model = MyEEGSNNModel(output_size).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b696c59e-0c42-4680-9931-2d17308e2967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:24<00:00, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1.4960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = ce_rate_loss()\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5681f-f238-4b3b-b97d-9b8a8757219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"SNNEEG_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf4c3c99-10e7-4ccc-98d3-dd57621b0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92532c4e-1c05-4050-9403-91f29f1a4f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fba86249-1f34-489c-8e63-a1d2e2b84c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 904.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_train\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[90], line 6\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, single_input)\u001b[0m\n\u001b[0;32m      3\u001b[0m single_input \u001b[38;5;241m=\u001b[39m single_input\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape changes from (channels, width, height) to (1, channels, width, height)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[83], line 40\u001b[0m, in \u001b[0;36mMyEEGSNNModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n\u001b[1;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)\n\u001b[0;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool4(x)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:164\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\trchenv3_10\\lib\\site-packages\\torch\\nn\\functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 904.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "output = evaluate_model(model, X_train)\n",
    "y_pred = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "y_true = np.argmax(y_train.cpu().detach().numpy(), axis=1)\n",
    "print(accuracy_score(y_pred, y_true))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b90cd0e3-722c-4ba9-b0fe-a70f21c44a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27382753403933435\n"
     ]
    }
   ],
   "source": [
    "output = evaluate_model(model, X_test)\n",
    "y_pred = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "y_true = np.argmax(y_test.cpu().detach().numpy(), axis=1)\n",
    "print(accuracy_score(y_pred, y_true))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8bd98-202d-48be-a27a-36edb974250e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trch310",
   "language": "python",
   "name": "trch310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
